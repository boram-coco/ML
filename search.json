[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ML",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 21, 2022\n\n\n기계학습 (1221)\n\n\n김보람 \n\n\n\n\nDec 14, 2022\n\n\n기계학습 final\n\n\n김보람 \n\n\n\n\nDec 1, 2022\n\n\n기계학습 (1201)\n\n\n김보람 \n\n\n\n\nNov 30, 2022\n\n\n기계학습 (1130) 12주차\n\n\n김보람 \n\n\n\n\nNov 29, 2022\n\n\n기계학습 final(교수님)\n\n\n최규빈 \n\n\n\n\nNov 16, 2022\n\n\n기계학습 (1116) 11주차\n\n\n김보람 \n\n\n\n\nNov 9, 2022\n\n\n기계학습 (1109) 10주차\n\n\n김보람 \n\n\n\n\nOct 31, 2022\n\n\n기계학습 (1031) 9주차\n\n\n김보람 \n\n\n\n\nOct 26, 2022\n\n\n기계학습 midterm\n\n\n김보람 \n\n\n\n\nOct 26, 2022\n\n\n기계학습 (1026) 8주차\n\n\n김보람 \n\n\n\n\nOct 19, 2022\n\n\n기계학습 (1019) 7주차\n\n\n김보람 \n\n\n\n\nOct 12, 2022\n\n\n기계학습 (1012) 6주차\n\n\n김보람 \n\n\n\n\nOct 5, 2022\n\n\n기계학습 (1005) 5주차\n\n\n김보람 \n\n\n\n\nSep 28, 2022\n\n\n기계학습 (0928) 4주차\n\n\n김보람 \n\n\n\n\nSep 21, 2022\n\n\n기계학습 (0921) 3주차\n\n\n김보람 \n\n\n\n\nSep 14, 2022\n\n\n기계학습 (0914) 2주차\n\n\n김보람 \n\n\n\n\nSep 7, 2022\n\n\n기계학습 (0907) 1주차\n\n\n김보람 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html",
    "href": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html",
    "title": "기계학습 (1005) 5주차",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\n\n준비1 loss_fn을 plot하는 함수\n\ndef plot_loss(loss_fn,ax=None):\n    if ax==None:\n        fig = plt.figure()\n        ax=fig.add_subplot(1,1,1,projection='3d')\n        ax.elev=15;ax.azim=75\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.15),torch.arange(-1,10,0.15),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    ax.scatter(w0hat,w1hat,loss,s=0.1,alpha=0.2) \n    ax.scatter(-1,5,l(-1,5),s=200,marker='*') # 실제로 -1,5에서 최소값을 가지는건 아님.. \n\n\n$y_i Ber(_i),$ where \\(\\pi_i = \\frac{\\exp(-1+5x_i)}{1+\\exp(-1+5x_i)}\\) 에서 생성된 데이터 한정하여 손실함수가 그려지게 되어있음.\n\n준비2: for문 대신 돌려주고 epoch마다 필요한 정보를 기록하는 함수\n\ndef learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    what_history = [] \n\n    for epoc in range(1000): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        optimizr.zero_grad() \n\n        ## record \n        if epoc % 20 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            what_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    return yhat_history, loss_history, what_history\n\n\n20에폭마다 yhat, loss, what을 기록\n\n준비3: 애니메이션을 만들어주는 함수\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\ndef show_lrpr2(net,loss_fn,optimizr,suptitle=''):\n    yhat_history,loss_history,what_history = learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7,2.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ax1.set_xticks([]);ax1.set_yticks([])\n    ax2.set_xticks([]);ax2.set_yticks([]);ax2.set_zticks([])\n    ax2.elev = 15; ax2.azim = 75\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,v,'--')\n    ax1.scatter(x,y,alpha=0.05)\n    line, = ax1.plot(x,yhat_history[0],'--') \n    plot_loss(loss_fn,ax2)\n    fig.suptitle(suptitle)\n    fig.tight_layout()\n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(what_history)[epoc,0],np.array(what_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\n준비1에서 그려진 loss 함수위에, 준비2의 정보를 조합하여 애니메이션을 만들어주는 함수"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#imports",
    "href": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#imports",
    "title": "기계학습 (1005) 5주차",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n\n\n\n준비1 loss_fn을 plot하는 함수\n\ndef plot_loss(loss_fn,ax=None):\n    if ax==None:\n        fig = plt.figure()\n        ax=fig.add_subplot(1,1,1,projection='3d')\n        ax.elev=15;ax.azim=75\n    w0hat,w1hat =torch.meshgrid(torch.arange(-10,3,0.15),torch.arange(-1,10,0.15),indexing='ij')\n    w0hat = w0hat.reshape(-1)\n    w1hat = w1hat.reshape(-1)\n    def l(w0hat,w1hat):\n        yhat = torch.exp(w0hat+w1hat*x)/(1+torch.exp(w0hat+w1hat*x))\n        return loss_fn(yhat,y) \n    loss = list(map(l,w0hat,w1hat))\n    ax.scatter(w0hat,w1hat,loss,s=0.1,alpha=0.2) \n    ax.scatter(-1,5,l(-1,5),s=200,marker='*') # 실제로 -1,5에서 최소값을 가지는건 아님.. \n\n\n$y_i Ber(_i),$ where \\(\\pi_i = \\frac{\\exp(-1+5x_i)}{1+\\exp(-1+5x_i)}\\) 에서 생성된 데이터 한정하여 손실함수가 그려지게 되어있음.\n\n준비2: for문 대신 돌려주고 epoch마다 필요한 정보를 기록하는 함수\n\ndef learn_and_record(net, loss_fn, optimizr):\n    yhat_history = [] \n    loss_history = []\n    what_history = [] \n\n    for epoc in range(1000): \n        ## step1 \n        yhat = net(x)\n        ## step2 \n        loss = loss_fn(yhat,y)\n        ## step3\n        loss.backward() \n        ## step4 \n        optimizr.step()\n        optimizr.zero_grad() \n\n        ## record \n        if epoc % 20 ==0: \n            yhat_history.append(yhat.reshape(-1).data.tolist())\n            loss_history.append(loss.item())\n            what_history.append([net[0].bias.data.item(), net[0].weight.data.item()])\n    return yhat_history, loss_history, what_history\n\n\n20에폭마다 yhat, loss, what을 기록\n\n준비3: 애니메이션을 만들어주는 함수\n\nfrom matplotlib import animation\nplt.rcParams[\"animation.html\"] = \"jshtml\"\n\n\ndef show_lrpr2(net,loss_fn,optimizr,suptitle=''):\n    yhat_history,loss_history,what_history = learn_and_record(net,loss_fn,optimizr)\n    \n    fig = plt.figure(figsize=(7,2.5))\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n    ax1.set_xticks([]);ax1.set_yticks([])\n    ax2.set_xticks([]);ax2.set_yticks([]);ax2.set_zticks([])\n    ax2.elev = 15; ax2.azim = 75\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,v,'--')\n    ax1.scatter(x,y,alpha=0.05)\n    line, = ax1.plot(x,yhat_history[0],'--') \n    plot_loss(loss_fn,ax2)\n    fig.suptitle(suptitle)\n    fig.tight_layout()\n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(what_history)[epoc,0],np.array(what_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\n준비1에서 그려진 loss 함수위에, 준비2의 정보를 조합하여 애니메이션을 만들어주는 함수"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#logistic-intro-review-alpha",
    "href": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#logistic-intro-review-alpha",
    "title": "기계학습 (1005) 5주차",
    "section": "Logistic intro (review + \\(\\alpha\\))",
    "text": "Logistic intro (review + \\(\\alpha\\))\n- 모델: \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n$y_i Ber(_i),$ where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) &lt;— 외우세요!!\n\n- toy example\n\nx=torch.linspace(-1,1,2000).reshape(2000,1)\nw0= -1 \nw1= 5 \nu = w0+x*w1 \nv = torch.exp(u)/(1+torch.exp(u)) # v=πi, 즉 확률을 의미함\ny = torch.bernoulli(v) \n\n\nplt.plot(x,y,'o')\n\n\n\n\n\nnote: \\((w_0,w_1)\\)의 true는 \\((-1,5)\\)이다. -&gt; \\((\\hat{w}_0, \\hat{w}_1)\\)을 적당히 \\((-1,5)\\)근처로 추정하면 된다는 의미\n\n\nplt.scatter(x,y,alpha=0.05)\nplt.plot(x,v,'--r')\n\n\n\n\n- step1: yhat을 만들기\n(방법1)\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(1,1)  #x의 shape보면(2000,1)인데 뒤에 1이 중요..\na1 = torch.nn.Sigmoid() \nyhat = a1(l1(x))\nyhat\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n(방법2)\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(1,1)\na1 = torch.nn.Sigmoid() \nnet = torch.nn.Sequential(l1,a1) #net는 l1과 a1의 합성함수\nyhat = net(x)\nyhat\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n(방법3)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat = net(x)\nyhat\n\n# 단점: a1과 l1 각 통과하는게 궁금한데 이건 중간과정 보기가힘들다.\n# len(net) = 2 : 2가 나오네.. 우너소에 접근을 해보자\n#net[0], net[1]\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet[0]\n\nLinear(in_features=1, out_features=1, bias=True)\n\n\n\nnet[0](x)\n\ntensor([[-0.5003],\n        [-0.5007],\n        [-0.5010],\n        ...,\n        [-1.1930],\n        [-1.1934],\n        [-1.1937]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nnet[1] #a1의 기능\n\nSigmoid()\n\n\n\nnet[1](net[0](x))\n\ntensor([[0.3775],\n        [0.3774],\n        [0.3773],\n        ...,\n        [0.2327],\n        [0.2327],\n        [0.2326]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- step2: loss (일단 MSE로..)\n(방법1)\n\ntorch.mean((y-yhat)**2) #mse는 교수님들이 싫어한데.. 왜? 몰라 일단 걍 해보쟈\n\ntensor(0.2846, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\nloss=torch.mean((y-yhat)**2)\nloss\n\ntensor(0.2846, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(방법2)\n\nloss_fn = torch.nn.MSELoss()\nloss_fn(yhat,y) # yhat을 먼저쓰자!\n\ntensor(0.2846, grad_fn=&lt;MseLossBackward0&gt;)\n\n\n- step3~4는 동일\n- 반복 (준비+for문)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.MSELoss() #MSELoss로 하면.. .. 별로? BCE이거로바꾸기\noptimizr = torch.optim.SGD(net.parameters(),lr=0.01)\n\n\nplt.plot(x,y,'o',alpha=0.01)\n\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad() #청소\n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,v,'--b')\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#로지스틱bceloss",
    "href": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#로지스틱bceloss",
    "title": "기계학습 (1005) 5주차",
    "section": "로지스틱–BCEloss",
    "text": "로지스틱–BCEloss\n- BCEloss로 바꾸어서 적합하여 보자.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.01)\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat)) # loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,v,'--b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- 왜 잘맞지? -&gt; “linear -&gt; sigmoid” 와 같은 net에 BCEloss를 이용하면 손실함수의 모양이 convex 하기 때문에\n\n#convex:볼록한... convex가 학습하기 좋은!!\n\n\nplot_loss 함수소개 = 이 예제에 한정하여 \\(\\hat{w}_0,\\hat{w}_1,loss(\\hat{w}_0,\\hat{w}_1)\\)를 각각 \\(x,y,z\\) 축에 그려줍니다.\n\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n시각화1: MSE, 좋은초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) #학습률\n\n\nl1,a1 = net #초기값 세팅\nl1.bias.data = torch.tensor([-3.0]) #세팅값\nl1.weight.data = torch.tensor([[-1.0]]) #세팅값\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, good_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화2: MSE, 나쁜초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, bad_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화3: BCE, 좋은초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, good_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화4: BCE, 나쁜초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, good_init // SGD')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#로지스틱adam-국민옵티마이저",
    "href": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#로지스틱adam-국민옵티마이저",
    "title": "기계학습 (1005) 5주차",
    "section": "로지스틱–Adam (국민옵티마이저)",
    "text": "로지스틱–Adam (국민옵티마이저)\n\n# Adam은 SGD에 비하여 2가지 면에서 개선점이 있음\n# 1. 어려워서 몰라도 뎀\n# 2. 가속도의 개념\n\n\n시각화1: MSE, 좋은초기값 –&gt; 이걸 아담으로!\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05)  ## &lt;-- 여기를 수정!\n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, good_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화2: MSE, 나쁜초기값 –&gt; 이걸 아담으로!\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-10.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'MSEloss, bad_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화3: BCE, 좋은초기값 –&gt; 이걸 아담으로! (혼자해봐요..)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nloss_fn = torch.nn.BCELoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.05) \n\n\nl1,a1 = net\nl1.bias.data = torch.tensor([-3.0])\nl1.weight.data = torch.tensor([[-1.0]])\n\n\nshow_lrpr2(net,loss_fn,optimizr,'BCEloss, good_init // Adam')\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n시각화4: BCE, 나쁜초기값 –&gt; 이걸 아담으로! (혼자해봐요..)\n(참고) Adam이 우수한 이유? SGD보다 두 가지 측면에서 개선이 있었음. 1. 그런게 있음.. 2. 가속도의 개념을 적용!!"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망로지스틱-회귀의-한계",
    "href": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망로지스틱-회귀의-한계",
    "title": "기계학습 (1005) 5주차",
    "section": "깊은신경망–로지스틱 회귀의 한계",
    "text": "깊은신경망–로지스틱 회귀의 한계\n\n신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다.\n\n\n가짜데이터\n- 위의 기사를 모티브로 한 데이터\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex0.csv')\ndf\n\n\n  \n    \n      \n\n\n\n\n\n\nx\nunderlying\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nplt.plot(df.x,df.y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\n\n로지스틱 회귀로 적합\n\n#nn: netral network?의 약자\n\n\nx= torch.tensor(df.x).float().reshape(-1,1)   #float(): 뒤에 거슬리는거 빼주기\ny= torch.tensor(df.y).float().reshape(-1,1)\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nyhat=net(x)\n\n\nloss_fn = torch.nn.BCELoss() \nloss = loss_fn(yhat,y) # loss = -torch.mean((y)*torch.log(yhat)+(1-y)*torch.log(1-yhat))\nloss\n\ntensor(0.9367, grad_fn=&lt;BinaryCrossEntropyBackward0&gt;)\n\n\n\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'--b')\nplt.plot(x,net(x).data,'--') # 학습전\n\n\n\n\n\nfor epoc in range(6000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'--b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- 이건 epoc=6억번으로 설정해도 못 맞출 것 같다 (증가하다가 감소하는 underlying을 설계하는 것이 불가능) \\(\\to\\) 모형의 표현력이 너무 낮다.\n\n\n해결책\n- sigmoid 넣기 전의 상태가 꺽인 그래프 이어야 한다.\n\nsig = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0');ax[0,1].plot(sig(u1),'--o',color='C0')\nax[1,0].plot(u2,'--o',color='C1');ax[1,1].plot(sig(u2),'--o',color='C1')\nax[2,0].plot(u3,'--o',color='C2');ax[2,1].plot(sig(u3),'--o',color='C2')\nax[3,0].plot(u4,'--o',color='C3');ax[3,1].plot(sig(u4),'--o',color='C3')"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망dnn을-이용한-해결",
    "href": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망dnn을-이용한-해결",
    "title": "기계학습 (1005) 5주차",
    "section": "깊은신경망–DNN을 이용한 해결",
    "text": "깊은신경망–DNN을 이용한 해결\n- 목표: 아래와 같은 벡터 \\({\\boldsymbol u}\\)를 만들어보자.\n\\({\\boldsymbol u} = [u_1,u_2,\\dots,u_{2000}], \\quad u_i = \\begin{cases} 9x_i +4.5& x_i &lt;0 \\\\ -4.5x_i + 4.5& x_i &gt;0 \\end{cases}\\)\n\n꺽인 그래프를 만드는 방법1\n\nu = [9*xi+4.5 if xi &lt;0 else -4.5*xi+4.5 for xi in x.reshape(-1).tolist()]  #tolist하면 list화 \nplt.plot(u,'--')\n\n\n\n\n\n\n꺽인 그래프를 만드는 방법2\n- 전략: 선형변환 \\(\\to\\) ReLU \\(\\to\\) 선형변환\n(예비학습) ReLU 함수란?\n\\(ReLU(x) = \\max(0,x)\\)\n\nrelu=torch.nn.ReLU()\nplt.plot(x,'--r')\nplt.plot(relu(x),'--b')\n\n\n\n\n\n빨간색: x, 파란색: relu(x)\n\n예비학습끝\n우리 전략 다시 확인: 선형변환1 -&gt; 렐루 -&gt; 선형변환2\n(선형변환1)\n\nplt.plot(x);plt.plot(-x)\n\n\n\n\n(렐루)\n\nplt.plot(x,alpha=0.2);plt.plot(-x,alpha=0.5)\nplt.plot(relu(x),'--',color='C0');plt.plot(relu(-x),'--',color='C1')\n\n#out feature을 2로 잡는당-&gt;선을 두개로\n\n\n\n\n(선형변환2)\n\nplt.plot(x,alpha=0.2);plt.plot(-x,alpha=0.2)\nplt.plot(relu(x),'--',color='C0',alpha=0.2);plt.plot(relu(-x),'--',color='C1',alpha=0.2)\nplt.plot(-4.5*relu(x)-9.0*relu(-x)+4.5,'--',color='C2')\n\n#하늘색 점선과 노란색 점섬을 더해보자..\n\n\n\n\n이제 초록색선에 sig를 취하기만 하면?\n\nplt.plot(sig(-4.5*relu(x)-9.0*relu(-x)+4.5),'--',color='C2')\n\n\n\n\n정리하면!\n\nfig = plt.figure(figsize=(8, 4))\nspec = fig.add_gridspec(4, 4)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title('x'); ax1.plot(x,'--',color='C0')\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title('-x'); ax2.plot(-x,'--',color='C1')\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title('relu(x)'); ax3.plot(relu(x),'--',color='C0')\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title('relu(-x)'); ax4.plot(relu(-x),'--',color='C1')\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title('u'); ax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nax6 = fig.add_subplot(spec[1:3,3]); ax6.set_title('yhat'); ax6.plot(sig(-4.5*relu(x)-9*relu(-x)+4.5),'--',color='C2')\nfig.tight_layout()\n\n\n\n\n\n이런느낌으로 \\(\\hat{\\boldsymbol y}\\)을 만들면 된다.\n\n\n\ntorch.nn.Linear()를 이용한 꺽인 그래프 구현\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(in_features=1,out_features=2,bias=True) \na1 = torch.nn.ReLU()\nl2 = torch.nn.Linear(in_features=2,out_features=1,bias=True) \na2 = torch.nn.Sigmoid() \n\n\nnet = torch.nn.Sequential(l1,a1,l2,a2) \n\n\nl1.weight,l1.bias,l2.weight,l2.bias\n\n(Parameter containing:\n tensor([[-0.3467],\n         [-0.8470]], requires_grad=True), Parameter containing:\n tensor([0.3604, 0.9336], requires_grad=True), Parameter containing:\n tensor([[ 0.2880, -0.6282]], requires_grad=True), Parameter containing:\n tensor([0.2304], requires_grad=True))\n\n\n\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0, 0.0])\nl2.weight.data = torch.tensor([[ -4.5, -9.0]])\nl2.bias.data= torch.tensor([4.5])\nl1.weight,l1.bias,l2.weight,l2.bias\n\n(Parameter containing:\n tensor([[ 1.],\n         [-1.]], requires_grad=True), Parameter containing:\n tensor([0., 0.], requires_grad=True), Parameter containing:\n tensor([[-4.5000, -9.0000]], requires_grad=True), Parameter containing:\n tensor([4.5000], requires_grad=True))\n\n\n\nplt.plot(l1(x).data)\n\n\n\n\n\nplt.plot(a1(l1(x)).data)\n\n\n\n\n\nplt.plot(l2(a1(l1(x))).data,color='C2')\n\n\n\n\n\nplt.plot(a2(l2(a1(l1(x)))).data,color='C2')\n#plt.plot(net(x).data,color='C2')\n\n\n\n\n- 수식표현\n\n\\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n\\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n\\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n\\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\\\ =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n\\(net({\\bf X})=(a_2 \\circ l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{sig}\\Big(\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\Big)\\\\=\\begin{bmatrix} \\text{sig}\\Big(-4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5\\Big) \\\\ \\text{sig}\\Big(-4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\Big)\\\\ \\dots \\\\ \\text{sig}\\Big(-4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\Big)\\end{bmatrix}\\)\n\n- 차원만 따지자\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nStep1 ~ Step4\n- 준비\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2), #u1=l1(x), x:(n,1) --&gt; u1:(n,2) \n    torch.nn.ReLU(), # v1=a1(u1), u1:(n,2) --&gt; v1:(n,2) \n    torch.nn.Linear(in_features=2,out_features=1), # u2=l2(v1), v1:(n,2) --&gt; u2:(n,1) \n    torch.nn.Sigmoid() # v2=a2(u2), u2:(n,1) --&gt; v2:(n,1) \n) \n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters()) # lr은 디폴트값으로..\n\n- 반복\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\nplt.title(\"before\")\n\nText(0.5, 1.0, 'before')\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--',color='C1')\nplt.title(\"after 3000 epochs\")\n\nText(0.5, 1.0, 'after 3000 epochs')\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## step1 \n    yhat = net(x) \n    ## step2 \n    loss = loss_fn(yhat,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--',color='C1')\nplt.title(\"after 6000 epochs\")\n\nText(0.5, 1.0, 'after 6000 epochs')"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망dnn으로-해결가능한-다양한-예제",
    "href": "posts/1. DNN/2022_09_28_(5주차)_10월05일_ipynb의_사본.html#깊은신경망dnn으로-해결가능한-다양한-예제",
    "title": "기계학습 (1005) 5주차",
    "section": "깊은신경망–DNN으로 해결가능한 다양한 예제",
    "text": "깊은신경망–DNN으로 해결가능한 다양한 예제\n\n예제1\n- 언뜻 생각하면 방금 배운 기술은 sig를 취하기 전이 꺽은선인 형태만 가능할 듯 하다. \\(\\to\\) 그래서 이 역시 표현력이 부족할 듯 하다. \\(\\to\\) 그런데 생각보다 표현력이 풍부한 편이다. 즉 생각보다 쓸 만하다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex1.csv')\n\n\n# 데이터정리\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\n이거 시그모이드 취하기 직전은 step이 포함된 듯 \\(\\to\\) 그래서 꺽은선으로는 표현할 수 없는 구조임 \\(\\to\\) 그런데 사실 대충은 표현가능\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=16), # x:(n,1) --&gt; u1:(n,16) #최대 16번 꺾일 수 있음..\n    torch.nn.ReLU(), # u1:(n,16) --&gt; v1:(n,16)\n    torch.nn.Linear(in_features=16,out_features=1), # v1:(n,16) --&gt; u2:(n,1) \n    torch.nn.Sigmoid() # u2:(n,1) --&gt; v2:(n,1) \n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,16)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,16)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(6000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()    \n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b') #실제로는 관츷ㄱ 못하는거\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n예제2\n- 사실 꺽은선의 조합으로 꽤 많은걸 표현할 수 있거든요? \\(\\to\\) 심지어 곡선도 대충 맞게 적합된다.\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex2.csv')\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\n\n\n\n\n\nx=torch.tensor(df.x).float().reshape(-1,1)\ny=torch.tensor(df.y).float().reshape(-1,1)\n\n(풀이1)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=32), # x:(n,1) --&gt; u1:(n,32)\n    torch.nn.ReLU(), # u1:(n,32) --&gt; v1:(n,32) \n    torch.nn.Linear(in_features=32,out_features=1) # v1:(n,32) --&gt; u2:(n,1)\n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.MSELoss() #mseloss:마지막에 sigmoid형태가 아니니까!\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(6000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,lw=4) #lw:두겁게\n\n\n\n\n(풀이2) – 풀이1보다 좀 더 잘맞음. 잘 맞는 이유? 좋은초기값 (=운)\n\ntorch.manual_seed(5)  # seed값을 43052-&gt;5로바꿔주기...\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=32), # x:(n,1) --&gt; u1:(n,32)\n    torch.nn.ReLU(), # u1:(n,32) --&gt; v1:(n,32) \n    torch.nn.Linear(in_features=32,out_features=1) # v1:(n,32) --&gt; u2:(n,1)\n)\n\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.MSELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nfor epoc in range(6000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(df.x,df.underlying,'-b')\nplt.plot(x,net(x).data,lw=4)\n\n\n\n\n\n풀이1에서 에폭을 많이 반복하면 풀이2의 적합선이 나올까? –&gt; 안나옴!! (local min에 빠졌다)\n\n\n\n예제3\n\nimport seaborn as sns\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex3.csv')\ndf\n\n\n\n\n\n\n\n\nx1\nx2\ny\n\n\n\n\n0\n-0.874139\n0.210035\n0.0\n\n\n1\n-1.143622\n-0.835728\n1.0\n\n\n2\n-0.383906\n-0.027954\n0.0\n\n\n3\n2.131652\n0.748879\n1.0\n\n\n4\n2.411805\n0.925588\n1.0\n\n\n...\n...\n...\n...\n\n\n1995\n-0.002797\n-0.040410\n0.0\n\n\n1996\n-1.003506\n1.182736\n0.0\n\n\n1997\n1.388121\n0.079317\n0.0\n\n\n1998\n0.080463\n0.816024\n1.0\n\n\n1999\n-0.416859\n0.067907\n0.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nsns.scatterplot(data=df,x='x1',y='x2',hue='y',alpha=0.5,palette={0:(0.5, 0.0, 1.0),1:(1.0,0.0,0.0)})\n\n&lt;AxesSubplot:xlabel='x1', ylabel='x2'&gt;\n\n\n\n\n\n\n# 데이터준비\nx1 = torch.tensor(df.x1).float().reshape(-1,1) \nx2 = torch.tensor(df.x2).float().reshape(-1,1) \nX = torch.concat([x1,x2],axis=1) \ny = torch.tensor(df.y).float().reshape(-1,1) \n\n\nX.shape\n\ntorch.Size([2000, 2])\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2,out_features=32),#X의 shape이 2니까 in_features=2\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid()\n)\n\n\n\\(\\underset{(n,2)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss() \n\n\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(3000):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\ndf2 = df.assign(yhat=yhat.reshape(-1).detach().tolist()) #seaborn을 그리려먼 dataframe형식으로 되어잇어야해\ndf2\n\n\n\n\n\n\n\n\nx1\nx2\ny\nyhat\n\n\n\n\n0\n-0.874139\n0.210035\n0.0\n0.345833\n\n\n1\n-1.143622\n-0.835728\n1.0\n0.605130\n\n\n2\n-0.383906\n-0.027954\n0.0\n0.111915\n\n\n3\n2.131652\n0.748879\n1.0\n0.918491\n\n\n4\n2.411805\n0.925588\n1.0\n0.912608\n\n\n...\n...\n...\n...\n...\n\n\n1995\n-0.002797\n-0.040410\n0.0\n0.254190\n\n\n1996\n-1.003506\n1.182736\n0.0\n0.508002\n\n\n1997\n1.388121\n0.079317\n0.0\n0.410099\n\n\n1998\n0.080463\n0.816024\n1.0\n0.262315\n\n\n1999\n-0.416859\n0.067907\n0.0\n0.107903\n\n\n\n\n2000 rows × 4 columns\n\n\n\n\nsns.scatterplot(data=df2,x='x1',y='x2',hue='yhat',alpha=0.5,palette='rainbow')\n\n&lt;AxesSubplot:xlabel='x1', ylabel='x2'&gt;\n\n\n\n\n\n- 결과시각화\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nsns.scatterplot(data=df,x='x1',y='x2',hue='y',alpha=0.5,palette={0:(0.5, 0.0, 1.0),1:(1.0,0.0,0.0)},ax=ax[0])\nsns.scatterplot(data=df2,x='x1',y='x2',hue='yhat',alpha=0.5,palette='rainbow',ax=ax[1])\n\n&lt;AxesSubplot:xlabel='x1', ylabel='x2'&gt;\n\n\n\n\n\n- 교훈: underlying이 엄청 이상해보여도 생각보다 잘 맞춤"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html",
    "title": "기계학습 (0928) 4주차",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt \nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#imports",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#imports",
    "title": "기계학습 (0928) 4주차",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt \nimport pandas as pd\nimport torch"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#numpy-torch-선택학습",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#numpy-torch-선택학습",
    "title": "기계학습 (0928) 4주차",
    "section": "numpy, torch (선택학습)",
    "text": "numpy, torch (선택학습)\n\nnumpy, torch는 엄청 비슷해요\n- torch.tensor() = np.array() 처럼 생각해도 무방\n\nnp.array([1,2,3]), torch.tensor([1,2,3])\n\n(array([1, 2, 3]), tensor([1, 2, 3]))\n\n\n- 소수점의 정밀도에서 차이가 있음 (torch가 좀 더 쪼잔함)\n\nnp.array([3.123456789])\n\narray([3.12345679])\n\n\n\ntorch.tensor([3.123456789]) #GPU메모리에 저장해서 \n\ntensor([3.1235])\n\n\n- 기본적인 numpy 문법은 np 대신에 torch를 써도 무방 // 완전 같지는 않음\n\nnp.arange(10), torch.arange(10)\n\n(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n\n\n\nnp.linspace(0,1,10), torch.linspace(0,1,10)\n\n(array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n        0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]),\n tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n         1.0000]))\n\n\n\nnp.random.randn(10)\n\narray([ 0.68732684, -0.53367188,  0.27916096,  0.28236708,  0.03800702,\n       -0.66236923,  1.32472364, -0.11671166, -0.77019834, -1.14755872])\n\n\n\ntorch.randn(10)\n\ntensor([ 0.8525,  0.2257,  0.3406, -0.4713,  1.5393, -2.0060, -0.4257,  3.0482,\n        -0.7659,  0.3265])\n\n\n\n\nlength \\(n\\) vector, \\(n \\times 1\\) col-vector, \\(1 \\times n\\) row-vector\n- 길이가 3인 벡터 선언방법\n\na = torch.tensor([1,2,3])\na.shape\n\ntorch.Size([3])\n\n\n- 3x1 col-vec 선언방법\n(방법1)\n\na = torch.tensor([[1],[2],[3]])\na.shape\n\ntorch.Size([3, 1])\n\n\n(방법2)\n\na = torch.tensor([1,2,3]).reshape(3,1)\na.shape\n\ntorch.Size([3, 1])\n\n\n- 1x3 row-vec 선언방법\n(방법1)\n\na = torch.tensor([[1,2,3]])\na.shape\n\ntorch.Size([1, 3])\n\n\n(방법2)\n\na = torch.tensor([1,2,3]).reshape(1,3)\na.shape\n\ntorch.Size([1, 3])\n\n\n- 3x1 col-vec 선언방법, 1x3 row-vec 선언방법에서 [[1],[2],[3]] 혹은 [[1,2,3]] 와 같은 표현이 이해안되면 아래링크로 가셔서\nhttps://guebin.github.io/STBDA2022/2022/03/14/(2주차)-3월14일.html\n첫번째 동영상 12:15 - 22:45 에 해당하는 분량을 학습하시길 바랍니다.\n\n\ntorch의 dtype\n- 기본적으로 torch는 소수점으로 저장되면 dtype=torch.float32 가 된다. (이걸로 맞추는게 편리함)\n\ntsr = torch.tensor([1.23,2.34])\ntsr\n\ntensor([1.2300, 2.3400])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n\n#float64보다 데이터를 적게 쓴다는 뜻-&gt; float32\n\n- 정수로 선언하더라도 dtype를 torch.float32로 바꾸는게 유리함\n(안 좋은 선언예시)\n\ntsr = torch.tensor([1,2])\ntsr \n\ntensor([1, 2])\n\n\n\ntsr.dtype\n\ntorch.int64\n\n\n(좋은 선언예시1)\n\ntsr = torch.tensor([1,2],dtype=torch.float32)\ntsr \n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n(좋은 선언예시2)\n\ntsr = torch.tensor([1,2.0])\ntsr \n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n(사실 int로 선언해도 나중에 float으로 바꾸면 큰 문제없음)\n\ntsr = torch.tensor([1,2]).float()\ntsr\n\ntensor([1., 2.])\n\n\n\ntsr.dtype\n\ntorch.float32\n\n\n- 왜 정수만으로 torch.tensor를 만들때에도 torch.float32로 바꾸는게 유리할까? \\(\\to\\) torch.tensor끼리의 연산에서 문제가 될 수 있음\n별 문제 없을수도 있지만\n\ntorch.tensor([1,2])-torch.tensor([1.0,2.0]) \n\ntensor([0., 0.])\n\n\n아래와 같이 에러가 날수도 있다\n(에러1)\n\ntorch.tensor([[1.0,0.0],[0.0,1.0]]) @ torch.tensor([[1],[2]]) \n\nRuntimeError: expected scalar type Float but found Long\n\n\n(에러2)\n\ntorch.tensor([[1,0],[0,1]]) @ torch.tensor([[1.0],[2.0]])\n\nRuntimeError: expected scalar type Long but found Float\n\n\n(해결1) 둘다 정수로 통일\n\ntorch.tensor([[1,0],[0,1]]) @ torch.tensor([[1],[2]])\n\ntensor([[1],\n        [2]])\n\n\n(해결2) 둘다 소수로 통일 &lt;– 더 좋은 방법임\n\ntorch.tensor([[1.0,0.0],[0.0,1.0]]) @ torch.tensor([[1.0],[2.0]])\n\ntensor([[1.],\n        [2.]])\n\n\n\n\nshape of vector\n- 행렬곱셈에 대한 shape 조심\n\nA = torch.tensor([[2.00,0.00],[0.00,3.00]]) \nb1 = torch.tensor([[-1.0,-5.0]])\nb2 = torch.tensor([[-1.0],[-5.0]])\nb3 = torch.tensor([-1.0,-5.0])\n\n\nA.shape,b1.shape,b2.shape,b3.shape\n\n(torch.Size([2, 2]), torch.Size([1, 2]), torch.Size([2, 1]), torch.Size([2]))\n\n\n- A@b1: 계산불가, b1@A: 계산가능\n\nA@b1 #행렬계산이라고 생각\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x2 and 1x2)\n\n\n\nb1@A\n\ntensor([[ -2., -15.]])\n\n\n- A@b2: 계산가능, b2@A: 계산불가\n\nA@b2\n\ntensor([[ -2.],\n        [-15.]])\n\n\n\nb2@A\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (2x1 and 2x2)\n\n\n- A@b3: 계산가능, b3@A: 계산가능\n\n(A@b3).shape ## b3를 마치 col-vec 처럼 해석\n\ntorch.Size([2])\n\n\n\n(b3@A).shape ## b3를 마지 row-vec 처럼 해석\n\ntorch.Size([2])\n\n\n- 브로드캐스팅\n\na = torch.tensor([1,2,3]) #a는 길이가 3인 벡터지만... 연산이 된다.\na - 1\n\ntensor([0, 1, 2])\n\n\n\nb = torch.tensor([[1],[2],[3]]) #b는 컬럼 벡터\nb - 1\n\ntensor([[0],\n        [1],\n        [2]])\n\n\n\na - b # a를 row-vec 로 해석 \n#불필요한 오류를 막기 위해서 dimension잘 써놓기\n\ntensor([[ 0,  1,  2],\n        [-1,  0,  1],\n        [-2, -1,  0]])"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#review-step14",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#review-step14",
    "title": "기계학습 (0928) 4주차",
    "section": "Review: step1~4",
    "text": "Review: step1~4\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-22-regression.csv\") \ndf\n\n\n  \n    \n      \n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-2.482113\n-8.542024\n\n\n1\n-2.362146\n-6.576713\n\n\n2\n-1.997295\n-5.949576\n\n\n3\n-1.623936\n-4.479364\n\n\n4\n-1.479192\n-4.251570\n\n\n...\n...\n...\n\n\n95\n2.244400\n10.325987\n\n\n96\n2.393501\n12.266493\n\n\n97\n2.605604\n13.098280\n\n\n98\n2.605658\n12.546793\n\n\n99\n2.663240\n13.834002\n\n\n\n\n100 rows × 2 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ntorch.tensor(df.x)\n#dtype=float32로 지정하면 밑에 dtype=torch.float64가 안붙는다. 메모리를 아끼기위해서 데이터타입을 float32로바꾼다리\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632], dtype=torch.float64)\n\n\n\nx= torch.tensor(df.x,dtype=torch.float32).reshape(100,1)   \ny= torch.tensor(df.y,dtype=torch.float32).reshape(100,1)\n\n# _1 = torch.ones([100,1])\n# X = torch.concat([_1,x]),axis=1\n\nX= torch.tensor([[1]*100,x]).T    #torch.ones([100,1])로 써도 됨\n\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True) # 아무 점이나 주어보자! (-5,10)\n\n\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\n#plt.plot(x,-5+10*x,'--')\nplt.plot(x,X@What.data,'--')\n\n\n\n\n\nver1: loss = sum of squares error\n\nalpha = 1/1000    #학습하는과정에 대한 분류 4가지\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분 \n    loss.backward()\n    # step4: update \n  #  What.data = What.data - 1/000 * What.grad   # alpha = 1/000\n  #  What.grad = None #              # gradient청소...\n\n    What.data = What.data - alpha * What.grad \n    What.grad = None # \n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o') \nplt.plot(x,X@What.data,'--')\n\n\n\n\n\nnote: 왜 What = What - alpha*What.grad 는 안되는지?\n\n\n\nver2: loss = mean squared error = MSE\n\nalpha = 1/10\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nfor epoc in range(30): \n    # step1: yhat \n    yhat = X@What \n    # step2: loss \n    loss = torch.mean((y-yhat)**2)   # 위랑 다른거 여기 mean!!!! \n    # step3: 미분 \n    loss.backward()\n    # step4: update \n    What.data = What.data - alpha * What.grad \n    What.grad = None # \n\n    # mean으로 하면 좋은거: 100개읟 ㅔ이터 1/1000 학습률 \n    # sample size가 달라질때마다 학습률 설정이 힘든데, mean으로 하면 데이터set이 계속 할수잇어서!!\n\n\nWhat\n\ntensor([[2.4290],\n        [4.0144]], requires_grad=True)"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step1의-다른버전-net-설계만",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step1의-다른버전-net-설계만",
    "title": "기계학습 (0928) 4주차",
    "section": "step1의 다른버전 – net 설계만",
    "text": "step1의 다른버전 – net 설계만\n\nver1: net = torch.nn.Linear(1,1,bias=True)\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1, out_features=1, bias=True)  # 함수를 만들어준다. x가들어가면 y가 나오는 것 가틍ㄴ..\n\n# x.shape 했을때 torch.size(100,1) 이 나온다. 100은 observation이고 뒤쪽에 있는 1이 in_features!!\n# out_features는 y.shape의 뒤쪽,,\n\n# net.bias, net.weight 하면 tensor 0.2366 -&gt; w0역할... tensor -0.8791 -&gt; w1역할 \n# 위 숫자는 최초의 숫자라 아무거나 찍은거 실행할때마다 달라질수 있음.\n# 맨 위에 seed를 주면 나중에 교수님 강의할때 편하게` 하려고 \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- net에서 \\(\\hat{w}_0, \\hat{w}_1\\) 의 값은?\n\nnet.weight # w1 \n\nParameter containing:\ntensor([[-0.3467]], requires_grad=True)\n\n\n\nnet.bias # w0 \n\nParameter containing:\ntensor([-0.8470], requires_grad=True)\n\n\n\n_yhat = -0.8470 + -0.3467*x \n\n\nplt.plot(x,y,'o')\nplt.plot(x, _yhat,'--')\nplt.plot(x,net(x).data,'-.')\n\n\n\n\n- 수식표현: \\(\\hat{y}_i = \\hat{w}_0 + \\hat{w}_1 x_i = \\hat{b} + \\hat{w}x_i = -0.8470 + -0.3467 x_i\\) for all \\(i=1,2,\\dots,100\\).\n\n\nver2: net = torch.nn.Linear(2,1,bias=False)\n- 입력이 x가 아닌 X를 넣고 싶다면? (보통 잘 안하긴 해요, 왜? bias=False로 주는게 귀찮거든요) - X는 바이어스가 고려된 상황\n\nnet(X) ## 그대로 쓰면 당연히 에러\n\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (100x2 and 1x1)\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2, out_features=1, bias=False) #bias=false:뒤쪽에 더해지는 값인거 같으니까....\n\n# out_features=3으로 쓰면 shape이 [100,3] 된다,,,,,,,,,,, 1이 되야해,,\n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n\nnet.bias # false로 설정해서 아무것도 안뜸\n\n\nplt.plot(x,y,'o') \nplt.plot(x,net(X).data, '--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]]), '-.')\n\n\n\n\n- 수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} = \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix}\\)\n\n\n잘못된사용1\n\n_x = x.reshape(-1)\n\n\n_x\n\ntensor([-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632])\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=1,out_features=1) \n\n\nnet(_x) #이렇게 하면 에러메시지뜬다리 \n# net(_x.reshape(100,1))로 바궈줘야 한다.\n\nRuntimeError: size mismatch, got 1, 1x1,100\n\n\n\n\n잘못된사용2\n\ntorch.manual_seed(43052)\nnet = torch.nn.Linear(in_features=2,out_features=1) # bias=False를 깜빡.. bias=true로 설정됨 기본으로 \n\n\nnet.weight\n\nParameter containing:\ntensor([[-0.2451, -0.5989]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.2549], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]])+0.2549,'-.')\n# b hat = 0.2549 의도와는 다르게 모델링 된것..\n\n\n# plt.plot(x,X@torch.tensor([[-0.2451],[-0.5989]]),'-.')\n# bias=f일때\n\n\n\n\n\n수식표현: \\(\\hat{\\bf y} = {\\bf X} {\\bf \\hat W} + \\hat{b}= \\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots & \\dots \\\\ 1 & x_{100} \\end{bmatrix} \\begin{bmatrix} -0.2451 \\\\ -0.5989 \\end{bmatrix} + 0.2549\\)"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step1의-다른버전-끝까지",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step1의-다른버전-끝까지",
    "title": "기계학습 (0928) 4주차",
    "section": "step1의 다른버전 – 끝까지",
    "text": "step1의 다른버전 – 끝까지\n\nver1: net = torch.nn.Linear(1,1,bias=True)\n- 준비\n\nnet = torch.nn.Linear(1,1,bias=True) # in_features=1 에서 1만 써도 뎀, bias 생략해도 뎀\nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([-5.0])\nnet.weight,net.bias\n\n(Parameter containing:\n tensor([[10.]], requires_grad=True),\n Parameter containing:\n tensor([-5.], requires_grad=True))\n\n\n- step1\n\nyhat = net(x)  # -5 + 10x 가 첫 값으로 나올것,,,\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n- step2\n\nloss = torch.mean((y-yhat)**2)\n\n- step3\n(미분전)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad   #grad값이 없는데.... \n\n(None, None)\n\n\n(미분)\n\nloss.backward()\n\n(미분후)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad,net.weight.grad    # 미분후에 값 자체는 변화가 없지만 grad값이 \n\n(tensor([-13.4225]), tensor([[11.8893]]))\n\n\n- step4\n(업데이트전)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-5.], requires_grad=True),\n Parameter containing:\n tensor([[10.]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(tensor([-13.4225]), tensor([[11.8893]]))\n\n\n(업데이트)\n\nnet.bias.data = net.bias.data - 0.1*net.bias.grad   # 기울기 0.1\nnet.weight.data = net.weight.data - 0.1*net.weight.grad \n\n\nnet.bias.grad = None  # 바뀌기만 하고 청소가 안된상태ㅣ니까 none값으로 지정해주기...\nnet.weight.grad = None \n\n(업데이트후)\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([-3.6577], requires_grad=True),\n Parameter containing:\n tensor([[8.8111]], requires_grad=True))\n\n\n\nnet.bias.grad, net.weight.grad\n\n(None, None)\n\n\n- 반복\n\nfor epoc in range(30):\n    # step1\n    yhat = net(x) \n    # step2\n    loss = torch.mean((y-yhat)**2)\n    # step3\n    loss.backward()\n    # step4\n    net.weight.data = net.weight.data - 0.1*net.weight.grad\n    net.bias.data = net.bias.data - 0.1*net.bias.grad\n    net.weight.grad = None\n    net.bias.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nver2: net = torch.nn.Linear(2,1,bias=False)\n- 준비\n\nnet = torch.nn.Linear(2,1,bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\n\n- step1\n\nyhat = net(X)\n\n- step2\n\nloss = torch.mean((y-yhat)**2)\n\n- step3\n(미분전)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\n(미분)\n\nloss.backward()\n\n(미분후)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\ntensor([[-13.4225,  11.8893]])\n\n\n- step4\n(업데이트전)\n\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet.weight.grad\n\ntensor([[-13.4225,  11.8893]])\n\n\n(업데이트)\n\nnet.weight.data = net.weight.data - 0.1*net.weight.grad\n\n\nnet.weight.grad = None\n\n(업데이트후)\n\nnet.weight\n\nParameter containing:\ntensor([[-3.6577,  8.8111]], requires_grad=True)\n\n\n\nnet.weight.grad\n\n- 반복\n\nnet = torch.nn.Linear(2,1,bias=False)\nnet.weight.data = torch.tensor([[-5.0, 10.0]])\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    # step1\n    yhat = net(X)\n    # step2 \n    loss = torch.mean((y-yhat)**2)\n    # step3\n    loss.backward()\n    # step4\n    net.weight.data = net.weight.data - 0.1*net.weight.grad\n    net.weight.grad = None\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step4의-다른버전-옵티마이저",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#step4의-다른버전-옵티마이저",
    "title": "기계학습 (0928) 4주차",
    "section": "step4의 다른버전: 옵티마이저!",
    "text": "step4의 다른버전: 옵티마이저!\n\nver1: net = torch.nn.Linear(1,1,bias=True)\n- 준비\n\nnet = torch.nn.Linear(1,1) \nnet.weight.data = torch.tensor([[10.0]]) \nnet.bias.data = torch.tensor([[-5.0]]) \n\n\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) # step4가 너무 귀찮기 때문에 net파라미터를 받아서 업데이트하고 청소해주는 오브젝트를 하나 만들기\n# optim.SGD(parameter, lr(alpha)=0.1)\n# net.parameters() = generator 어쩌고 튀어나오는데 이거 넣어주기 \n\n- step1~3\n\nyhat = net(x)     \n\n\nloss = torch.mean((y-yhat)**2) \n\n\nloss.backward() \n\n- step4\n(update 전)\n\nnet.weight.data, net.bias.data ## 값은 업데이트 전\n\n(tensor([[10.]]), tensor([[-5.]]))\n\n\n\nnet.weight.grad, net.bias.grad ## 미분값은 청소전 \n\n(tensor([[11.8893]]), tensor([[-13.4225]]))\n\n\n(update)\n\noptimizr.step()  # update 진행해줌\noptimizr.zero_grad() # grad값 청소\n\n(update 후)\n\nnet.weight.data, net.bias.data ## 값은 업데이트 되었음 \n\n(tensor([[8.8111]]), tensor([[-3.6577]]))\n\n\n\nnet.weight.grad, net.bias.grad ## 미분값은 0으로 초기화하였음 \n\n(tensor([[0.]]), tensor([[0.]]))\n\n\n- 반복\n\nnet = torch.nn.Linear(1,1) \nnet.weight.data = torch.tensor([[10.0]])\nnet.bias.data = torch.tensor([-5.0])\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\nfor epoc in range(30): \n    # step1\n    yhat = net(x)\n    # step2\n    loss = torch.mean((y-yhat)**2) \n    # step3\n    loss.backward()\n    # step4 \n    optimizr.step(); optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\nver2: net = torch.nn.Linear(2,1,bias=False)\n- 바로 반복하겠습니다..\n\nnet = torch.nn.Linear(2,1,bias=False) \nnet.weight.data = torch.tensor([[-5.0, 10.0]])\noptimizr = torch.optim.SGD(net.parameters(),lr=1/10) \n\n\nfor epoc in range(30): \n    yhat = net(X)              # ver1에서는 스몰x였는데 여기서는 라지X\n    loss = torch.mean((y-yhat)**2) \n    loss.backward() \n    optimizr.step(); optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#appendix-net.parameters의-의미-선택학습",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#appendix-net.parameters의-의미-선택학습",
    "title": "기계학습 (0928) 4주차",
    "section": "Appendix: net.parameters()의 의미? (선택학습)",
    "text": "Appendix: net.parameters()의 의미? (선택학습)\n- iterator, generator의 개념필요 - https://guebin.github.io/IP2022/2022/06/06/(14주차)-6월6일.html, 클래스공부 8단계 참고\n- 탐구시작: 네트워크 생성\n\nnet = torch.nn.Linear(in_features=1,out_features=1)\nnet.weight\n\nParameter containing:\ntensor([[-0.1656]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.8529], requires_grad=True)\n\n\n- torch.optim.SGD? 를 확인하면 params에 대한설명에 아래와 같이 되어있음\nparams (iterable): iterable of parameters to optimize or dicts defining\n        parameter groups\n- 설명을 읽어보면 params에 iterable object를 넣으라고 되어있음 (iterable object는 숨겨진 명령어로 __iter__를 가지고 있는 오브젝트를 의미)\n\nset(dir(net.parameters)) & {'__iter__'}\n\nset()\n\n\n\nset(dir(net.parameters())) & {'__iter__'}\n\n{'__iter__'}\n\n\n- 무슨의미?\n\n_generator = net.parameters()\n\n\n_generator.__next__()\n\nParameter containing:\ntensor([[-0.1656]], requires_grad=True)\n\n\n\n_generator.__next__()\n\nParameter containing:\ntensor([0.8529], requires_grad=True)\n\n\n\n_generator.__next__()\n\nStopIteration: \n\n\n- 이건 이런느낌인데?\n\n_generator2 = iter([net.weight,net.bias])\n\n\n_generator2\n\n&lt;list_iterator at 0x7efce86d5dd0&gt;\n\n\n\n_generator2.__next__()\n\nParameter containing:\ntensor([[-0.1656]], requires_grad=True)\n\n\n\n_generator2.__next__()\n\nParameter containing:\ntensor([0.8529], requires_grad=True)\n\n\n\n_generator2.__next__()\n\nStopIteration: \n\n\n- 즉 아래는 같은코드이다.\n### 코드1\n_generator = net.parameters() \ntorch.optim.SGD(_generator,lr=1/10) \n### 코드2\n_generator = iter([net.weight,net.bias])\ntorch.optim.SGD(_generator,lr=1/10) \n### 코드3 (이렇게 써도 코드2가 실행된다고 이해할 수 있음)\n_iterator = [net.weight,net.bias]\ntorch.optim.SGD(_iterator,lr=1/10) \n결론: net.parameters()는 net오브젝트에서 학습할 파라메터를 모두 모아 리스트(iterable object)로 만드는 함수라 이해할 수 있다.\n- 응용예제1\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\noptimizr = torch.optim.SGD([What],lr=1/10) \n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    yhat = X@What \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    optimizr.step();optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n- 응용예제2\n\nb = torch.tensor(-5.0,requires_grad=True)\nw = torch.tensor(10.0,requires_grad=True)\noptimizr = torch.optim.SGD([b,w],lr=1/10)\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    yhat = b+ w*x \n    loss = torch.mean((y-yhat)**2)\n    loss.backward()\n    optimizr.step(); optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')"
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#logistic-regression",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#logistic-regression",
    "title": "기계학습 (0928) 4주차",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nmotive\n- 현실에서 이런 경우가 많음 - \\(x\\)가 커질수록 (혹은 작아질수록) 성공확률이 증가함.\n\n# EX) x는 학점이고.. y는 취업할 확률\n\n- (X,y)는 어떤모양?\n\n_df = pd.DataFrame({'x':range(-6,7),'y':[0,0,0,0,0,0,1,0,1,1,1,1,1]})\n_df \n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n-6\n0\n\n\n1\n-5\n0\n\n\n2\n-4\n0\n\n\n3\n-3\n0\n\n\n4\n-2\n0\n\n\n5\n-1\n0\n\n\n6\n0\n1\n\n\n7\n1\n0\n\n\n8\n2\n1\n\n\n9\n3\n1\n\n\n10\n4\n1\n\n\n11\n5\n1\n\n\n12\n6\n1\n\n\n\n\n\n\n\n\nplt.plot(_df.x,_df.y,'o')\n\n\n\n\n- (예비학습) 시그모이드라는 함수가 있음\n\nxx = torch.linspace(-6,6,100)   # -6에서 6까지 100개..\ndef f(x):\n    return torch.exp(x)/(1+torch.exp(x))  \n\n\nplt.plot(_df.x,_df.y,'o')\nplt.plot(xx,f(xx))   # f(xx) = f(1*xx) 얌.. 근데 만약 f(5*xx)하면 기울기가 더 급해져.. 애매한 부분이 더 적어지고 스펙에 대한 영향을 ... f(2.5*xx)-1.2 (우측으로 1.2 이동) 이렇게 튜닝이 가능\n\n\n\n\n\n\nmodel\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n$y_i Ber(_i),$ where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) &lt;— 외우세요!!\n\n\n# 베르누이.. pi i 라는 건.. 왜 p가 아니고 pi냐? 사람마다 합격할 확률이 다르기 때문에.\n# x가 무한대로 가면 pi i 는 1에 가까워지고 마이너스 무한대로 가면 0에가까워진다\n\n# loss는 MSE로 하긴 어렵고,, 라이클리우드?????????? 설명이기니까 위에 그냥 외우기\n# y i = 0 일대랑 1 일때 저식에 넣어서 그래프 그려서 생각해보기... loss는 yi랑 y값이 비슷하면 loss 값이 작아짐\n\n\n\ntoy example\n- 예제시작\n\nx=torch.linspace(-1,1,2000).reshape(2000,1)\nw0= -1 \nw1= 5 \nu = w0+x*w1 \nv = torch.exp(u)/(1+torch.exp(u)) # v=πi, 즉 확률을 의미함,  v는 성공할확률\ny = torch.bernoulli(v) \n\n# torch.bernoulli(toch.tensor([0.5]*100))   0,1 반복해서 뽑힘. 0.5는 확률!!!!!\n\n\nplt.scatter(x,y,alpha=0.05)   # 여기서 알파가 투명도인듯??????????? \nplt.plot(x,v,'--r')\n\n\n\n\n\n우리의 목적: \\(x\\)가 들어가면 빨간선 \\(\\hat{y}\\)의 값을 만들어주는 mapping을 학습해보자.\n\n\n# 최초의 곡선\n# w0hat = -1\n# w1hat = 3\n\n\n# yhat = f(w0hat+x*w1hat)\n# plt.plot(x,y, 'o', alpha=0.05)   \n# plt.plot(x,v,'--')\n# plt.plot(x,yhat,'--r')\n\nSyntaxError: ignored\n\n\n\n# sigmoid함수만들엇던걸..............."
  },
  {
    "objectID": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#숙제",
    "href": "posts/1. DNN/2022_09_28_(4주차)_9월 28일__ipynb의_사본.html#숙제",
    "title": "기계학습 (0928) 4주차",
    "section": "숙제",
    "text": "숙제"
  },
  {
    "objectID": "posts/(202250926)기계학습특강_final (2).html",
    "href": "posts/(202250926)기계학습특강_final (2).html",
    "title": "기계학습 final",
    "section": "",
    "text": "기계학습특강 기말고사\n\nimport torch \nfrom fastai.text.all import *\n\n\ndf = pd.read_csv('/content/Corona_NLP_train.csv',encoding=\"ISO-8859-1\")\ndf\n\n\n  \n    \n      \n\n\n\n\n\n\nUserName\nScreenName\nLocation\nTweetAt\nOriginalTweet\nSentiment\n\n\n\n\n0\n3799\n48751\nLondon\n16-03-2020\n@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\nNeutral\n\n\n1\n3800\n48752\nUK\n16-03-2020\nadvice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\nPositive\n\n\n2\n3801\n48753\nVagabonds\n16-03-2020\nCoronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\nPositive\n\n\n3\n3802\n48754\nNaN\n16-03-2020\nMy food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\nPositive\n\n\n4\n3803\n48755\nNaN\n16-03-2020\nMe, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\nExtremely Negative\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n41152\n44951\n89903\nWellington City, New Zealand\n14-04-2020\nAirline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp\nNeutral\n\n\n41153\n44952\n89904\nNaN\n14-04-2020\nResponse to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?\nExtremely Negative\n\n\n41154\n44953\n89905\nNaN\n14-04-2020\nYou know itÂ’s getting tough when @KameronWilds is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!\nPositive\n\n\n41155\n44954\n89906\nNaN\n14-04-2020\nIs it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus\nNeutral\n\n\n41156\n44955\n89907\ni love you so much || he/him\n14-04-2020\n@TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe\nNegative\n\n\n\n\n41157 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n# 텍스트 분석\n# 1단계 : TextDataLoaders\n# 2단계 : language_model_learner()\n# 3단계 : lrnr.fit()\n# 4단계 : lrnr.predict()\n\ndf = pd.read_csv('Corona_NLP_train.csv',encoding=\"ISO-8859-1\")\ndf\n\n\n  \n    \n      \n\n\n\n\n\n\nUserName\nScreenName\nLocation\nTweetAt\nOriginalTweet\nSentiment\n\n\n\n\n0\n3799\n48751\nLondon\n16-03-2020\n@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\nNeutral\n\n\n1\n3800\n48752\nUK\n16-03-2020\nadvice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\nPositive\n\n\n2\n3801\n48753\nVagabonds\n16-03-2020\nCoronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\nPositive\n\n\n3\n3802\n48754\nNaN\n16-03-2020\nMy food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\nPositive\n\n\n4\n3803\n48755\nNaN\n16-03-2020\nMe, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\nExtremely Negative\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n41152\n44951\n89903\nWellington City, New Zealand\n14-04-2020\nAirline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp\nNeutral\n\n\n41153\n44952\n89904\nNaN\n14-04-2020\nResponse to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?\nExtremely Negative\n\n\n41154\n44953\n89905\nNaN\n14-04-2020\nYou know itÂ’s getting tough when @KameronWilds is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!\nPositive\n\n\n41155\n44954\n89906\nNaN\n14-04-2020\nIs it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus\nNeutral\n\n\n41156\n44955\n89907\ni love you so much || he/him\n14-04-2020\n@TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe\nNegative\n\n\n\n\n41157 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nTextDataLoaders?\n\n\ndls = TextDataLoaders.from_df(df,text_col='OriginalTweet',is_lm=True, seq_len=64)\n\n\n\n\n\n\n\n\n\ndls.show_batch()\n\n\n\n\n\ntext\ntext_\n\n\n\n\n0\nxxbos xxmaj japanese symbol for xxunk xxmaj germany at supermarket xxmaj edeka the will teach you how to appropriately social distance and give you shit when you don t xxbos xxup tp xxmaj shortages ? ? ! ? ! xxmaj not us we are fully stocked and you can help a great cause ? \\r\\r\\n https : / / t.co / xxunk \\r\\r\\n .\nxxmaj japanese symbol for xxunk xxmaj germany at supermarket xxmaj edeka the will teach you how to appropriately social distance and give you shit when you don t xxbos xxup tp xxmaj shortages ? ? ! ? ! xxmaj not us we are fully stocked and you can help a great cause ? \\r\\r\\n https : / / t.co / xxunk \\r\\r\\n . \\r\\r\\n\n\n\n1\n, when there was shortage of food and # xxmaj corona at its peak ? xxbos xxmaj consider donating to a local shelter if you have the means … xxunk was today 's pick for me ! xxmaj they are also always looking for retailer gift cards if that suits you better . xxmaj they would love the extra support as they work to\nwhen there was shortage of food and # xxmaj corona at its peak ? xxbos xxmaj consider donating to a local shelter if you have the means … xxunk was today 's pick for me ! xxmaj they are also always looking for retailer gift cards if that suits you better . xxmaj they would love the extra support as they work to combat\n\n\n2\na little xxmaj wednesday humor for you . \\r\\r\\n\\r\\r\\n▁ # coronavirus # toiletpaper # xxunk # xxunk # xxmaj satire # humor # xxunk https : / / t.co / xxunk xxbos xxmaj so a friend of mine at a division of has to supply her own gloves and safety equipment xxmaj grocery store workers deserve hazard pay and the means to protect themselves\nlittle xxmaj wednesday humor for you . \\r\\r\\n\\r\\r\\n▁ # coronavirus # toiletpaper # xxunk # xxunk # xxmaj satire # humor # xxunk https : / / t.co / xxunk xxbos xxmaj so a friend of mine at a division of has to supply her own gloves and safety equipment xxmaj grocery store workers deserve hazard pay and the means to protect themselves from\n\n\n3\nhttps : / / t.co / xxunk xxbos xxmaj as a former supermarket fairy , i think itâ’s about time all of the food shop workers get some credit . xxmaj theyâ’re always looked down on as xxunk working in a xxunk but theyâ’re working hard to put the stock on the shelves that everyone is panic buying every day ! ? ? #\n: / / t.co / xxunk xxbos xxmaj as a former supermarket fairy , i think itâ’s about time all of the food shop workers get some credit . xxmaj theyâ’re always looked down on as xxunk working in a xxunk but theyâ’re working hard to put the stock on the shelves that everyone is panic buying every day ! ? ? # coronavirus\n\n\n4\ncare home staff xxmaj care at home teams xxmaj volunteers xxmaj call help lines xxmaj supermarket workers xxmaj xxunk transport teams xxmaj social xxmaj xxunk xxmaj thank xxmaj you 19uk xxbos \" the real risk now is that the xxmaj government sets terms to pay so xxunk that it brings mass social unrest . \" \\r\\r\\n\\r\\r\\n xxmaj the xxmaj government has never spent more\nhome staff xxmaj care at home teams xxmaj volunteers xxmaj call help lines xxmaj supermarket workers xxmaj xxunk transport teams xxmaj social xxmaj xxunk xxmaj thank xxmaj you 19uk xxbos \" the real risk now is that the xxmaj government sets terms to pay so xxunk that it brings mass social unrest . \" \\r\\r\\n\\r\\r\\n xxmaj the xxmaj government has never spent more in\n\n\n5\nat third and last reading that allows the government to limit the prices of non - vital medicine and medical devices . xxmaj as a result , the state has more influence on price regulation . # xxup covid2019 # covid19russia ahk - liveticker https : / / t.co / xxunk https : / / t.co / xxunk xxbos a graduate from our xxmaj\nthird and last reading that allows the government to limit the prices of non - vital medicine and medical devices . xxmaj as a result , the state has more influence on price regulation . # xxup covid2019 # covid19russia ahk - liveticker https : / / t.co / xxunk https : / / t.co / xxunk xxbos a graduate from our xxmaj english\n\n\n6\ncalled racist . xxmaj on cue , he is called racist by globalists in denial . xxmaj pathetic ! https : / / t.co / xxunk xxbos @susannareid100 xxmaj but it 's ok for hundreds of people to be shopping in 300 argos stores across the country that are allowed to remain open even though they are nt essential retailers xxunk @bbcwatchdog @sainsburys @argos_online\nracist . xxmaj on cue , he is called racist by globalists in denial . xxmaj pathetic ! https : / / t.co / xxunk xxbos @susannareid100 xxmaj but it 's ok for hundreds of people to be shopping in 300 argos stores across the country that are allowed to remain open even though they are nt essential retailers xxunk @bbcwatchdog @sainsburys @argos_online #\n\n\n7\npanicbuyinguk xxbos xxmaj did a supply run today . xxmaj walk all the way from my condo to the nearest supermarket ( still pretty far ! xxmaj walkthrough xxup xxunk ) and back in broad xxunk . 7 kg rice not included in the pic cuz its in my xxunk sucks . https : / / t.co / xxunk xxbos # xxup covid19 :\nxxbos xxmaj did a supply run today . xxmaj walk all the way from my condo to the nearest supermarket ( still pretty far ! xxmaj walkthrough xxup xxunk ) and back in broad xxunk . 7 kg rice not included in the pic cuz its in my xxunk sucks . https : / / t.co / xxunk xxbos # xxup covid19 : xxmaj\n\n\n8\nthe phone . # toiletpaper # xxmaj coronavirus xxbos xxmaj denver xxmaj news xxup ag warns xxmaj coloradans against coronavirus scams https : / / t.co / xxunk https : / / t.co / xxunk xxbos xxmaj this bus driver said he felt violated when a passenger coughed and sneezed on the bus without covering her mouth . xxmaj he died of # coronavirus\nphone . # toiletpaper # xxmaj coronavirus xxbos xxmaj denver xxmaj news xxup ag warns xxmaj coloradans against coronavirus scams https : / / t.co / xxunk https : / / t.co / xxunk xxbos xxmaj this bus driver said he felt violated when a passenger coughed and sneezed on the bus without covering her mouth . xxmaj he died of # coronavirus 11\n\n\n\n\n\n\nlrnr = language_model_learner(dls,AWD_LSTM,metrics=[accuracy,Perplexity()])\n\n\nlrnr.fine_tune(3,1e-1) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nperplexity\ntime\n\n\n\n\n0\n4.812939\n4.488820\n0.288512\n89.016312\n02:03\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nperplexity\ntime\n\n\n\n\n0\n4.009799\n3.902233\n0.327761\n49.512905\n02:30\n\n\n1\n3.722594\n3.662943\n0.355355\n38.975876\n02:33\n\n\n2\n3.447793\n3.590583\n0.365500\n36.255199\n02:30\n\n\n\n\n\n\nlrnr.predict('the price of',20) \n\n\n\n\n\n\n\n\n'the price of milk and toilet roll havenâ\\x92t tripled surges by the end of the week but we have had a sense of'\n\n\n\n\n2. COVID10 tweets -&gt; 분류\n\ndf = pd.read_csv('Corona_NLP_train.csv',encoding=\"ISO-8859-1\")\ndf\n\n\n  \n    \n      \n\n\n\n\n\n\nUserName\nScreenName\nLocation\nTweetAt\nOriginalTweet\nSentiment\n\n\n\n\n0\n3799\n48751\nLondon\n16-03-2020\n@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8\nNeutral\n\n\n1\n3800\n48752\nUK\n16-03-2020\nadvice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\nPositive\n\n\n2\n3801\n48753\nVagabonds\n16-03-2020\nCoronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\nPositive\n\n\n3\n3802\n48754\nNaN\n16-03-2020\nMy food stock is not the only one which is empty...\\r\\r\\n\\r\\r\\nPLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. \\r\\r\\nStay calm, stay safe.\\r\\r\\n\\r\\r\\n#COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\nPositive\n\n\n4\n3803\n48755\nNaN\n16-03-2020\nMe, ready to go at supermarket during the #COVID19 outbreak.\\r\\r\\n\\r\\r\\nNot because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage...\\r\\r\\n\\r\\r\\n#CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\nExtremely Negative\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n41152\n44951\n89903\nWellington City, New Zealand\n14-04-2020\nAirline pilots offering to stock supermarket shelves in #NZ lockdown #COVID-19 https://t.co/cz89uA0HNp\nNeutral\n\n\n41153\n44952\n89904\nNaN\n14-04-2020\nResponse to complaint not provided citing COVID-19 related delays. Yet prompt in rejecting policy before consumer TAT is over. Way to go ?\nExtremely Negative\n\n\n41154\n44953\n89905\nNaN\n14-04-2020\nYou know itÂ’s getting tough when @KameronWilds is rationing toilet paper #coronavirus #toiletpaper @kroger martinsville, help us out!!\nPositive\n\n\n41155\n44954\n89906\nNaN\n14-04-2020\nIs it wrong that the smell of hand sanitizer is starting to turn me on?\\r\\r\\n\\r\\r\\n#coronavirus #COVID19 #coronavirus\nNeutral\n\n\n41156\n44955\n89907\ni love you so much || he/him\n14-04-2020\n@TartiiCat Well new/used Rift S are going for $700.00 on Amazon rn although the normal market price is usually $400.00 . Prices are really crazy right now for vr headsets since HL Alex was announced and it's only been worse with COVID-19. Up to you whethe\nNegative\n\n\n\n\n41157 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ndls = TextDataLoaders.from_df(df,text_col='OriginalTweet', label_col='Sentiment', seq_len=64)\ndls.show_batch()\n\n\n\n\n\n\n\n\n\n\n\n\ntext\ncategory\n\n\n\n\n0\nxxbos xxrep 5 ? ? ? xxrep 7 ? ? ? xxrep 7 ? xxrep 4 ? xxrep 4 ? xxrep 11 ? ? ? xxrep 6 ? xxrep 4 ? , xxrep 3 ? xxrep 3 ? ? ? xxrep 3 ? xxrep 4 ? xxrep 3 ? ? ? ? ? xxrep 4 ? ? ? xxrep 3 ? , xxrep 4 ? ? ? ? ? xxrep 6 ? xxrep 3 ? xxrep 3 ? xxrep 3 ? ? ? xxrep 3 ? \\r\\r\\n▁ xxrep 5 ? xxrep 6 ? ? ? xxrep 3 ? xxrep 4 ? xxrep 4 ? ? ? xxrep 4 ? xxrep 6 ? xxrep 4 ? xxrep 8 ? ? ? xxrep 6 ? ? ? xxrep 5 ? ? ? xxrep 3 ? xxrep 4 ? ? ? xxrep 7 ? xxrep 5 ? - xxrep 8 ? xxrep 5\nNeutral\n\n\n1\nxxbos xxup ask xxup your xxup self xxup what xxup do xxup you xxup think xxup is xxup going xxup to xxup happen xxup the xxup time xxup to xxup wake xxup up xxup is xxup now xxup do xxup you xxup think xxup food xxup going xxup to xxup be xxup xxunk xxup on xxup shop xxup shelfs .. no \\r\\r\\n xxup do xxup you xxup think xxup food xxup rise xxup in xxup price .. yes \\r\\r\\n xxup i m xxup going xxup to xxup stock xxup up xxup as xxup much i xxup can \\r\\r\\n xxup food xxup ladies xxup gentleman xxup is xxup most xxup valuable xxup asset \\r\\r\\n▁ # xxmaj coronavirus # xxup covid19 https : / / t.co / xxunk\nExtremely Positive\n\n\n2\nxxbos xxup keep xxup your xxup home xxup safe & & xxup clean \\r\\r\\n xxmaj the xxmaj best xxmaj way to xxmaj avoid the # xxmaj coronavirus is in xxmaj clean xxmaj home \\r\\r\\n xxmaj absolutely xxmaj outstanding xxmaj cleaning @ xxmaj awesome xxmaj rates \\r\\r\\n xxmaj prices : 2 xxmaj hours 2 xxmaj maids $ 75 + \\r\\r\\n xxmaj serving xxmaj las # xxmaj vegas , # xxmaj summerlin , # xxmaj xxunk xxmaj city & & xxmaj more \\r\\r\\n https : / / t.co / xxunk \\r\\r\\n ( xxunk - xxunk \\r\\r\\n▁ # xxup xxunk # xxup xxunk # xxup xxunk https : / / t.co / xxunk\nExtremely Positive\n\n\n3\nxxbos # xxup xxunk : xxup xxunk ' xxup back & & xxup forth xxup in xxup my xxup chair , xxup wearin ' xxup my xxup xxunk , xxup wrapped xxup in xxup my xxup blanket , xxup xxunk ' xxup exhausted , xxup xxunk ' xxunk xxup xxunk ' xxup in xxup line xxup at xxup the xxup supermarket , xxup xxunk ' xxup like xxup i m xxup cool xxup wit ' # xxup socialdistancing xxup there … . xxup why i xxup have xxup to xxup wait xxup so xxup long xxup before xxup xxunk … https : / / t.co / xxunk\nPositive\n\n\n4\nxxbos xxup sweet xxup baby xxup jesus & & xxup all xxup his xxup xxunk ! i swear 2 xxmaj god xxmaj i 'm going 2 throat punch these xxup covid-19 xxup food xxup hoarders . xxmaj the world xxmaj is n't going 2 end u selfish pricks . i went 2 get milk tonight & & they were out of stock . 4 the love of xxup xxunk xxup hoarding & & xxup save xxup some xxup products xxup for xxup the xxup rest xxup of xxup us xxrep 3 ! https : / / t.co / xxunk\nExtremely Positive\n\n\n5\nxxbos xxmaj this # xxmaj afternoon : xxmaj at xxup bs i could n't buy scratchers b / c it was # closed b / c of # coronavirus . xxmaj after xxup bs i walked to # xxmaj water xxmaj store to buy $ 2 scratchers . i won $ 10 with xxup xxunk and $ 1 with xxup xxunk . xxmaj after xxup ws i walked to # xxmaj mexican # xxmaj grocery to buy $ 2 scratchers . i lost $ 1 with xxup xxunk and $ 1 with xxup xxunk .\nPositive\n\n\n6\nxxbos xxmaj running xxmaj in xxmaj place , xxmaj working xxmaj out # 2k20 # xxmaj park # xxmaj workouts # xxmaj xxunk # xxmaj xxunk # xxmaj basketball # xxmaj court # xxmaj bored # xxmaj coronavirus # toiletpaper # xxmaj running # xxmaj lockdown # xxmaj home # xxmaj governor # xxmaj browns # xxup nfl # xxup nba # xxmaj cleveland # xxmaj art # xxmaj poetry # xxmaj peaceful # xxmaj beauty # xxmaj meditation # xxmaj ventilator \\r\\r\\n https : / / t.co / xxunk via @youtube\nNeutral\n\n\n7\nxxbos xxup mbbs - xxup rmc xxmaj pakistan \\r\\r\\n msc xxmaj public xxmaj health - xxup lsh xxup uk \\r\\r\\n ex - global xxmaj coordinator xxup who \\r\\r\\n ex - regional xxmaj adviser xxup who \\r\\r\\n xxmaj founder & & xxmaj executive xxmaj coordinator - xxmaj the xxmaj network for xxmaj consumer xxmaj protection xxmaj pakistan \\r\\r\\n\\r\\r\\n xxup vs \\r\\r\\n\\r\\r\\n xxup ba - xxmaj national xxmaj college xxmaj karachi . \\r\\r\\n xxup llb - xxmaj sindh xxmaj muslim xxmaj law xxmaj college \\r\\r\\n\\r\\r\\n▁ # coronaviruspakistan # xxmaj coronavirus\nNeutral\n\n\n8\nxxbos xxup stop xxup hoarding - u r xxup causing xxup problems 4 / xxup people xxup who xxup canâ’t get around xxup easy & & quick ( the elderly & & those w / physical disabilities ) most r xxup over xxup buying products xxunk at higher prices xxup not 4 / xxup need & & treating toilet paper like xxup roll xxup gold - look at xxup what u r xxup doing . \\r\\r\\n▁ # stophoarding \\r\\r\\n▁ # coronavirus https : / / t.co / xxunk\nNegative\n\n\n\n\n\n\nlrnr = text_classifier_learner(dls,AWD_LSTM,metrics=accuracy)\n\n\nlrnr.fine_tune(5, 1e-2)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.466701\n1.372223\n0.390597\n00:46\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.171761\n1.022376\n0.572956\n00:53\n\n\n1\n0.947488\n0.843770\n0.669056\n00:51\n\n\n2\n0.802706\n0.684167\n0.740858\n00:52\n\n\n3\n0.671411\n0.648740\n0.758110\n00:52\n\n\n4\n0.605033\n0.645920\n0.759203\n00:54\n\n\n\n\n\n\nlrnr.predict(\"the government’s approach to the pendemic has been a complete disaster\") \n\n\n\n\n\n\n\n\n('Extremely Negative',\n tensor(0),\n tensor([6.7275e-01, 5.5622e-06, 3.2659e-01, 2.4446e-05, 6.2955e-04]))\n\n\n\nlrnr.predict(\"the new vaccines hold the promise of a quick return to economic growth\") \n\n\n\n\n\n\n\n\n('Extremely Positive',\n tensor(1),\n tensor([1.6411e-06, 9.0713e-01, 1.5391e-04, 4.9677e-05, 9.2669e-02]))\n\n\n\n\n3. human numbers 5\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \ntxt_x = txt[:-1]\ntxt_y = txt[1:] \n\n\ntxt_x[:5], txt_y[:5]\n\n(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])\n\n\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n\n #torch.nn.RNNCell()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\n\n\ntorch.manual_seed(202250926)\nrnncell = torch.nn.RNNCell(6,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = [] \n    ht = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht = rnncell(xt,ht) \n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.999, 0.   , 0.   , 0.001, 0.   , 0.   ],\n       [0.   , 0.002, 0.998, 0.   , 0.   , 0.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.999, 0.   , 0.001],\n       [0.999, 0.   , 0.   , 0.001, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.999, 0.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.001, 0.001, 0.998],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.999, 0.   , 0.   , 0.   , 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','1','2','3','4','5']);\n\n\n\n\n\n# torch.nn.RNN()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\nrnn = torch.nn.RNN(6,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden, hT = rnn(x) \n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','1','2','3','4','5']);\n\n\n\n\n\n#  torch.nn.LSTMCell()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\ntorch.manual_seed(202250926) \nlstmcell = torch.nn.LSTMCell(6,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = []\n    ht = torch.zeros(8).to(\"cuda:0\")\n    ct = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.997, 0.   , 0.002, 0.   , 0.001, 0.   ],\n       [0.   , 0.   , 0.991, 0.004, 0.005, 0.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.028, 0.003, 0.969, 0.   , 0.   ],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.004, 0.   , 0.975, 0.021],\n       [1.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.019, 0.   , 0.   , 0.021, 0.961],\n       [0.998, 0.002, 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.937, 0.   , 0.03 , 0.   , 0.032]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','1','2','3','4','5']);\n\n\n\n\n\n# torch.nn.LSTM()을 이용하여 다음단어를 예측하는 신경망을 설계하고 학습하라.\nlstm = torch.nn.LSTM(6,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,6).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden, (hT,cT) = lstm(x)\n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(6),labels=[',','1','2','3','4','5']);"
  },
  {
    "objectID": "posts/3. RNN/2022_12_08_13wk_checkpoint.html",
    "href": "posts/3. RNN/2022_12_08_13wk_checkpoint.html",
    "title": "기계학습 (1201)",
    "section": "",
    "text": "IMDB자료의 분석 (텍스트생성과 감성분류), 잡담"
  },
  {
    "objectID": "posts/3. RNN/2022_12_08_13wk_checkpoint.html#잡담1-순환신경망-텍스트마이닝-시계열분석",
    "href": "posts/3. RNN/2022_12_08_13wk_checkpoint.html#잡담1-순환신경망-텍스트마이닝-시계열분석",
    "title": "기계학습 (1201)",
    "section": "잡담1: 순환신경망, 텍스트마이닝, 시계열분석",
    "text": "잡담1: 순환신경망, 텍스트마이닝, 시계열분석\n- 순환신경망은 순서가 있는 (말이 좀 애매하지만 아무튼 이렇게 많이 표현해요) 자료를 분석할때 사용할 수 있다. 순서가 있는 자료는 대표적으로 시계열자료과 텍스트자료가 있다.\n- 그래서 언뜻 생각하면 텍스트마이닝이나 시계열분석과 내용이 비슷할 것 같지만 사실 그렇지 않다.\n\n텍스트마이닝의 토픽: 단어를 어떻게 숫자로 잘 만들지, 토픽모델 // 자잘하고 실용적인 느낌? 공학적임..\n\n시계열분석의 토픽: 예측(forecasting)과 신뢰구간, 변화점과 관련한 연구 (detection/test), 정상/비정상시계열모형 (ARIMA, GARCH), Cointegration Test, // 느낌이 좀 거창해.. 경제와 관련 많음.\n순환신경망의 토픽(재작년까지): 텍스트생성, 텍스트분류 + 시계열 자료의 예측, 단어의 숫자화 … 텍스트마이닝과 시계열분석의 거의 모든 토픽에 관여함\n순환신경망의 토픽(작년부터?): 딥러닝의 거의 모든 영역에 관여하기 시작함 (심지어 요즘 이미지 분석도 순환망으로 합니다)\n\n\nhttps://youtu.be/thsXGOkcGGg"
  },
  {
    "objectID": "posts/3. RNN/2022_12_08_13wk_checkpoint.html#잡담2-순환신경망의-아키텍처를-얼마나-깊이-이해해야-할까",
    "href": "posts/3. RNN/2022_12_08_13wk_checkpoint.html#잡담2-순환신경망의-아키텍처를-얼마나-깊이-이해해야-할까",
    "title": "기계학습 (1201)",
    "section": "잡담2: 순환신경망의 아키텍처를 얼마나 깊이 이해해야 할까?",
    "text": "잡담2: 순환신경망의 아키텍처를 얼마나 깊이 이해해야 할까?\n- 과거기준(텍스트생성, 텍스트분류, 시계열자료예측 등에만 순환망이 이용되었을 때): 학부수준에서 순수 RNN만 알아도 충분했던 것 같음. LSTM이나 GRU는 석사수준?\n- 현재기준: 석사기준 LSTM 같은건 기본이고 어텐션, 트랜스포머등에 대한 개념도 잘 알고 있어야 함. (학부는 잘 모르겠네..)\n- 내 생각: 결국 아키텍처는 근데 유행이라 아키텍처는 한번 따라하면서 이해해보고 핵심 아이디어만 이해하면 된다고 생각함. 즉 LSTM 같은 특정모형의 아키텍처를 달달 외울필요는 없다, 수식써있는거 보고 이해하면 그만임. (수식정도를 이해할 능력은 필요한게.. 코드를 짤때 옵션을 이해할 수는 있어야하니까)\n- 망상: 나중에는 순환신경망이 거의 모든 딥러닝 방법의 base가 되지 않을까?"
  },
  {
    "objectID": "posts/3. RNN/2022_12_08_13wk_checkpoint.html#잡담3-fastai-pytorch-lightning",
    "href": "posts/3. RNN/2022_12_08_13wk_checkpoint.html#잡담3-fastai-pytorch-lightning",
    "title": "기계학습 (1201)",
    "section": "잡담3: fastai, pytorch lightning",
    "text": "잡담3: fastai, pytorch lightning\n- 비 컴퓨터공학 출신이 쓰기에는 fastai가 좀 더 쓰기 편한건 사실\n- pytorch lightning은 fastai보다 쓰기 어렵지만 (진짜 약간의 클래스관련 지식이 필요함, 솔직히 별로 어렵진 않아요) 좀 더 순수 파이토치에 가깝고 따라서 코드를 뜯어보기 편리하다.\n- 과거의 생각\n\n전문가: pytorch + fastai // pytorch + pytorch lightning (컴공출신)\n비 전문가: 순수 fastai\n\n- 요즘 생각\n\n모두: pytorch + pytorch lightning\n특정한경우: 순수 fastai &lt;– 모형이 구현되어 있다면 fastai가 좋긴 좋아.. 그런데 모형의 구현속도가 못따라감"
  },
  {
    "objectID": "posts/3. RNN/2022_12_08_13wk_checkpoint.html#잡담4-우린-뭘-해야-할까-학석사-레벨에서..",
    "href": "posts/3. RNN/2022_12_08_13wk_checkpoint.html#잡담4-우린-뭘-해야-할까-학석사-레벨에서..",
    "title": "기계학습 (1201)",
    "section": "잡담4: 우린 뭘 해야 할까 (학석사 레벨에서..)",
    "text": "잡담4: 우린 뭘 해야 할까 (학석사 레벨에서..)\n- 능력1: 코드이해력 (= 구현능력 = 코드 베끼는 능력)\n\n이미지분석? 해봤음. 텍스트자료? 해봤음. 시계열? 해봤음. 등등등등? 다 해본적 있음. 어떤 원리인지 정확하게 몰라도 다 해본적 있고 그래서 일할 수 있음!!\n돌아가는 코드 최대한 많이 모아놓으세요. torch, fastai, pytorch lightning, tensorflow, keras 등등\n\n- 능력2: 최신트렌드를 파악할 수 있는 힘 (= 논문이해력)\n\n공부, 공부, 공부… A to Z 까지 수식 다 뜯어보고 코드 다 뜯어보면서 집요하게 공부해야함. (LSTM에서 했던것 처럼!) 물론 차근차근 알려주면 수업이 있다면 좋겠지 그런데 보통은 적당히 두리뭉실하게 설명하지 detail 하게 설명하는 수업은 잘 없음. (지루하거든요)\n수식이나 코드중 하나라도 볼 줄 모르면 능력2를 얻는것 자체가 불가능."
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html",
    "title": "기계학습 (1116) 11주차",
    "section": "",
    "text": "RNN(2)– AbAcAd예제, GPU실험 // LSTM– abcabC, abcdabcD, LSTM의 계산과정, LSTM은 왜 강한가?"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data",
    "title": "기계학습 (1116) 11주차",
    "section": "data",
    "text": "data\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]), tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현1-손으로-직접구현-리뷰",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현1-손으로-직접구현-리뷰",
    "title": "기계학습 (1116) 11주차",
    "section": "순환신경망 구현1 (손으로 직접구현) – 리뷰",
    "text": "순환신경망 구현1 (손으로 직접구현) – 리뷰\n(1) 숙성담당 네트워크\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) \n        self.h2h = torch.nn.Linear(2,2) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell = rNNCell() # 숙성담당 네트워크 \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat.data[-15:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f09e935fa50&gt;"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현2-with-rnncell-hidden-node-2",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현2-with-rnncell-hidden-node-2",
    "title": "기계학습 (1116) 11주차",
    "section": "순환신경망 구현2 (with RNNCell, hidden node 2)",
    "text": "순환신경망 구현2 (with RNNCell, hidden node 2)\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n\n구현1과 같은 초기값 (확인용)\n(1) 숙성네트워크\n\ntorch.manual_seed(43052)\n_rnncell = rNNCell() # 숙성담당 네트워크 \n\n\nrnncell = torch.nn.RNNCell(4,2)   # 4=x , 2=h\n\nrNNCell() 는 사실 torch.nn.RNNCell()와 같은 동작을 하도록 설계를 하였음. 같은동작을 하는지 확인하기 위해서 동일한 초기상태에서 rNNCell()에 의하여 학습된 결과와 torch.nn.RNNCell()에 의하여 학습된 결과를 비교해보자.\n\nrnncell.weight_ih.data = _rnncell.i2h.weight.data\nrnncell.bias_ih.data = _rnncell.i2h.bias.data\nrnncell.weight_hh.data = _rnncell.h2h.weight.data\nrnncell.bias_hh.data = _rnncell.h2h.bias.data\n\n# 초기상태를 똑같이! 앞에서 손으로 직접구현한 것과 일치하는지 확인하기 위해서.\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) # 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습\n\nT = len(x) \nfor epoc in range(5000):\n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht)\n        ot = cook(ht)\n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nhidden = torch.zeros(T,2) \n\n\n# t=0 \n_water = torch.zeros(1,2)\nhidden[[0]] = rnncell(x[[0]],_water)\n# t=1~T \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat[:15].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f09e0352f90&gt;\n\n\n\n\n\n\nplt.matshow(yhat[-15:].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f09c75ffd90&gt;\n\n\n\n\n\n\n\n새로운 초기값\n(1) 숙성네트워크\n\ntorch.manual_seed(43052)\ntorch.nn.RNNCell(4,2)\n\nRNNCell(4, 2)\n\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) # 숙성된 2차원의 단어를 다시 4차원으로 바꿔줘야지 나중에 softmax취할 수 있음\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습\n\nT = len(x) \nfor epoc in range(5000):\n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht)\n        ot = cook(ht)\n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\nyhat을 저장한 적이 없는데? x -&gt; h -&gt; outfut -&gt; yhat 이렇게 되야하는데.. 히든레이어에 출력이 T시점에만 저장되어 있고 1부터 599에 해당되는 히든레이어가 저장이 안되어있는 네트워크만 저장된 상태 시각화를 위해 hidden레이어를 재정의 해야함\n\nhidden = torch.zeros(T,2)\n#맹물을 만들자\n_water=torch.zeros(1,2)\n#t=0\nhidden[[0]] = rnncell(x[[0]],_water)\n\n#t=1~T\nfor t in range(1,T):\n  hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\n\n\nyhat = soft(cook(hidden)) \nplt.matshow(yhat[:15].data,cmap='bwr')"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현3-with-rnn-hidden-node-2-성공",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현3-with-rnn-hidden-node-2-성공",
    "title": "기계학습 (1116) 11주차",
    "section": "순환신경망 구현3 (with RNN, hidden node 2) – 성공",
    "text": "순환신경망 구현3 (with RNN, hidden node 2) – 성공\n(예비학습)\n- 네트워크학습이후 yhat을 구하려면 번거로웠음\nhidden = torch.zeros(T,2) \n_water = torch.zeros(1,2)\nhidden[[0]] = rnncell(x[[0]],_water)\nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\nyhat = soft(cook(hidden))\n- 이렇게 하면 쉽게(?) 구할 수 있음\n\nrnn = torch.nn.RNN(4,2)\n\n\nrnn.weight_hh_l0.data = rnncell.weight_hh.data    # 2x2 매트릭스\nrnn.weight_ih_l0.data = rnncell.weight_ih.data\nrnn.bias_hh_l0.data = rnncell.bias_hh.data\nrnn.bias_ih_l0.data = rnncell.bias_ih.data\n\n- rnn(x,_water)의 결과는 (1) 599년치 간장 (2) 599번째 간장 이다\n\n_water = torch.zeros(1,2)\nrnn(x,_water), hidden \n# 두개의 값이 같다! \n\n# x: tupple.. \n\n((tensor([[-0.9912, -0.9117],\n          [ 0.0698, -1.0000],\n          [-0.9927, -0.9682],\n          ...,\n          [-0.9935, -0.9315],\n          [ 0.5777, -1.0000],\n          [-0.9960, -0.0109]], grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[-0.9960, -0.0109]], grad_fn=&lt;SqueezeBackward1&gt;)),\n tensor([[-0.9912, -0.9117],\n         [ 0.0698, -1.0000],\n         [-0.9927, -0.9682],\n         ...,\n         [-0.9935, -0.9315],\n         [ 0.5777, -1.0000],\n         [-0.9960, -0.0109]], grad_fn=&lt;IndexPutBackward0&gt;))\n\n\n\nsoft(cook(rnn(x,_water)[0]))\n\ntensor([[1.9725e-02, 1.5469e-03, 8.2766e-01, 1.5106e-01],\n        [9.1875e-01, 1.6513e-04, 6.7702e-02, 1.3384e-02],\n        [2.0031e-02, 1.0660e-03, 8.5248e-01, 1.2642e-01],\n        ...,\n        [1.9640e-02, 1.3568e-03, 8.3705e-01, 1.4196e-01],\n        [9.9564e-01, 1.3114e-05, 3.5069e-03, 8.4108e-04],\n        [3.5473e-03, 1.5670e-01, 1.4102e-01, 6.9873e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n(예비학습결론) torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. (for문이 포함된 버전이다)\n\ntorch.nn.RNN(4,2)를 이용하여 구현하자.\n(1) 숙성네트워크\n선언\n\nrnn = torch.nn.RNN(4,2)\n\n가중치초기화\n\ntorch.manual_seed(43052)\n_rnncell = torch.nn.RNNCell(4,2)\n\n\nrnn.weight_hh_l0.data = _rnncell.weight_hh.data \nrnn.weight_ih_l0.data = _rnncell.weight_ih.data\nrnn.bias_hh_l0.data = _rnncell.bias_hh.data\nrnn.bias_ih_l0.data = _rnncell.bias_ih.data\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))\n\n(4) 학습\n\n# 맹물을 넣어주기 위한 세팅\n_water = torch.zeros(1,2) \n\nfor epoc in range(5000):\n    ## 1  hT: 그냥 써논거 \n    hidden,hT = rnn(x,_water)\n    output = cook(hidden) #output이 배치로 나오게 된다.\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()   #갱신\n    optimizr.zero_grad()  #초기화\n\n(5) 시각화1: yhat\n\nyhat = soft(output)\n\n\nplt.matshow(yhat.data[:15],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7fe67c231310&gt;\n\n\n\n\n\n\n처음은 좀 틀렸음 ㅎㅎ\n\n\nplt.matshow(yhat.data[-15:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7fe67c1c5d90&gt;\n\n\n\n\n\n\n뒤에는 잘맞음\n\n실전팁: _water 대신에 hT를 대입 (사실 큰 차이는 없음)\n\n# hT에 값이 있음\n# rnn(x,hT)[0][:6] 값과 hidden[:6] 값을 비교해보면 비슷함 \n\n\nrnn(x[:6],_water),rnn(x[:6],hT)\n\n((tensor([[-0.9912, -0.9117],\n          [ 0.0698, -1.0000],\n          [-0.9927, -0.9682],\n          [ 0.5761, -1.0000],\n          [-0.9960, -0.0173],\n          [ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)),\n (tensor([[-0.9713, -1.0000],\n          [ 0.0535, -1.0000],\n          [-0.9925, -0.9720],\n          [ 0.5759, -1.0000],\n          [-0.9960, -0.0180],\n          [ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[ 0.9960, -1.0000]], grad_fn=&lt;SqueezeBackward1&gt;)))\n\n\n(6) 시각화2: hidden, yhat\n\ncombinded = torch.concat([hidden,yhat],axis=1)\n\n\nplt.matshow(combinded[-15:].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7fe67c13b7d0&gt;\n\n\n\n\n\n\n히든노드의 해석이 어려움."
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현4-with-rnn-hidden-node-3-성공",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#순환신경망-구현4-with-rnn-hidden-node-3-성공",
    "title": "기계학습 (1116) 11주차",
    "section": "순환신경망 구현4 (with RNN, hidden node 3) – 성공",
    "text": "순환신경망 구현4 (with RNN, hidden node 3) – 성공\n(1) 숙성네트워크~ (2) 조리네트워크\n\ntorch.manual_seed(2) #1 \nrnn = torch.nn.RNN(4,3) \ncook = torch.nn.Linear(3,4) \n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()))\n\n(4) 학습\n\n_water = torch.zeros(1,3) \nfor epoc in range(5000):\n    ## 1\n    hidden,hT = rnn(x,_water) \n    output = cook(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화1: yhat\n\nyhat = soft(output)\n\n\nplt.matshow(yhat[-15:].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7fe67c04f550&gt;\n\n\n\n\n\n(6) 시각화2: hidden, yhat\n\ncombinded = torch.concat([hidden,yhat],axis=1)\n\n\nplt.matshow(combinded[-15:].data,cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7fe6747ba910&gt;\n\n\n\n\n\n\n세번째 히든노드 = 대소문자를 구분\n1,2 히든노드 = bcd를 구분"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes",
    "title": "기계학습 (1116) 11주차",
    "section": "20000 len + 20 hidden nodes",
    "text": "20000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()   # 역전파를 하는 곳이 시간을 제일 많이 잡아먹는다. \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n93.01761960983276\n\n\ngpu\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n3.2665085792541504\n\n\n\n왜 빠른지?\n\n\n# for문이 중첩이 되어있는 형태인데, hidden에서 cpu에서는 그래서 오래걸리는 거구... 근데 이것보다는 역전파 하는곳 때문에 더 오래걸린다!"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-역전파주석처리",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-역전파주석처리",
    "title": "기계학습 (1116) 11주차",
    "section": "20000 len + 20 hidden nodes + 역전파주석처리",
    "text": "20000 len + 20 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([20000,4]) \ny = torch.randn([20000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n18.851768255233765\n\n\ngpu (역전파주석처리)\n\nx = torch.randn([20000,4]).to(\"cuda:0\")\ny = torch.randn([20000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.2901742458343506"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-1",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-1",
    "title": "기계학습 (1116) 11주차",
    "section": "2000 len + 20 hidden nodes",
    "text": "2000 len + 20 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n6.533619165420532\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.7532594203948975"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-역전파주석처리-1",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-20-hidden-nodes-역전파주석처리-1",
    "title": "기계학습 (1116) 11주차",
    "section": "2000 len + 20 hidden nodes + 역전파주석처리",
    "text": "2000 len + 20 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,20) \nlinr = torch.nn.Linear(20,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n1.2477965354919434\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,20).to(\"cuda:0\")\nlinr = torch.nn.Linear(20,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,20).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n0.14130854606628418"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-5000-hidden-nodes",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-5000-hidden-nodes",
    "title": "기계학습 (1116) 11주차",
    "section": "2000 len + 5000 hidden nodes",
    "text": "2000 len + 5000 hidden nodes\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n58.99820685386658\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n4.7596595287323"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-5000-hidden-nodes-역전파주석처리",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#len-5000-hidden-nodes-역전파주석처리",
    "title": "기계학습 (1116) 11주차",
    "section": "2000 len + 5000 hidden nodes + 역전파주석처리",
    "text": "2000 len + 5000 hidden nodes + 역전파주석처리\ncpu\n\nx = torch.randn([2000,4]) \ny = torch.randn([2000,4]) \n\n\nrnn = torch.nn.RNN(4,1000) \nlinr = torch.nn.Linear(1000,4) \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000)\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n13.163657188415527\n\n\ngpu\n\nx = torch.randn([2000,4]).to(\"cuda:0\")\ny = torch.randn([2000,4]).to(\"cuda:0\")\n\n\nrnn = torch.nn.RNN(4,1000).to(\"cuda:0\")\nlinr = torch.nn.Linear(1000,4).to(\"cuda:0\")\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()))\nloss_fn = torch.nn.MSELoss() \n\n\nt1 = time.time()\nfor epoc in range(100):\n    ## 1 \n    _water = torch.zeros(1,1000).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water) \n    yhat = linr(hidden) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3\n    #loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2 - t1 \n\n2.2989864349365234"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#실험결과-요약",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#실험결과-요약",
    "title": "기계학습 (1116) 11주차",
    "section": "실험결과 요약",
    "text": "실험결과 요약\n\n\n\nlen\n# of hidden nodes\nbackward\ncpu\ngpu\nratio\n\n\n\n\n20000\n20\nO\n93.02\n3.26\n28.53\n\n\n20000\n20\nX\n18.85\n1.29\n14.61\n\n\n2000\n20\nO\n6.53\n0.75\n8.70\n\n\n2000\n20\nX\n1.25\n0.14\n8.93\n\n\n2000\n1000\nO\n58.99\n4.75\n12.41\n\n\n2000\n1000\nX\n13.16\n2.29\n5.74"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-1",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-1",
    "title": "기계학습 (1116) 11주차",
    "section": "data",
    "text": "data\n\ntxt = list('abcabC')*100\ntxt[:8]\n\n['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b']\n\n\n\ntxt_x = txt[:-1] \ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\") \n\n\nx.shape\n\ntorch.Size([599, 4])\n\n\na1, b1, c, a2, b2, C - 보이는 문자수가 a,b,c,C 이므로 4개 - 문맥까지 고려하면 6개(a1, a2와 같이,.)"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn",
    "title": "기계학습 (1116) 11주차",
    "section": "RNN",
    "text": "RNN\n\ntorch.manual_seed(43052) \nrnn = torch.nn.RNN(4,3)    # 문맥의 차이 고려가 힘드니까 히든레이어를 3개 정도는 있어야 문맥에 따른걸 생각할 수 있을 거 같다!  \nlinr = torch.nn.Linear(3,4) \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+ list(linr.parameters()))\n\n\nrnn.to(\"cuda:0\") \nlinr.to(\"cuda:0\")\n\nLinear(in_features=3, out_features=4, bias=True)\n\n\n- 3000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f47e032f890&gt;\n\n\n\n\n\n- 6000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f47e1078b90&gt;\n\n\n\n\n\n- 9000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f47e0358590&gt;\n\n\n\n\n\n- 12000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f47e2de6f10&gt;\n\n\n\n\n\n- 15000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, hT = rnn(x,_water)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr')\n\n&lt;matplotlib.image.AxesImage at 0x7f47cc12ae50&gt;"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm",
    "title": "기계학습 (1116) 11주차",
    "section": "LSTM",
    "text": "LSTM\n- LSTM\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,3) #RNN-&gt;lstm\nlinr = torch.nn.Linear(3,4) \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(linr.parameters()))\n\n\nlstm.to(\"cuda:0\") \nlinr.to(\"cuda:0\")\n\nLinear(in_features=3, out_features=4, bias=True)\n\n\n- 3000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, (hT,cT) = lstm(x,(_water,_water))   # lstm은 물을 두개 넣어줘야 하고 hT랑 cT랑이 나온다..\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f47cc0608d0&gt;\n\n\n\n\n\n- 6000 epochs\n\nfor epoc in range(3000):\n    ## 1 \n    _water = torch.zeros(1,3).to(\"cuda:0\")\n    hidden, (hT,cT) = lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\ncombinded  = torch.concat([hidden,yhat],axis=1).data.to(\"cpu\")\n\n\nplt.matshow(combinded[-6:],cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f47c61dd750&gt;"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn-vs-lstm-성능비교실험",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn-vs-lstm-성능비교실험",
    "title": "기계학습 (1116) 11주차",
    "section": "RNN vs LSTM 성능비교실험",
    "text": "RNN vs LSTM 성능비교실험\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,3).to(\"cuda:0\")\n        linr = torch.nn.Linear(3,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,3).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,3).to(\"cuda:0\")\n        linr = torch.nn.Linear(3,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,3).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-2",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-2",
    "title": "기계학습 (1116) 11주차",
    "section": "data",
    "text": "data\n\ntxt = list('abcdabcD')*100\ntxt[:8]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'D']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0, 'b':1, 'c':2, 'd':3, 'D':4}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx=x.to(\"cuda:0\")\ny=y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn-vs-lstm-성능비교실험-1",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#rnn-vs-lstm-성능비교실험-1",
    "title": "기계학습 (1116) 11주차",
    "section": "RNN vs LSTM 성능비교실험",
    "text": "RNN vs LSTM 성능비교실험\n- RNN\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$RNN$\",size=20)\nfig.tight_layout()\n\n\n\n\n- LSTM\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(5,4).to(\"cuda:0\")\n        linr = torch.nn.Linear(4,5).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,4).to(\"cuda:0\")\n        for epoc in range(3000):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-8:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(r\"$LSTM$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 관찰1: LSTM이 확실히 장기기억에 강하다.\n- 관찰2: LSTM은 hidden에 0이 잘 나온다.\n\n사실 확실히 구분되는 특징을 판별할때는 -1,1 로 히든레이어 값들이 설정되면 명확하다.\n히든레이어에 -1~1사이의 값이 나온다면 애매한 판단이 내려지게 된다.\n그런데 이 애매한 판단이 어떻게 보면 문맥의 뉘앙스를 이해하는데 더 잘 맞다.\n그런데 RNN은 -1,1로 셋팅된 상황에서 -1~1로의 변화가 더디다는 것이 문제임.\n\n\n# 히든레이어는 하얀색.."
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-abab",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-abab",
    "title": "기계학습 (1116) 11주차",
    "section": "data: abaB",
    "text": "data: abaB\n\ntxt = list('abaB')*100\ntxt[:5]\n\n['a', 'b', 'a', 'B', 'a']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'a':0, 'b':1, 'B':2}\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver1-with-torch.nn.lstmcell",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver1-with-torch.nn.lstmcell",
    "title": "기계학습 (1116) 11주차",
    "section": "1 epoch ver1 (with torch.nn.LSTMCell)",
    "text": "1 epoch ver1 (with torch.nn.LSTMCell)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) #LSTM말고 LSTMCell (LSTM을 batch버전으로..)  # 단어수가 3개니까 3!!! abB, 근데 문맥상 a1,a2,b,B 4개의 문자가 있으니까 히든노드를 2개정도로 잡자.\nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)   #lr=학습률\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)  # 히든노드가 2개니까 차원이 2인 맹물을 만들어주자.\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt)\n    loss = loss / T\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nht,ct \n\n(tensor([[-0.0406,  0.2505]], grad_fn=&lt;MulBackward0&gt;),\n tensor([[-0.0975,  0.7134]], grad_fn=&lt;AddBackward0&gt;))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver2-완전-손으로-구현",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver2-완전-손으로-구현",
    "title": "기계학습 (1116) 11주차",
    "section": "1 epoch ver2 (완전 손으로 구현)",
    "text": "1 epoch ver2 (완전 손으로 구현)\n\nt=0 \\(\\to\\) t=1\n- lstm_cell 을 이용한 계산 (결과비교용)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(1):\n        xt,yt = x[[t]], y[[t]]\n        ht,ct = lstm_cell(xt,(ht,ct))\n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht,ct \n\n(tensor([[-0.0541,  0.0892]], grad_fn=&lt;MulBackward0&gt;),\n tensor([[-0.1347,  0.2339]], grad_fn=&lt;AddBackward0&gt;))\n\n\n\n이런결과를 어떻게 만드는걸까?\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n\n- 직접계산\n\nht = torch.zeros(1,2)\nct = torch.zeros(1,2)\n\n\n_ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n\n\ninput_gate = sig(_ifgo[:,0:2])\nforget_gate = sig(_ifgo[:,2:4])\ngt = tanh(_ifgo[:,4:6])\noutput_gate = sig(_ifgo[:,6:8])\n\n\nct = forget_gate * ct + input_gate * gt\nht = output_gate * tanh(ct)\n\n\nht,ct\n\n(tensor([[-0.0541,  0.0892]], grad_fn=&lt;MulBackward0&gt;),\n tensor([[-0.1347,  0.2339]], grad_fn=&lt;AddBackward0&gt;))\n\n\n\n\nt=0 \\(\\to\\) t=T\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2) \nlinr = torch.nn.Linear(2,3)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm_cell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nT = len(x) \nfor epoc in range(1):\n    ht = torch.zeros(1,2)\n    ct = torch.zeros(1,2)\n    loss = 0 \n    ## 1~2\n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        \n        ## lstm_cell step1: calculate _ifgo \n        _ifgo = xt @ lstm_cell.weight_ih.T + ht @ lstm_cell.weight_hh.T + lstm_cell.bias_ih + lstm_cell.bias_hh\n        ## lstm_cell step2: decompose _ifgo \n        input_gate = sig(_ifgo[:,0:2])\n        forget_gate = sig(_ifgo[:,2:4])\n        gt = tanh(_ifgo[:,4:6])\n        output_gate = sig(_ifgo[:,6:8])\n        ## lstm_cell step3: calculate ht,ct \n        ct = forget_gate * ct + input_gate * gt\n        ht = output_gate * tanh(ct)\n        \n    #     ot = linr(ht) \n    #     loss = loss + loss_fn(ot,yt)\n    # loss = loss / T\n    # ## 3 \n    # loss.backward()\n    # ## 4 \n    # optimizr.step()\n    # optimizr.zero_grad()\n\n\nht,ct\n\n#LSMT_Cell로 쉽게 계산한것이랑 값이 같다.\n\n(tensor([[-0.0406,  0.2505]], grad_fn=&lt;MulBackward0&gt;),\n tensor([[-0.0975,  0.7134]], grad_fn=&lt;AddBackward0&gt;))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver3-with-torch.nn.lstm",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch-ver3-with-torch.nn.lstm",
    "title": "기계학습 (1116) 11주차",
    "section": "1 epoch ver3 (with torch.nn.LSTM)",
    "text": "1 epoch ver3 (with torch.nn.LSTM)\n\ntorch.manual_seed(43052) \nlstm_cell = torch.nn.LSTMCell(3,2)\nlinr = torch.nn.Linear(2,3) \n\n\nlstm = torch.nn.LSTM(3,2) \n\n\n# batch버전 통해서 확인해보기, 가중치값 덮어씌워보기\nlstm.weight_hh_l0.data = lstm_cell.weight_hh.data \nlstm.bias_hh_l0.data = lstm_cell.bias_hh.data \nlstm.weight_ih_l0.data = lstm_cell.weight_ih.data \nlstm.bias_ih_l0.data = lstm_cell.bias_ih.data \n\n\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters()) + list(linr.parameters()), lr=0.1) \n\n\n_water = torch.zeros(1,2) \nfor epoc in range(1): \n    ## step1 \n    hidden, (ht,ct) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    # ## step2\n    # loss = loss_fn(output,y) \n    # ## step3\n    # loss.backward()\n    # ## step4 \n    # optimizr.step()\n    # optimizr.zero_grad() \n\n\nht,ct\n\n(tensor([[-0.0406,  0.2505]], grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([[-0.0975,  0.7134]], grad_fn=&lt;SqueezeBackward1&gt;))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-abab-1",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#data-abab-1",
    "title": "기계학습 (1116) 11주차",
    "section": "data: abaB",
    "text": "data: abaB\n\ntxt = list('abaB')*100\ntxt[:5]\n\n['a', 'b', 'a', 'B', 'a']\n\n\n\nn_words = 3\n\n\nmapping = {'a':0, 'b':1, 'B':2}\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:10],txt_y[:10]\n\n(['a', 'b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b'],\n ['b', 'a', 'B', 'a', 'b', 'a', 'B', 'a', 'b', 'a'])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx,y\n\n(tensor([[1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.],\n         ...,\n         [1., 0., 0.],\n         [0., 1., 0.],\n         [1., 0., 0.]]),\n tensor([[0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.],\n         ...,\n         [0., 1., 0.],\n         [1., 0., 0.],\n         [0., 0., 1.]]))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#epoch",
    "title": "기계학습 (1116) 11주차",
    "section": "1000 epoch",
    "text": "1000 epoch\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(3,2) \nlinr = torch.nn.Linear(2,3) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(linr.parameters()),lr=0.1)\n\n\n_water = torch.zeros(1,2) \nfor epoc in range(1000): \n    ## step1 \n    hidden, (ht,ct) = lstm(x,(_water,_water))\n    output = linr(hidden)\n    ## step2\n    loss = loss_fn(output,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화",
    "title": "기계학습 (1116) 11주차",
    "section": "시각화",
    "text": "시각화\n\nT = len(x)\ninput_gate = torch.zeros(T,2)\nforget_gate = torch.zeros(T,2)\noutput_gate = torch.zeros(T,2)\ng = torch.zeros(T,2)\ncell = torch.zeros(T,2)\nh = torch.zeros(T,2)  # 히든노드를 2개로 잡아놨으니까.. \n\n# 계산식에 의해서 위에 값들이 다 (T,2)형태여야 한다.\n\n\n# LSTM 계산과정을 다시 따라가면,\n\nfor t in range(T): \n    ## 1: calculate _ifgo \n    _ifgo = x[[t]] @ lstm.weight_ih_l0.T + h[[t]] @ lstm.weight_hh_l0.T + lstm.bias_ih_l0 + lstm.bias_hh_l0 \n    ## 2: decompose _ifgo \n    input_gate[[t]] = sig(_ifgo[:,0:2])\n    forget_gate[[t]] = sig(_ifgo[:,2:4])\n    g[[t]] = tanh(_ifgo[:,4:6])\n    output_gate[[t]] = sig(_ifgo[:,6:8])\n    ## 3: calculate ht,ct \n    cell[[t]] = forget_gate[[t]] * cell[[t]] + input_gate[[t]] * g[[t]]\n    h[[t]] = output_gate[[t]] * tanh(cell[[t]])\n\n\ncombinded1 = torch.concat([input_gate,forget_gate,output_gate],axis=1)  # gate끼리 묶어서 시각화\ncombinded2 = torch.concat([g,cell,h,soft(output)],axis=1)               # 나머지 묶어서 시각화\n\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n\n\n\n\n상단그림은 게이트의 값들만 시각화, 하단그림은 게이트 이외의 값들을 시각화"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화의-해석i",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화의-해석i",
    "title": "기계학습 (1116) 11주차",
    "section": "시각화의 해석I",
    "text": "시각화의 해석I\n\nplt.matshow(combinded1[-8:].data,cmap='bwr',vmin=-1,vmax=1);\nplt.xticks(range(combinded1.shape[-1]),labels=['i']*2 + ['f']*2 + ['o']*2);\n\nNameError: ignored\n\n\n- input_gate, forget_gate, output_gate는 모두 0~1 사이의 값을 가진다.\n파 -1 흰 0 빨 1 이니까 .. xt, ht-1 가지고 sig취해서 i,f,o를 만들었으니 0~1사이의 값을 가진다.\n- 이 값들은 각각 모두 \\({\\boldsymbol g}_t, {\\boldsymbol c}_{t-1}, \\tanh({\\boldsymbol c}_t)\\)에 곱해진다. 따라서 input_gate, forget_gate, output_gate 는 gate의 역할로 비유가능하다. (1이면 통과, 0이면 차단)\n\ninput_gate: \\({\\boldsymbol g}_t\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\nforget_gate: \\({\\boldsymbol c}_{t-1}\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정\noutput_gate: \\(\\tanh({\\boldsymbol c}_t)\\)의 값을 얼만큼 통과시킬지 0~1사이의 숫자로 결정"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화의-해석ii",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#시각화의-해석ii",
    "title": "기계학습 (1116) 11주차",
    "section": "시각화의 해석II",
    "text": "시각화의 해석II\n\nplt.matshow(combinded2[-8:].data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(combinded2.shape[-1]),labels=['g']*2 + ['c']*2 + ['h']*2 + ['yhat']*3);\n\n\n\n\n- 결국 \\({\\boldsymbol g}_t\\to {\\boldsymbol c}_t \\to {\\boldsymbol h}_t \\to \\hat{\\boldsymbol y}\\) 의 느낌이다. (\\({\\boldsymbol h}_t\\)를 계산하기 위해서는 \\({\\boldsymbol c}_t\\)가 필요했고 \\({\\boldsymbol c}_t\\)를 계산하기 위해서는 \\({\\boldsymbol c}_{t-1}\\)과 \\({\\boldsymbol g}_t\\)가 필요했음)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol c}_t) \\odot {\\boldsymbol o}_t\\)\n\\({\\boldsymbol c}_t ={\\boldsymbol c}_{t-1} \\odot {\\boldsymbol f}_t + {\\boldsymbol g}_{t} \\odot {\\boldsymbol i}_t\\)\n\n- \\({\\boldsymbol g}_t,{\\boldsymbol c}_t,{\\boldsymbol h}_t\\) 모두 \\({\\boldsymbol x}_t\\)의 정보를 숙성시켜 가지고 있는 느낌이 든다.\n- \\({\\boldsymbol g}_t\\) 특징: 보통 -1,1 중 하나의 값을 가지도록 학습되어 있다. (마치 RNN의 hidden node처럼!)\n\n\\(\\boldsymbol{g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg}+ {\\boldsymbol b}_{ig}+{\\boldsymbol b}_{hg})\\)\n\n- \\({\\boldsymbol c}_t\\) 특징: \\({\\boldsymbol g}_t\\)와 매우 비슷하지만 약간 다른값을 가진다. 그래서 \\({\\boldsymbol g}_t\\)와는 달리 -1,1 이외의 값도 종종 등장.\n\nprint(\"first row: gt={}, ct={}\".format(g[-8].data, cell[-8].data))\nprint(\"second row: gt={}, ct={}\".format(g[-7].data, cell[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373])\n\n\n- \\({\\boldsymbol h}_t\\) 특징: (1) \\({\\boldsymbol c}_t\\)의 느낌이 있음 하지만 약간의 변형이 있음. (2) -1~1 사이에의 값을 훨씬 다양하게 가진다. (tanh때문)\n\nprint(\"first row: gt={}, ct={}, ht={}\".format(g[-8].data, cell[-8].data,h[-8].data))\nprint(\"second row: gt={}, ct={}, ht={}\".format(g[-7].data, cell[-7].data,h[-7].data))\n#g[-7], cell[-7]\n\nfirst row: gt=tensor([ 0.9999, -0.9999]), ct=tensor([ 0.9647, -0.9984]), ht=tensor([ 0.7370, -0.3323])\nsecond row: gt=tensor([ 0.9970, -0.9554]), ct=tensor([ 0.3592, -0.9373]), ht=tensor([ 0.0604, -0.6951])\n\n\n- 예전의문 해결\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RRN은 \\({\\boldsymbol h}_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\({\\boldsymbol h}_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\({\\boldsymbol h}_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm의-알고리즘-리뷰-i-수식위주",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm의-알고리즘-리뷰-i-수식위주",
    "title": "기계학습 (1116) 11주차",
    "section": "LSTM의 알고리즘 리뷰 I (수식위주)",
    "text": "LSTM의 알고리즘 리뷰 I (수식위주)\n(step1) calculate \\({\\tt ifgo}\\)\n\\({\\tt ifgo} = {\\boldsymbol x}_t \\big[{\\bf W}_{ii} | {\\bf W}_{if}| {\\bf W}_{ig} |{\\bf W}_{io}\\big] + {\\boldsymbol h}_{t-1} \\big[ {\\bf W}_{hi}|{\\bf W}_{hf} |{\\bf W}_{hg} | {\\bf W}_{ho} \\big] + bias\\)\n\\(=\\big[{\\boldsymbol x}_t{\\bf W}_{ii} + {\\boldsymbol h}_{t-1}{\\bf W}_{hi} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{if}+ {\\boldsymbol h}_{t-1}{\\bf W}_{hf}~ \\big|~ {\\boldsymbol x}_t{\\bf W}_{ig} + {\\boldsymbol h}_{t-1}{\\bf W}_{hg} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{io} + {\\boldsymbol h}_{t-1}{\\bf W}_{ho} \\big] + bias\\)\n참고: 위의 수식은 아래코드에 해당하는 부분\nifgo = xt @ lstm_cell.weight_ih.T +\\\n       ht @ lstm_cell.weight_hh.T +\\\n       lstm_cell.bias_ih + lstm_cell.bias_hh\n(step2) decompose \\({\\tt ifgo}\\) and get \\({\\boldsymbol i}_t\\), \\({\\boldsymbol f}_t\\), \\({\\boldsymbol g}_t\\), \\({\\boldsymbol o}_t\\)\n\\({\\boldsymbol i}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{ii} + {\\boldsymbol h}_{t-1} {\\bf W}_{hi} +bias )\\)\n\\({\\boldsymbol f}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{if} + {\\boldsymbol h}_{t-1} {\\bf W}_{hf} +bias )\\)\n\\({\\boldsymbol g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg} +bias )\\)\n\\({\\boldsymbol o}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{io} + {\\boldsymbol h}_{t-1} {\\bf W}_{ho} +bias )\\)\n(step3) calculate \\({\\boldsymbol c}_t\\) and \\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol c}_t = {\\boldsymbol i}_t \\odot {\\boldsymbol g}_t+ {\\boldsymbol f}_t \\odot {\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol h}_t = \\tanh({\\boldsymbol o}_t \\odot {\\boldsymbol c}_t)\\)"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm의-알고리즘-리뷰-ii-느낌위주",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm의-알고리즘-리뷰-ii-느낌위주",
    "title": "기계학습 (1116) 11주차",
    "section": "LSTM의 알고리즘 리뷰 II (느낌위주)",
    "text": "LSTM의 알고리즘 리뷰 II (느낌위주)\n\n이해 및 암기를 돕기위해서 비유적으로 설명한 챕터입니다..\n\n- 느낌1: RNN이 콩물에서 간장을 한번에 숙성시키는 방법이라면 LSTM은 콩물에서 간장을 3차로 나누어 숙성하는 느낌이다.\n\n콩물: \\({\\boldsymbol x}_t\\)\n1차숙성: \\({\\boldsymbol g}_t\\)\n2차숙성: \\({\\boldsymbol c}_t\\)\n3차숙성: \\({\\boldsymbol h}_t\\)\n\n- 느낌2: \\({\\boldsymbol g}_t\\)에 대하여\n\n계산방법: \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)를 \\({\\bf W}_{ig}, {\\bf W}_{hg}\\)를 이용해 선형결합하고 \\(\\tanh\\)를 취한 결과\nRNN에서 간장을 만들던 그 수식에서 \\(h_t\\)를 \\(g_t\\)로 바꾼것\n크게 2가지의 의미를 가진다 (1) 과거와 현재의 결합 (2) 활성화함수 \\(\\tanh\\)를 적용\n\n- 느낌3: \\({\\boldsymbol c}_t\\)에 대하여 (1)\n\n계산방법: \\({\\boldsymbol g}_{t}\\)와 \\({\\boldsymbol c}_{t-1}\\)를 요소별로 선택하고 더하는 과정\n\\(g_t\\)는 (1) 과거와 현재의 결합 (2) 활성화함수 tanh를 적용으로 나누어지는데 이중에서 (1) 과거와 현재의 정보를 결합하는 과정만 해당한다. 차이점은 요소별 선택 후 덧셈\n이러한 결합을 쓰는 이유? 게이트를 이용하여 과거와 현재의 정보를 제어 (일반적인 설명, 솔직히 내가 좋아하는 설명은 아님)\n\n- 느낌4: \\({\\boldsymbol c}_t\\)에 대하여 (2) // \\({\\boldsymbol c}_t\\)는 왜 과거와 현재의 정보를 제어한다고 볼 수 있는가?\n\\(t=1\\) 시점 계산과정관찰\n\ninput_gate[1],g[1],forget_gate[1],cell[0]    # g[1]:현재시점 cell[0]:과거시점\n\n(tensor([0.9065, 0.9999], grad_fn=&lt;SelectBackward0&gt;),\n tensor([0.9931, 0.9999], grad_fn=&lt;SelectBackward0&gt;),\n tensor([0.9931, 0.0014], grad_fn=&lt;SelectBackward0&gt;),\n tensor([ 0.3592, -0.9373], grad_fn=&lt;SelectBackward0&gt;))\n\n\n\\([0.9,1.0] \\odot {\\boldsymbol g}_t + [1.0,0.0] \\odot {\\boldsymbol c}_{t-1}\\)\n\nforget_gate는 \\(c_{t-1}\\)의 첫번째 원소는 기억하고, 두번째 원소는 잊으라고 말하고 있음 // forget_gate는 과거(\\(c_{t-1}\\))의 정보를 얼마나 잊을지 (= 얼마나 기억할지) 를 결정한다고 해석할 수 있다.\ninput_gate는 \\(g_{t}\\)의 첫번째 원소와 두번째 원소를 모두 기억하되 두번째 원소를 좀 더 중요하게 기억하라고 말하고 있음 // input_gate는 현재(\\(g_{t}\\))의 정보를 얼만큼 강하게 반영할지 결정한다.\n이 둘을 조합하면 \\({\\boldsymbol c}_t\\)가 현재와 과거의 정보중 어떠한 정보를 더 중시하면서 기억할지 결정한다고 볼 수 있다.\n\n\n이 설명은 제가 좀 싫어해요, 싫어하는 이유는 (1) “기억의 정도를 조절한다”와 “망각의 정도를 조절한다”는 사실 같은말임. 그래서 forget_gate의 용어가 모호함. (2) 기억과 망각을 조정하는 방식으로 꼭 gate의 개념을 사용해야 하는건 아님\n\n- 느낌5: \\({\\boldsymbol c}_t\\)에 대하여 (3)\n\n사실상 LSTM 알고리즘의 꽃이라 할 수 있음.\nLSTM은 long short term memory의 약자임. 기존의 RNN은 장기기억을 활용함에 약점이 있는데 LSTM은 단기기억/장기기억 모두 잘 활용함.\nLSTM이 장기기억을 잘 활용하는 비법은 바로 \\({\\boldsymbol c}_t\\)에 있다.\n\n- 느낌6: \\({\\boldsymbol h}_t\\)에 대하여 - 계산방법: \\(\\tanh({\\boldsymbol c}_t)\\)를 요소별로 선택\n- RNN, LSTM의 변수들 비교 테이블\n\n\n\n\n\n\n\n\n\n\n\n\n\n과거정보\n현재정보\n과거와 현재의 결합방식\n활성화\n느낌\n비고\n\n\n\n\nRNN-\\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\) \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n간장\n\n\n\n\n\n\n\n\n\n\n\n\nLSTM-\\({\\boldsymbol g}_t\\)\n\\({\\boldsymbol h}_{t-1}\\)\n\\({\\boldsymbol x}_t\\)\n\\(\\times\\) \\(\\to\\) \\(+\\)\n\\(\\tanh\\)\n1차간장\n\n\n\nLSTM-\\({\\boldsymbol c}_t\\)\n\\({\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol g}_t\\)\n\\(\\odot\\) \\(\\to\\) \\(+\\)\nNone\n2차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\nLSTM-\\({\\boldsymbol h}_t\\)\nNone\n\\({\\boldsymbol c}_t\\)\nNone\n\\(\\tanh\\), \\(\\odot\\)\n3차간장\ngate를 열림정도를 판단할때 \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)을 이용\n\n\n\n\nRNN은 기억할 과거정보가 \\({\\boldsymbol h}_{t-1}\\) 하나이지만 LSTM은 \\({\\boldsymbol c}_{t-1}\\), \\({\\boldsymbol h}_{t-1}\\) 2개이다.\n\n- 알고리즘리뷰 :\n\n콩물,과거3차간장 \\(\\overset{\\times,+,\\tanh}{\\longrightarrow}\\) 현재1차간장\n현재1차간장, 과거2차간장 \\(\\overset{\\odot,+,\\tanh}{\\longrightarrow}\\) 현재2차간장\n현재2차간장 \\(\\overset{\\tanh,\\odot}{\\longrightarrow}\\) 현재3차간장"
  },
  {
    "objectID": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm이-강한이유",
    "href": "posts/3. RNN/2022_11_16_11wk_ipynb의_사본.html#lstm이-강한이유",
    "title": "기계학습 (1116) 11주차",
    "section": "LSTM이 강한이유",
    "text": "LSTM이 강한이유\n- LSTM이 장기기억에 유리함. 그 이유는 input, forget, output gate 들이 과거기억을 위한 역할을 하기 때문.\n\n비판: 아키텍처에 대한 이론적 근거는 없음. 장기기억을 위하여 꼭 LSTM같은 구조일 필요는 없음. (왜 3차간장을 만들때 tanh를 써야하는지? 게이트는 꼭3개이어야 하는지?)\n\n- 저는 사실 아까 살펴본 아래의 이유로 이해하고 있습니다.\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RRN은 \\({\\boldsymbol h}_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\({\\boldsymbol h}_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\({\\boldsymbol h}_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? (1) gate들의 역할 (2) 마지막에 취해지는 tanh 때문"
  },
  {
    "objectID": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#import",
    "href": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#import",
    "title": "기계학습 (1109) 10주차",
    "section": "import",
    "text": "import\n\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#예비학습-net.parameters의-의미",
    "href": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#예비학습-net.parameters의-의미",
    "title": "기계학습 (1109) 10주차",
    "section": "예비학습: net.parameters()의 의미",
    "text": "예비학습: net.parameters()의 의미\n9월27일 강의노트 중 “net.parameters()의 의미?”를 설명한다.\n- iterator, generator의 개념필요 - https://guebin.github.io/IP2022/2022/06/06/(14주차)-6월6일.html, 클래스공부 8단계 참고\n- 탐구시작: 네트워크 생성\n\nnet = torch.nn.Linear(in_features=1,out_features=1)\nnet.weight\n\nParameter containing:\ntensor([[0.0003]], requires_grad=True)\n\n\n\nnet.bias\n\nParameter containing:\ntensor([0.0782], requires_grad=True)\n\n\n- torch.optim.SGD? 를 확인하면 params에 대한설명에 아래와 같이 되어있음\nparams (iterable): iterable of parameters to optimize or dicts defining\n        parameter groups\n- 설명을 읽어보면 params에 iterable object를 넣으라고 되어있음 (iterable object는 숨겨진 명령어로 __iter__를 가지고 있는 오브젝트를 의미)\n\nset(dir(net.parameters())) & {'__iter__'}\n\n{'__iter__'}\n\n\n\n# 만약  iter 가 아니면 & 했을때 빈값이 나옴 \n\n\n# for문 뒤에 오는 거.. iterable object\n# for i in [1,2,3] : 이런거.. 리스트, 스트링,, \n# lst.__ 뒤에 iter__ ~ \n\n- 무슨의미?\n\nfor param in net.parameters():\n    print(param)\n\nParameter containing:\ntensor([[0.0003]], requires_grad=True)\nParameter containing:\ntensor([0.0782], requires_grad=True)\n\n\n- 그냥 이건 이런느낌인데?\n\nfor param in [net.weight,net.bias]:\n    print(param)\n\nParameter containing:\ntensor([[0.0003]], requires_grad=True)\nParameter containing:\ntensor([0.0782], requires_grad=True)\n\n\n결론: net.parameters()는 net오브젝트에서 학습할 파라메터를 모두 모아 리스트같은 iterable object로 만드는 함수라 이해할 수 있다.\n- 응용예제1\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-22-regression.csv\") \nx=torch.tensor(df.x).float().reshape(100,1)\ny=torch.tensor(df.y).float().reshape(100,1)\n\n\nb = torch.tensor(-5.0,requires_grad=True)\nw = torch.tensor(10.0,requires_grad=True)\noptimizr = torch.optim.SGD([b,w],lr=1/10) ## 이렇게 전달하면 됩니당!!\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    ## step1\n    yhat = b+ w*x \n    ## step2\n    loss = torch.mean((y-yhat)**2)\n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(w*x+b).data,'--')\n\n\n\n\n- 응용예제2\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-22-regression.csv\") \nx = torch.tensor(df.x).float().reshape(100,1)\ny = torch.tensor(df.y).float().reshape(100,1)\nX = torch.concat([torch.ones_like(x),x],axis=1)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\noptimizr = torch.optim.SGD([What],lr=1/10) # What은 iterable 하지 않지만 [What]은 iterable 함\n\n\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n\nfor epoc in range(30):\n    ## step1\n    yhat = X@What \n    ## step2 \n    loss = torch.mean((y-yhat)**2)\n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nplt.plot(x,y,'o')\nplt.plot(x,(X@What).data,'--')\n\n\n\n\n\n스스로 학습 (중간고사 대비문제)\n아래와 같은 자료가 있다고 가정하자.\n\nx = torch.rand([1000,1])*2-1\ny = 3.14 + 6.28*x + torch.randn([1000,1]) \n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n아래의 모형을 가정하고 \\(\\alpha_0,\\alpha_1,\\beta_0,\\beta_1\\)을 파이토치를 이용하여 추정하고자한다.\n\n\\(y_i = \\alpha_0+\\beta_0+ \\beta_1x_i + \\alpha_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\)\n\n아래는 이를 수행하기 위한 코드이다. ???를 적절히 채워서 코드를 완성하라.\n\n항목 추가\n항목 추가\n\n\nalpha0 = torch.tensor([0.5], requires_grad=True)\nalpha1 = torch.tensor([[0.5]], requires_grad=True)\nbeta0 = torch.tensor([0.7], requires_grad=True)\nbeta1 = torch.tensor([[0.7]], requires_grad=True)\n\n\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD([alpha0,alpha1,beta0,beta1], lr=1/10)\n\n\nfor epoc in range(30):\n    ## 1\n    yhat = alpha0 + beta0 + alpha1*x + beta1*x \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nprint(alpha0+beta0)\n\ntensor([3.1593], grad_fn=&lt;AddBackward0&gt;)\n\n\n\n3.14 근처\n\n\nprint(alpha1+beta1)\n\ntensor([[6.0875]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\n6.28 근처"
  },
  {
    "objectID": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#define-some-funtions",
    "href": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#define-some-funtions",
    "title": "기계학습 (1109) 10주차",
    "section": "Define some funtions",
    "text": "Define some funtions\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsoft = torch.nn.Softmax(dim=1)"
  },
  {
    "objectID": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam2-abc",
    "href": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam2-abc",
    "title": "기계학습 (1109) 10주차",
    "section": "Exam2: abc",
    "text": "Exam2: abc\n\ndata\n\ntxt = list('abc')*100\ntxt[:10]\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'a', 'b'], ['b', 'c', 'a', 'b', 'c'])\n\n\n\n\n하나의 은닉노드를 이용한 풀이 – 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3,embedding_dim=1), #a,b,c 문자 3개니까 num_embeddings=3 쓰고 \n    torch.nn.Tanh(),\n    #===#\n    torch.nn.Linear(in_features=1,out_features=3)\n    #torch.nn.Softmax() 생략!\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2 \n    loss = loss_fn(net(x),y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과해석\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data \n\n\nplt.plot(hidden[:9],'--o')\n# 가운데:a 맨위:b, 맨아래:c\n\n\n\n\n\nplt.plot(net(x).data[:9],'--o')\n\n\n\n\n\nplt.plot(yhat[:9],'--o')\n\n\n\n\n\n억지로 맞추고있긴한데 파라메터가 부족해보인다.\n\n- 결과시각화1\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n첫 그림 -&gt; 두번째 그림\n\n# 첫번째그림 \nhidden[:9], (net[-1].weight.data).T, net[-1].bias.data\n\n(tensor([[-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896],\n         [-0.0147],\n         [ 0.9653],\n         [-0.9896]]),\n tensor([[-4.6804,  0.3071,  5.2894]]),\n tensor([-1.5440,  0.9143, -1.3970]))\n\n\n\n# hidden : n x 1 형태\n# new[-1] : 3 x 1 형태여서 trans\n\n\nhidden[:9]@(net[-1].weight.data).T + net[-1].bias.data\n\ntensor([[-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312],\n        [-1.4755,  0.9098, -1.4745],\n        [-6.0618,  1.2108,  3.7086],\n        [ 3.0875,  0.6104, -6.6312]])\n\n\n\n(파랑,주황,초록) 순서로 그려짐\n파랑 = hidden * (-4.6804) + (-1.5440)\n주황 = hidden * (0.3071) + (0.9143)\n초록 = hidden * (5.2894) + (-1.3970)\n\n- 내부동작을 잘 뜯어보니까 사실 엉성해. 엄청 위태위태하게 맞추고 있었음. - weight: 파랑과 초록을 구분하는 역할을 함 - weight + bias: 뭔가 교모하게 애매한 주황값을 만들어서 애매하게 ’b’라고 나올 확률을 학습시킨다. \\(\\to\\) 사실 학습하는 것 같지 않고 때려 맞추는 느낌, 쓸수있는 weight가 한정적이라서 생기는 현상 (양수,음수,0)\n\n참고: torch.nn.Linear()의 비밀? - 사실 \\({\\boldsymbol y}={\\boldsymbol x}{\\bf W} + {\\boldsymbol b}\\) 꼴에서의 \\({\\bf W}\\)와 \\({\\boldsymbol b}\\)가 저장되는게 아니다. - \\({\\boldsymbol y}={\\boldsymbol x}{\\bf A}^T + {\\boldsymbol b}\\) 꼴에서의 \\({\\bf A}\\)와 \\({\\boldsymbol b}\\)가 저장된다. - \\({\\bf W} = {\\bf A}^T\\) 인 관계에 있으므로 l1.weight 가 우리가 생각하는 \\({\\bf W}\\) 로 해석하려면 사실 transpose를 취해줘야 한다.\n왜 이렇게..? - 계산의 효율성 때문 (numpy의 구조를 알아야함) - \\({\\boldsymbol x}\\), \\({\\boldsymbol y}\\) 는 수학적으로는 col-vec 이지만 메모리에 저장할시에는 row-vec 로 해석하는 것이 자연스럽다. (사실 메모리는 격자모양으로 되어있지 않음)\n잠깐 딴소리!!\n(예시1)\n\n_arr = np.array(range(4)).reshape(2,2)\n\n\n_arr.strides\n\n(16, 8)\n\n\n\n아래로 한칸 = 16칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시2)\n\n_arr = np.array(range(6)).reshape(3,2)\n\n\n_arr.strides\n\n(16, 8)\n\n\n\n아래로 한칸 = 16칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시3)\n\n_arr = np.array(range(6)).reshape(2,3)\n\n\n_arr.strides\n\n(24, 8)\n\n\n\n아래로 한칸 = 24칸 jump\n오른쪽으로 한칸 = 8칸 jump\n\n(예시4)\n\n_arr = np.array(range(4),dtype=np.int8).reshape(2,2)\n\n\n_arr\n\narray([[0, 1],\n       [2, 3]], dtype=int8)\n\n\n\n_arr.strides\n\n(2, 1)\n\n\n\n아래로한칸 = 2칸 (= 2바이트 jump = 16비트 jump)\n오른쪽으로 한칸 = 1칸 jump (= 1바이트 jump = 8비트 jump)\n\n진짜 참고..\n\n1바이트 = 8비트\n1바이트는 2^8=256 의 정보 표현\nnp.int8은 8비트로 정수를 저장한다는 의미\n\n\n2**8\n\n256\n\n\n\nprint(np.array(55,dtype=np.int8))\nprint(np.array(127,dtype=np.int8))\nprint(np.array(300,dtype=np.int8)) # overflow \n\n55\n127\n44\n\n\n딴소리 끝!!\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([299, 7])\n\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(7), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam3-abcd",
    "href": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam3-abcd",
    "title": "기계학습 (1109) 10주차",
    "section": "Exam3: abcd",
    "text": "Exam3: abcd\n\ndata\n\ntxt = list('abcd')*100\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'd', 'a'], ['b', 'c', 'd', 'a', 'b'])\n\n\n\n\n하나의 은닉노드를 이용한 풀이 – 억지로 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nnet[0].weight.data = torch.tensor([[-0.3333],[-2.5000],[5.0000],[0.3333]])\n\nnet[-1].weight.data = torch.tensor([[1.5000],[-6.0000],[-2.0000],[6.0000]])\nnet[-1].bias.data = torch.tensor([0.1500, -2.0000,  0.1500, -2.000])\n\n\nfor epoc in range(5000):\n    ## 1\n    ## 2 \n    loss = loss_fn(net(x),y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 9])\n\n\n\nplt.matshow(combined[:15],vmin=-15,vmax=15,cmap='bwr')\nplt.xticks(range(9), labels=[r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\n\n두개의 은닉노드를 이용한 풀이 – 깔끔한 성공\n- 데이터정리\n\nmapping = {'a':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 0]), tensor([1, 2, 3, 0, 1]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([399, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-7,vmax=7,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=a?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=a)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam4-abcde-스스로-공부",
    "href": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam4-abcde-스스로-공부",
    "title": "기계학습 (1109) 10주차",
    "section": "Exam4: abcde (스스로 공부)",
    "text": "Exam4: abcde (스스로 공부)\n\ndata\n주어진 자료가 다음과 같다고 하자.\n\ntxt = list('abcde')*100\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'e', 'a', 'b', 'c', 'd', 'e']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['a', 'b', 'c', 'd', 'e'], ['b', 'c', 'd', 'e', 'a'])\n\n\n아래 코드를 변형하여 적절한 네트워크를 설계하고 위의 자료를 학습하라. (깔끔한 성공을 위한 최소한의 은닉노드를 설정할 것)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=??,embedding_dim=??),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=??,out_features=??)\n)\n\n\n3개의 은닉노드를 이용한 풀이\na,b,c,d,e 를 표현함에 있어서 3개의 은닉노드면 충분하다. - 1개의 은닉노드 -&gt; 2개의 문자를 표현할 수 있음. - 2개의 은닉노드 -&gt; 4개의 문자를 표현할 수 있음. - 3개의 은닉노드 -&gt; 8개의 문자를 표현할 수 있음.\n\nmapping = {'a':0,'b':1,'c':2,'d':3,'e':4}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 3, 4]), tensor([1, 2, 3, 4, 0]))\n\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=5,embedding_dim=3),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=3,out_features=5)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([499, 13])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(13), labels=[r'$h$',r'$h$',r'$h$',\n                              r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$y=e?$',\n                              r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$',r'$P(y=e)$'],size=13)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')"
  },
  {
    "objectID": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam5-abacad",
    "href": "posts/3. RNN/2022_11_09_(10주차)_11월9일_ipynb의_사본.html#exam5-abacad",
    "title": "기계학습 (1109) 10주차",
    "section": "Exam5: AbAcAd",
    "text": "Exam5: AbAcAd\n\ndata\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\n\n두개의 은닉노드를 이용한 풀이 – 실패\n- 데이터정리\n\nmapping = {'A':0,'b':1,'c':2,'d':3}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 0, 2, 0]), tensor([1, 0, 2, 0, 3]))\n\n\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nhidden = net[:-1](x).data\nyhat = soft(net(x)).data\n\n\nfig,ax = plt.subplots(1,3,figsize=(15,5))\nax[0].plot(hidden[:9],'--o'); ax[0].set_title('$h:=(tanh \\circ linr_1)(x)$',size=15)\nax[1].plot(net(x).data[:9],'--o'); ax[1].set_title('$net(x):=(linr_2 \\circ tanh \\circ linr_1)(x)$',size=15)\nax[2].plot(yhat[:9],'--o'); ax[2].set_title('$\\hat{y}$ = softmax$(net(x))$',size=15);\nfig.suptitle(r\"Vis1: $h,net(x),\\hat{y}$\",size=20)\nplt.tight_layout()\n\n\n\n\n- 결과시각화2\n\ncombined  = torch.concat([hidden,net(x).data,yhat],axis=1)\ncombined.shape\n\ntorch.Size([599, 10])\n\n\n\nplt.matshow(combined[:15],vmin=-5,vmax=5,cmap='bwr')\nplt.xticks(range(10), labels=[r'$h$',r'$h$',r'$y=A?$',r'$y=b?$',r'$y=c?$',r'$y=d?$',r'$P(y=A)$',r'$P(y=b)$',r'$P(y=c)$',r'$P(y=d)$'],size=14)\nplt.colorbar()\nplt.gcf().set_figwidth(15)\nplt.gcf().set_figheight(15)\nplt.title(r\"Vis2: $[h | net(x) | \\hat{y}]$\",size=25)\n\nText(0.5, 1.0, 'Vis2: $[h | net(x) | \\\\hat{y}]$')\n\n\n\n\n\n\n실패\n\n- 실패를 해결하는 순진한 접근방식: 위 문제를 해결하기 위해서는 아래와 같은 구조로 데이터를 다시 정리하면 될 것이다.\n\n\n\nX\ny\n\n\n\n\nA,b\nA\n\n\nb,A\nc\n\n\nA,c\nA\n\n\nc,A\nd\n\n\nA,d\nA\n\n\nd,A\nb\n\n\nA,b\nA\n\n\nb,A\nc\n\n\n…\n…\n\n\n\n- 순진한 접근방식의 비판: - 결국 정확하게 직전 2개의 문자를 보고 다음 문제를 예측하는 구조 - 만약에 직전 3개의 문자를 봐야하는 상황이 된다면 또 다시 코드를 수정해야함. - 그리고 실전에서는 직전 몇개의 문자를 봐야하는지 모름.\n\n# \n# x1 -&gt; y1\n# x1, x2 -&gt; y2\n# x1, x2, x3 -&gt; y3\n# x1, x2, x3, x4 -&gt; y4\n# ...\n\n이것에 대한 해결책은 순환신경망이다.\n\n\n순환망을 위하여 data 다시정리\n- 기존의 정리방식\n\ntxt = list('AbAcAd')*100\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5]\n\n(['A', 'b', 'A', 'c', 'A'], ['b', 'A', 'c', 'A', 'd'])\n\n\n\nx = torch.tensor(f(txt_x,{'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(f(txt_y,{'A':0,'b':1,'c':2,'d':3}))\n\n\nx[:8],y[:8]\n\n(tensor([0, 1, 0, 2, 0, 3, 0, 1]), tensor([1, 0, 2, 0, 3, 0, 1, 0]))\n\n\n- 이번엔 원핫인코딩형태까지 미리 정리하자. (임베딩 레이어 안쓸예정)\n\nx= torch.nn.functional.one_hot(x).float()\ny= torch.nn.functional.one_hot(y).float()\n\n\nx,y\n\n(tensor([[1., 0., 0., 0.],\n         [0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         ...,\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.]]),\n tensor([[0., 1., 0., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 1., 0.],\n         ...,\n         [0., 0., 1., 0.],\n         [1., 0., 0., 0.],\n         [0., 0., 0., 1.]]))\n\n\n\n\n실패했던 풀이의 재구현1\n- 방금 실패한 풀이\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n- Tanh까지만 클래스로 바꾸어서 구현 - 클래스를 이용하는 방법: https://guebin.github.io/DL2022/2022/11/01/(9주차)-11월1일.html#로지스틱-모형을-이용한-풀이\n\nclass Hnet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        # 사용할 레이어 정의\n        self.i2h = torch.nn.Linear(in_features=4,out_features=2) #input에 들어가서 hidden을 만들어주는 ?  # 이름만들땐 self를 붙여주기\n        self.tanh = torch.nn.Tanh() # 두레이어 통과시켜서 hidden 출력! \n    def forward(self,x):\n      # yhat을 어떻게 구현할 것인지 정의 \n        hidden = self.tanh(self.i2h(x)) \n        return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()))\n\n\n# hne.parameters() 안에 뭔 값이 있는데 안보이니까 list화 시키기 \n\n- for문: 20회반복\n\nfor epoc in range(20): \n    ## 1 \n    ## 2 \n    hidden = hnet(x) \n    output = linr(hidden)\n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 &lt;– 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n\n실패했던 풀이의 재구현2\n- Tanh까지 구현한 클래스\n\n\n# class Hnet(torch.nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         self.i2h = torch.nn.Linear(in_features=4,out_features=2)\n#         self.tanh = torch.nn.Tanh()\n#     def forward(self,x):\n#         hidden = self.tanh(self.i2h(x))\n#         return hidden\n\n- for문돌릴준비\n\ntorch.manual_seed(43052) \nhnet = Hnet()\nlinr = torch.nn.Linear(in_features=2,out_features=4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()))\n\n- for문: 20회 반복\n\nT = len(x) \nfor epoc in range(20): \n    ## 1~2\n    loss = 0 \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = hnet(xt) \n        ot = linr(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- linr(hnet(x)) 적합결과 &lt;– 숫자체크\n\nlinr(hnet(x))\n\ntensor([[-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.2912,  0.8140, -0.2032,  0.0178],\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        ...,\n        [-0.3589,  0.7921, -0.1970, -0.0302],\n        [-0.1065,  0.6307, -0.0874,  0.1821],\n        [-0.3589,  0.7921, -0.1970, -0.0302]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n\n순환신경망의 아이디어\n\n모티브\n(예비생각1) \\({\\boldsymbol h}\\)에 대한 이해\n\\({\\boldsymbol h}\\)는 사실 문자열 ’abcd’들을 숫자로 바꾼 또 다른 형식의 숫자표현이라 해석할 수 있음. 즉 원핫인코딩과 다른 또 다른 형태의 숫자표현이라 해석할 수 있다. (사실 원핫인코딩보다 약간 더 (1) 액기스만 남은 느낌 + (2) 숙성된 느낌을 준다) - (why1) h는 “학습을 용이하게 하기 위해서 x를 적당히 선형적으로 전처리한 상태”라고 이해가능 - (why2) 실제로 예시를 살펴보면 그러했다.\n결론: 사실 \\({\\boldsymbol h}\\)는 잘 숙성되어있는 입력정보 \\({\\bf X}\\) 그 자체로 해석 할 수 있다.\n(예비생각2) 수백년전통을 이어가는 방법\n“1리터에 500만원에 낙찰된 적 있습니다.”\n“2kg에 1억원 정도 추산됩니다.”\n“20여 종 종자장을 블렌딩해 100ml에 5000만원씩 분양 예정입니다.”\n\n모두 씨간장(종자장) 가격에 관한 실제 일화다.\n\n(중략...)\n\n위스키나 와인처럼 블렌딩을 하기도 한다. \n새로 담근 간장에 씨간장을 넣거나, 씨간장독에 햇간장을 넣어 맛을 유지하기도 한다. \n이를 겹장(또는 덧장)이라 한다. \n몇몇 종갓집에선 씨간장 잇기를 몇백 년째 해오고 있다. \n매년 새로 간장을 담가야 이어갈 수 있으니 불씨 꺼트리지 않는 것처럼 굉장히 어려운 일이다.\n이렇게 하는 이유는 집집마다 내려오는 고유 장맛을 잃지 않기 위함이다. \n씨간장이란 그만큼 소중한 주방의 자산이며 정체성이다.\n덧장: 새로운간장을 만들때, 옛날간장을 섞어서 만듬\n* 기존방식 - \\(\\text{콩물} \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}\\)\n* 수백년 전통의 간장맛을 유지하는 방식\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3\\)\n\n* 수백년 전통의 간장맛을 유지하면서 조리를 한다면?\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n점점 맛있는 간장계란밥이 탄생함\n* 알고리즘의 편의상 아래와 같이 생각해도 무방\n\n\\(\\text{콩물}_1, \\text{간장}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\), \\(\\text{간장}_0=\\text{맹물}\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n아이디어\n* 수백년 전통의 간장맛을 유지하면서 조리하는 과정을 수식으로?\n\n\\(\\boldsymbol{x}_1, \\boldsymbol{h}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_1 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_1\\)\n\\(\\boldsymbol{x}_2, \\boldsymbol{h}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_2 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_2\\)\n\\(\\boldsymbol{x}_3, \\boldsymbol{h}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_3 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_3\\)\n\n이제 우리가 배울것은 (1) “\\(\\text{콩물}_{t}\\)”와 “\\(\\text{간장}_{t-1}\\)”로 “\\(\\text{간장}_t\\)”를 숙성하는 방법 (2) “\\(\\text{간장}_t\\)”로 “\\(\\text{간장계란밥}_t\\)를 조리하는 방법이다\n즉 숙성담당 네트워크와 조리담당 네트워크를 각각 만들어 학습하면 된다.\n\n\n알고리즘\n세부적인 알고리즘 (\\(t=0,1,2,\\dots\\)에 대하여 한줄 한줄 쓴 알고리즘)\n\n\\(t=0\\)\n\n\\({\\boldsymbol h}_0=[[0,0]]\\) &lt;– \\(\\text{간장}_0\\)은 맹물로 초기화\n\n\\(t=1\\)\n\n\\({\\boldsymbol h}_1= \\tanh({\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\) - \\({\\boldsymbol x}_1\\): (1,4) - \\({\\bf W}_{ih}\\): (4,2) - \\({\\boldsymbol h}_0\\): (1,2) - \\({\\bf W}_{hh}\\): (2,2) - \\({\\boldsymbol b}_{ih}\\): (1,2) - \\({\\boldsymbol b}_{hh}\\): (1,2)\n\\({\\boldsymbol o}_1= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_1 = \\text{soft}({\\boldsymbol o}_1)\\)\n\n\\(t=2\\) &lt;– 여기서부터는 \\(t=2\\)와 비슷\n\n\n좀 더 일반화된 알고리즘\n(ver1)\ninit \\(\\boldsymbol{h}_0\\)\nfor \\(t\\) in \\(1:T\\)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol x}_t{\\bf W}_{ih}+{\\boldsymbol h}_{t-1}{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\\({\\boldsymbol o}_t= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_t = \\text{soft}({\\boldsymbol o}_t)\\)\n\n(ver2)\ninit hidden\n\nfor t in 1:T \n    hidden = tanh(linr(x)+linr(hidden)) # 더하기 위해서 linr 해준다\n    # t시점 간장              # t-1시점 간장\n    output = linr(hidden)\n    yt_hat = soft(output)\n\n코드상으로는 \\(h_t\\)와 \\(h_{t-1}\\)의 구분이 교모하게 사라진다. (그래서 오히려 좋아)\n\n\n전체알고리즘은 대충 아래와 같은 형식으로 구현될 수 있음\n### \nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        linr1 = torch.nn.Linear(?,?) \n        linr2 = torch.nn.Linear(?,?) \n        tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = tanh(lrnr1(x)+lrnr2(hidden))\n        return hidden\n\ninit ht\nrnncell = rNNCell()\n\nfor t in 1:T \n    xt, yt = x[[t]], y[[t]] \n    ht = rnncell(xt, ht)\n    ot = linr(ht) \n    loss = loss + loss_fn(ot, yt)\n\n\n\n순환신경망 구현1 – 성공\n(1) 숙성담당 네트워크\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) # 입력이 h로 간다...i2h\n        self.h2h = torch.nn.Linear(2,2) # h 에서 h 로~ \n        self.tanh = torch.nn.Tanh()\n    def forward(self,x,hidden):\n        hidden = self.tanh(self.i2h(x)+self.h2h(hidden))\n        return hidden\n\n\ntorch.manual_seed(43052)\nrnncell = rNNCell() # 숙성담당 네트워크 \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수  # 학습만 했기 때문에 어디에 저장해야해~ \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n&lt;matplotlib.image.AxesImage at 0x7f919046aed0&gt;\n\n\n\n\n\n\n아주 특이한 특징: yhat[:15], yhat[:-15] 의 적합결과가 다르다\n왜? 간장계란밥은 간장이 중요한데, 간장은 시간이 갈수록 맛있어지니까..\n\n\n\n순환신경망 구현2 (with RNNCell) – 성공\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n(1) 숙성네트워크\n선언\n\nrnncell = torch.nn.RNNCell(4,2)\n\n가중치초기화 (순환신경망 구현1과 동일하도록)\n\ntorch.manual_seed(43052)\n_rnncell = rNNCell()\n\n\nrnncell.weight_ih.data = _rnncell.i2h.weight.data \nrnncell.weight_hh.data = _rnncell.h2h.weight.data \nrnncell.bias_hh.data = _rnncell.h2h.bias.data \nrnncell.bias_ih.data = _rnncell.i2h.bias.data \n\n(2) 조리담당 네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4) \n\n(3) 손실함수, 옵티마이저 설계\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()))\n\n(4) 학습 (6분정도 걸림)\n\nT = len(x) \nfor epoc in range(5000): \n    ## 1~2\n    loss = 0 \n    ht = torch.zeros(1,2) \n    for t in range(T):\n        xt,yt = x[[t]], y[[t]]\n        ht = rnncell(xt,ht) \n        ot = cook(ht) \n        loss = loss + loss_fn(ot,yt) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]]) \n\n\nyhat = soft(cook(hidden))\nyhat\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat.data[-15:])\n\n&lt;matplotlib.image.AxesImage at 0x7f917546d210&gt;\n\n\n\n\n\n\n\n순환신경망 구현3 (with RNN) – 성공\n(예비학습)\n- 아무리 생각해도 yhat구하려면 좀 귀찮음\n\nT = len(x) \nhidden = torch.zeros(T,2) # 599년치 h를 담을 변수 \n_water = torch.zeros(1,2) # 맹물 \nhidden[[0]] = rnncell(x[[0]],_water) \nfor t in range(1,T):\n    hidden[[t]] = rnncell(x[[t]],hidden[[t-1]])\n\n\nsoft(cook(hidden))\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n- 이렇게 하면 쉽게(?) 구할 수 있음\n\nrnn = torch.nn.RNN(4,2) \n\n\nrnn.weight_hh_l0.data = rnncell.weight_hh.data \nrnn.bias_hh_l0.data = rnncell.bias_hh.data \nrnn.weight_ih_l0.data = rnncell.weight_ih.data \nrnn.bias_ih_l0.data = rnncell.bias_ih.data \n\n\n_water\n\ntensor([[0., 0.]])\n\n\n\nsoft(cook(rnn(x,_water)[0]))\n\ntensor([[1.6522e-02, 6.2036e-01, 1.0433e-01, 2.5879e-01],\n        [9.9965e-01, 6.5788e-05, 1.8450e-05, 2.6785e-04],\n        [7.6673e-05, 1.9704e-01, 8.0201e-01, 8.7218e-04],\n        ...,\n        [7.4634e-05, 1.9501e-01, 8.0407e-01, 8.4751e-04],\n        [9.4785e-01, 7.4711e-03, 6.1182e-04, 4.4064e-02],\n        [3.6306e-02, 1.2466e-01, 2.8862e-03, 8.3615e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\n똑같음!\n\n- rnn(x,_water)의 결과는 (1) 599년치 간장 (2) 599번째 간장 이다\n\nrnn(x,_water)\n\n(tensor([[-0.2232,  0.9769],\n         [-0.9999, -0.9742],\n         [ 0.9154,  0.9992],\n         ...,\n         [ 0.9200,  0.9992],\n         [-0.9978, -0.0823],\n         [-0.9154,  0.9965]], grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([[-0.9154,  0.9965]], grad_fn=&lt;SqueezeBackward1&gt;))\n\n\n(예비학습결론) torch.nn.RNN(4,2)는 torch.nn.RNNCell(4,2)의 batch 버전이다. (for문이 포함된 버전이다)\n\ntorch.nn.RNN(4,2)를 이용하여 구현하자.\n(1) 숙성네트워크\n선언\n\ntorch.manual_seed(43052)\nrnn = torch.nn.RNN(4,2)\n\n(2) 조리네트워크\n\ntorch.manual_seed(43052)\ncook = torch.nn.Linear(2,4)\n\n(3) 손실함수와 옵티마이저\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters())) # 우리가 배울것: 숙성하는 방법 + 요리하는 방법 \n\n(4) 학습\n\nfor epoc in range(5000):\n    ## 1\n    _water = torch.zeros(1,2)\n    hidden, _ = rnn(x,_water)\n    output = cook(hidden)\n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n(5) 시각화\n\nyhat = soft(cook(rnn(x,_water)[0]))\nyhat\n\ntensor([[1.9725e-02, 1.5469e-03, 8.2766e-01, 1.5106e-01],\n        [9.1875e-01, 1.6513e-04, 6.7703e-02, 1.3384e-02],\n        [2.0031e-02, 1.0659e-03, 8.5248e-01, 1.2642e-01],\n        ...,\n        [1.9640e-02, 1.3568e-03, 8.3705e-01, 1.4196e-01],\n        [9.9564e-01, 1.3114e-05, 3.5069e-03, 8.4108e-04],\n        [3.5473e-03, 1.5670e-01, 1.4102e-01, 6.9873e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nplt.matshow(yhat.data[:15])\n\n&lt;matplotlib.image.AxesImage at 0x7f91754970d0&gt;\n\n\n\n\n\n\n!git add .\n!git commit -m .\n!git push\n\n[master abb1501] .\n 1 file changed, 4132 insertions(+)\n create mode 100644 \"_notebooks/2022-11-09-(10\\354\\243\\274\\354\\260\\250) 11\\354\\233\\2249\\354\\235\\274.ipynb\"\nEnumerating objects: 6, done.\nCounting objects: 100% (6/6), done.\nDelta compression using up to 16 threads\nCompressing objects: 100% (4/4), done.\nWriting objects: 100% (4/4), 814.34 KiB | 23.95 MiB/s, done.\nTotal 4 (delta 2), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo https://github.com/guebin/STML2022.git\n   b77134c..abb1501  master -&gt; master"
  },
  {
    "objectID": "posts/2022_12_21_Extra_1_ipynb의_사본.html",
    "href": "posts/2022_12_21_Extra_1_ipynb의_사본.html",
    "title": "기계학습 (1221)",
    "section": "",
    "text": "import torch\nimport numpy as np \nimport pandas as pd\nfrom fastai.collab import *"
  },
  {
    "objectID": "posts/2022_12_21_Extra_1_ipynb의_사본.html#주절주절-intro",
    "href": "posts/2022_12_21_Extra_1_ipynb의_사본.html#주절주절-intro",
    "title": "기계학습 (1221)",
    "section": "주절주절 intro",
    "text": "주절주절 intro\n- Data\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/STML2022/main/posts/V.%20RecSys/2022-12-21-rcmdsolo.csv',index_col=0)\ndf_view \n\n\n  \n    \n      \n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n- 데이터를 이해할때 필요한 가정들 – 내맘대로 한 설정임.\n\n(옥순,영자,정숙)은 (영식,영철,영호)와 성격이 잘 맞고 (영숙,순자,현숙)은 (광수,상철,영수)와 성격이 잘맞음\n((옥순,영자,정숙),(영식,영철,영호))은 MBTI가 I로 시작하고 ((영숙,순자,현숙),(광수,상철,영수))는 MBTI가 E로 시작한다.\n\n- 목표: NaN 을 추론\n- 수동추론:\n\n(옥순,영호)이 만난다면? \\(\\to\\) 둘다 I성향이니까 잘 맞지 않을까? \\(\\to\\) 4.0 정도?\n(정숙,영식)조합은? \\(\\to\\) 둘다 I성향이니까 잘 맞지 않을까? + 정숙은 다 잘맞던데..? \\(\\to\\) 4.8 정도?\n(현숙,영식)조합은? \\(\\to\\) 현숙은 E성향인데 영식은 I성향이므로 잘 안맞을 것임 + 현숙은 원래 좀 눈이 높음 \\(\\to\\) 0.25 정도?\n\n- 좀 더 체계적인 추론\n사람들이 가지고 있는 성향들을 두 개의 숫자로 표현하자.\n\n옥순의 성향 = (I성향,E성향) = (1.9, 0.0)\n영식의 성향 = (I성향,E성향) = (2.0, 0.1)\n현숙의 성향 = (I성향,E성향) = (0.0, 1.5)\n\n(1) 옥순과 영식의 궁합 \\(\\approx\\) 옥순의I성향\\(\\times\\)영식의I성향 \\(+\\) 옥순의E성향\\(\\times\\)영식의E성향 // 적합\n\na1= np.array([1.9,0.0]).reshape(2,1) # a1은 옥순의 성향, col-vec으로 선언하자. \nb1= np.array([2.0,0.1]).reshape(2,1) # b1은 영식의 성향, col-vec으로 선언하자.\n(a1*b1).sum()\n\n3.8\n\n\n(2) 현숙과 영식의 궁합 \\(\\approx\\) 현숙의I성향\\(\\times\\)영식의I성향 \\(+\\) 현숙의E성향\\(\\times\\)영식의E성향 // 예측\n\na6= np.array([0.0,1.5]).reshape(2,1)\n(a6*b1).sum()\n\n0.15000000000000002\n\n\n\n그럴듯함..\n\n- 모델링\n아래가 같음을 관찰하라. (차원만 다름)\n\n(a1*b1).sum(), a1.T@b1\n\n(3.8, array([[3.8]]))\n\n\n\n(a6*b1).sum(), a6.T@b1\n\n(0.15000000000000002, array([[0.15]]))\n\n\n만약에 여자의성향, 남자의성향을 적당한 매트릭스로 정리할 수 있다면 궁합매트릭스를 만들 수 있음\n\na1= np.array([1.9,0.0]).reshape(2,1)\na2= np.array([2.0,0.1]).reshape(2,1)\na3= np.array([2.5,1.0]).reshape(2,1)\na4= np.array([0.1,1.9]).reshape(2,1)\na5= np.array([0.2,2.1]).reshape(2,1)\na6= np.array([0.0,1.5]).reshape(2,1)\nA = np.concatenate([a1,a2,a3,a4,a5,a6],axis=1)\nA\n\narray([[1.9, 2. , 2.5, 0.1, 0.2, 0. ],\n       [0. , 0.1, 1. , 1.9, 2.1, 1.5]])\n\n\n\nb1= np.array([2.0,0.1]).reshape(2,1)\nb2= np.array([1.9,0.2]).reshape(2,1)\nb3= np.array([1.8,0.3]).reshape(2,1)\nb4= np.array([0.3,2.1]).reshape(2,1)\nb5= np.array([0.2,2.0]).reshape(2,1)\nb6= np.array([0.1,1.9]).reshape(2,1)\nB = np.concatenate([b1,b2,b3,b4,b5,b6],axis=1)\nB\n\narray([[2. , 1.9, 1.8, 0.3, 0.2, 0.1],\n       [0.1, 0.2, 0.3, 2.1, 2. , 1.9]])\n\n\n\nA.T@B\n\narray([[3.8 , 3.61, 3.42, 0.57, 0.38, 0.19],\n       [4.01, 3.82, 3.63, 0.81, 0.6 , 0.39],\n       [5.1 , 4.95, 4.8 , 2.85, 2.5 , 2.15],\n       [0.39, 0.57, 0.75, 4.02, 3.82, 3.62],\n       [0.61, 0.8 , 0.99, 4.47, 4.24, 4.01],\n       [0.15, 0.3 , 0.45, 3.15, 3.  , 2.85]])\n\n\n\na1.T@b1, a2.T@b2, a3.T@b1\n\n(array([[3.8]]), array([[3.82]]), array([[5.1]]))\n\n\n결국 모형은 아래와 같다.\n\\[\\text{궁합매트릭스} = {\\bf A}^\\top {\\bf B} + \\text{오차}\\]\n- 학습전략: 아래의 매트릭스중에서 어떤값은 관측하였고 어떤값은 관측하지 못함 \\(\\to\\) 관측한 값들만 대충 비슷하게 하면 되는거 아니야?\n\nA.T@B \n\narray([[3.8 , 3.61, 3.42, 0.57, 0.38, 0.19],\n       [4.01, 3.82, 3.63, 0.81, 0.6 , 0.39],\n       [5.1 , 4.95, 4.8 , 2.85, 2.5 , 2.15],\n       [0.39, 0.57, 0.75, 4.02, 3.82, 3.62],\n       [0.61, 0.8 , 0.99, 4.47, 4.24, 4.01],\n       [0.15, 0.3 , 0.45, 3.15, 3.  , 2.85]])\n\n\n\ndf_view\n\n\n  \n    \n      \n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n- 자료를 아래와 같이 정리한다면?\n\ndf = pd.DataFrame([(f,m,df_view.loc[f,m]) for f in df_view.index for m in df_view.columns if not np.isnan(df_view.loc[f,m])])\ndf.columns = ['X1','X2','y']\ndf\n\n\n  \n    \n      \n\n\n\n\n\n\nX1\nX2\ny\n\n\n\n\n0\n옥순\n영식\n3.9\n\n\n1\n옥순\n영철\n4.1\n\n\n2\n옥순\n광수\n0.5\n\n\n3\n옥순\n상철\n0.3\n\n\n4\n영자\n영식\n4.5\n\n\n5\n영자\n영호\n3.7\n\n\n6\n영자\n광수\n0.5\n\n\n7\n영자\n영수\n0.2\n\n\n8\n정숙\n영철\n4.9\n\n\n9\n정숙\n영호\n4.7\n\n\n10\n정숙\n상철\n1.2\n\n\n11\n정숙\n영수\n1.3\n\n\n12\n영숙\n영식\n0.6\n\n\n13\n영숙\n영철\n0.2\n\n\n14\n영숙\n광수\n4.1\n\n\n15\n영숙\n상철\n4.3\n\n\n16\n순자\n영식\n0.7\n\n\n17\n순자\n영철\n0.9\n\n\n18\n순자\n광수\n4.2\n\n\n19\n순자\n영수\n3.9\n\n\n20\n현숙\n영철\n0.2\n\n\n21\n현숙\n영호\n0.3\n\n\n22\n현숙\n상철\n3.5\n\n\n23\n현숙\n영수\n3.4\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nmapp1 = {k[1]:k[0] for k in enumerate(df.X1.unique())}\nmapp2 = {k[1]:k[0] for k in enumerate(df.X2.unique())}\nmapp1,mapp2\n\n({'옥순': 0, '영자': 1, '정숙': 2, '영숙': 3, '순자': 4, '현숙': 5},\n {'영식': 0, '영철': 1, '광수': 2, '상철': 3, '영호': 4, '영수': 5})\n\n\n\nX1 = torch.tensor(list(map(lambda name: mapp1[name], df.X1)))\nX2 = torch.tensor(list(map(lambda name: mapp2[name], df.X2)))\nX1 = torch.nn.functional.one_hot(X1).float()\nX2 = torch.nn.functional.one_hot(X2).float()\ny = torch.tensor(df.y).float()\n\n\nX1\n\ntensor([[1., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 1.]])\n\n\n- yhat을 구하는 과정..\n\nl1 = torch.nn.Linear(in_features=6,out_features=2) # I성향 E성향.. #여출 \nl2 = torch.nn.Linear(in_features=6,out_features=2) # 남출\n\n\nl1(X1) # 옥순~현숙의 성향들 \n\ntensor([[-0.1484,  0.1981],\n        [-0.1484,  0.1981],\n        [-0.1484,  0.1981],\n        [-0.1484,  0.1981],\n        [-0.1659,  0.7817],\n        [-0.1659,  0.7817],\n        [-0.1659,  0.7817],\n        [-0.1659,  0.7817],\n        [ 0.1933,  0.7089],\n        [ 0.1933,  0.7089],\n        [ 0.1933,  0.7089],\n        [ 0.1933,  0.7089],\n        [ 0.0649,  0.3645],\n        [ 0.0649,  0.3645],\n        [ 0.0649,  0.3645],\n        [ 0.0649,  0.3645],\n        [ 0.3438,  0.2501],\n        [ 0.3438,  0.2501],\n        [ 0.3438,  0.2501],\n        [ 0.3438,  0.2501],\n        [-0.2503,  0.4676],\n        [-0.2503,  0.4676],\n        [-0.2503,  0.4676],\n        [-0.2503,  0.4676]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nl2(X2) # 영식~영수의 성향들 \n\ntensor([[ 0.2230,  0.3115],\n        [-0.1752, -0.0627],\n        [ 0.2852,  0.4847],\n        [-0.2893,  0.2159],\n        [ 0.2230,  0.3115],\n        [ 0.1466, -0.0453],\n        [ 0.2852,  0.4847],\n        [-0.4553,  0.3573],\n        [-0.1752, -0.0627],\n        [ 0.1466, -0.0453],\n        [-0.2893,  0.2159],\n        [-0.4553,  0.3573],\n        [ 0.2230,  0.3115],\n        [-0.1752, -0.0627],\n        [ 0.2852,  0.4847],\n        [-0.2893,  0.2159],\n        [ 0.2230,  0.3115],\n        [-0.1752, -0.0627],\n        [ 0.2852,  0.4847],\n        [-0.4553,  0.3573],\n        [-0.1752, -0.0627],\n        [ 0.1466, -0.0453],\n        [-0.2893,  0.2159],\n        [-0.4553,  0.3573]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 몇개의 관측치만 생각해보자..\n\ndf.head()\n\n\n  \n    \n      \n\n\n\n\n\n\nX1\nX2\ny\n\n\n\n\n0\n옥순\n영식\n3.9\n\n\n1\n옥순\n영철\n4.1\n\n\n2\n옥순\n광수\n0.5\n\n\n3\n옥순\n상철\n0.3\n\n\n4\n영자\n영식\n4.5\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n(l1(X1)[0]*l2(X2)[0]).sum() # (옥순의성향 * 영식의성향).sum()\n\ntensor(0.0286, grad_fn=&lt;SumBackward0&gt;)\n\n\n\n이 값이 실제로는 3.9 이어야 한다.\n\n\n(l1(X1)[1]*l2(X2)[1]).sum() # (옥순의성향 * 영철의성향).sum()\n\ntensor(0.0136, grad_fn=&lt;SumBackward0&gt;)\n\n\n\n이 값이 실제로는 4.1 이어야 한다.\n\n- yhat을 구하면!\n\nyhat = (l1(X1) * l2(X2)).sum(axis=1) # (l1(X1) * l2(X2)).sum(1)와 결과가 같음 \nyhat\n\ntensor([ 0.0286,  0.0136,  0.0537,  0.0857,  0.2065, -0.0597,  0.3316,  0.3548,\n        -0.0783, -0.0038,  0.0971,  0.1652,  0.1280, -0.0342,  0.1952,  0.0599,\n         0.1546, -0.0759,  0.2193, -0.0672,  0.0145, -0.0579,  0.1734,  0.2810],\n       grad_fn=&lt;SumBackward1&gt;)\n\n\n\nyhat[:2],y[:2] # 이 값들이 비슷해야 하는데..\n\n(tensor([0.0286, 0.0136], grad_fn=&lt;SliceBackward0&gt;), tensor([3.9000, 4.1000]))\n\n\n- 0~5 까지의 범위로 고정되어 있으니까 아래와 같이 해도 되겠음..\n\nsig = torch.nn.Sigmoid() # range: 0~1\n\n\nyhat = sig((l1(X1) * l2(X2)).sum(axis=1))*5 # (l1(X1) * l2(X2)).sum(1)와 결과가 같음    #range: 0~5\nyhat\n\ntensor([2.5357, 2.5170, 2.5671, 2.6071, 2.7572, 2.4254, 2.9108, 2.9389, 2.4021,\n        2.4953, 2.6213, 2.7061, 2.6598, 2.4572, 2.7432, 2.5749, 2.6928, 2.4052,\n        2.7730, 2.4161, 2.5182, 2.4277, 2.7162, 2.8490],\n       grad_fn=&lt;MulBackward0&gt;)\n\n\n\nloss = torch.mean((y-yhat)**2)\nloss\n\ntensor(3.4368, grad_fn=&lt;MeanBackward0&gt;)"
  },
  {
    "objectID": "posts/2022_12_21_Extra_1_ipynb의_사본.html#torch를-이용한-학습",
    "href": "posts/2022_12_21_Extra_1_ipynb의_사본.html#torch를-이용한-학습",
    "title": "기계학습 (1221)",
    "section": "torch를 이용한 학습",
    "text": "torch를 이용한 학습\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(6,2) \nl2 = torch.nn.Linear(6,2)\nsig = torch.nn.Sigmoid() \n\n\nloss_fn = torch.nn.MSELoss() \noptimizr = torch.optim.Adam(list(l1.parameters())+list(l2.parameters()))\n\n\nfor epoc in range(5000):\n    ## 1 \n    feature1 = l1(X1)\n    feature2 = l2(X2) \n    matching_score = (feature1*feature2).sum(axis=1) \n    yhat = sig(matching_score)*5 # 만약에 1~3점이라면 \"1+sig(matching_score)*2\" 와 같이 하면 되었을듯 \n    ## 2 \n    loss = loss_fn(yhat,y)    \n    ## 3 \n    loss.backward()    \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat\n\ntensor([3.9382, 4.0624, 0.4665, 0.3353, 4.5038, 3.6975, 0.3562, 0.3558, 4.8614,\n        4.7208, 1.1813, 1.3158, 0.4606, 0.3573, 4.1288, 4.2734, 0.8611, 0.7347,\n        4.0493, 4.0464, 0.1810, 0.3124, 3.5031, 3.3948],\n       grad_fn=&lt;MulBackward0&gt;)\n\n\n\ny\n\ntensor([3.9000, 4.1000, 0.5000, 0.3000, 4.5000, 3.7000, 0.5000, 0.2000, 4.9000,\n        4.7000, 1.2000, 1.3000, 0.6000, 0.2000, 4.1000, 4.3000, 0.7000, 0.9000,\n        4.2000, 3.9000, 0.2000, 0.3000, 3.5000, 3.4000])\n\n\n\nl1(X1) # 두번째 칼럼이 I 성향 점수로 \"해석\"된다\n\ntensor([[-1.4663,  0.2938],\n        [-1.4663,  0.2938],\n        [-1.4663,  0.2938],\n        [-1.4663,  0.2938],\n        [-1.7086,  0.6597],\n        [-1.7086,  0.6597],\n        [-1.7086,  0.6597],\n        [-1.7086,  0.6597],\n        [-0.8705,  1.2945],\n        [-0.8705,  1.2945],\n        [-0.8705,  1.2945],\n        [-0.8705,  1.2945],\n        [ 1.1046, -0.8298],\n        [ 1.1046, -0.8298],\n        [ 1.1046, -0.8298],\n        [ 1.1046, -0.8298],\n        [ 0.9880, -0.5193],\n        [ 0.9880, -0.5193],\n        [ 0.9880, -0.5193],\n        [ 0.9880, -0.5193],\n        [ 0.6834, -1.2201],\n        [ 0.6834, -1.2201],\n        [ 0.6834, -1.2201],\n        [ 0.6834, -1.2201]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n포인트: 여성출연자중, 정숙은 대체로 잘 맞춰주고 현숙은 그렇지 않았음.. \\(\\to\\) 그러한 가중치가 잘 드러남!!"
  },
  {
    "objectID": "posts/2022_12_21_Extra_1_ipynb의_사본.html#fastai를-이용한-학습",
    "href": "posts/2022_12_21_Extra_1_ipynb의_사본.html#fastai를-이용한-학습",
    "title": "기계학습 (1221)",
    "section": "fastai를 이용한 학습",
    "text": "fastai를 이용한 학습\n(1) dls\n\ndf.head() # 앞단계 전처리의 산물\n\n\n  \n    \n      \n\n\n\n\n\n\nX1\nX2\ny\n\n\n\n\n0\n옥순\n영식\n3.9\n\n\n1\n옥순\n영철\n4.1\n\n\n2\n옥순\n광수\n0.5\n\n\n3\n옥순\n상철\n0.3\n\n\n4\n영자\n영식\n4.5\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ndls = CollabDataLoaders.from_df(df,bs=2,valid_pct=2/24) #bs:배치사이즈\n\n(2) lrnr 생성\n\nlrnr = collab_learner(dls,n_factors=2,y_range=(0,5))\n\n(3) 학습\n\nlrnr.fit(30,lr=0.05)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.005521\n0.306862\n00:00\n\n\n1\n0.006144\n0.246958\n00:00\n\n\n2\n0.006997\n0.300838\n00:00\n\n\n3\n0.009465\n0.193282\n00:00\n\n\n4\n0.011386\n0.157935\n00:00\n\n\n5\n0.011837\n0.273318\n00:00\n\n\n6\n0.011834\n0.170711\n00:00\n\n\n7\n0.011649\n0.245928\n00:00\n\n\n8\n0.012505\n0.198697\n00:00\n\n\n9\n0.014821\n0.153817\n00:00\n\n\n10\n0.012487\n0.144184\n00:00\n\n\n11\n0.011637\n0.164051\n00:00\n\n\n12\n0.011798\n0.189932\n00:00\n\n\n13\n0.012036\n0.163537\n00:00\n\n\n14\n0.012818\n0.203912\n00:00\n\n\n15\n0.017325\n0.210955\n00:00\n\n\n16\n0.024745\n0.143737\n00:00\n\n\n17\n0.025496\n0.172830\n00:00\n\n\n18\n0.025869\n0.138098\n00:00\n\n\n19\n0.025482\n0.151525\n00:00\n\n\n20\n0.027537\n0.193854\n00:00\n\n\n21\n0.024163\n0.109432\n00:00\n\n\n22\n0.020186\n0.167370\n00:00\n\n\n23\n0.017565\n0.107690\n00:00\n\n\n24\n0.015754\n0.160082\n00:00\n\n\n25\n0.013752\n0.115723\n00:00\n\n\n26\n0.012612\n0.105396\n00:00\n\n\n27\n0.011966\n0.094555\n00:00\n\n\n28\n0.014367\n0.162134\n00:00\n\n\n29\n0.013150\n0.175142\n00:00\n\n\n\n\n\n(4) 예측\n적합값 확인\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\nX1\nX2\ny\ny_pred\n\n\n\n\n0\n1.0\n3.0\n3.9\n3.740652\n\n\n1\n6.0\n2.0\n3.5\n4.069994\n\n\n\n\n\n(옥순의 궁합)\n\ndf_new = pd.DataFrame({'X1':['옥순']*6, 'X2':['영식','영철','영호','광수','상철','영수']})\ndf_new\n\n\n  \n    \n      \n\n\n\n\n\n\nX1\nX2\n\n\n\n\n0\n옥순\n영식\n\n\n1\n옥순\n영철\n\n\n2\n옥순\n영호\n\n\n3\n옥순\n광수\n\n\n4\n옥순\n상철\n\n\n5\n옥순\n영수\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nlrnr.get_preds(dl=dls.test_dl(df_new))\n\n\n\n\n\n\n\n\n(tensor([3.9063, 4.1200, 3.2875, 0.5278, 0.1878, 0.3123]), None)\n\n\n비교를 위해서\n\ndf_view\n\n\n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n\n\n(정숙의 궁합)\n\ndf_new = pd.DataFrame({'X1':['정숙']*6, 'X2':['영식','영철','영호','광수','상철','영수']})\ndf_new\n\n\n  \n    \n      \n\n\n\n\n\n\nX1\nX2\n\n\n\n\n0\n정숙\n영식\n\n\n1\n정숙\n영철\n\n\n2\n정숙\n영호\n\n\n3\n정숙\n광수\n\n\n4\n정숙\n상철\n\n\n5\n정숙\n영수\n\n\n\n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nlrnr.get_preds(dl=dls.test_dl(df_new))\n\n\n\n\n\n\n\n\n(tensor([4.7749, 4.8766, 4.7028, 1.7205, 0.5784, 1.1272]), None)\n\n\n비교를 위해서\n\ndf_view\n\n\n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n\n\n- Appedix: fastai 구조공부..\n\nlrnr.model\n\nEmbeddingDotBias(\n  (u_weight): Embedding(7, 2)\n  (i_weight): Embedding(7, 2)\n  (u_bias): Embedding(7, 1)\n  (i_bias): Embedding(7, 1)\n)\n\n\n\nlrnr.model.forward??\n\n\nSignature: lrnr.model.forward(x)\nDocstring:\nDefines the computation performed at every call.\nShould be overridden by all subclasses.\n.. note::\n    Although the recipe for forward pass needs to be defined within\n    this function, one should call the :class:`Module` instance afterwards\n    instead of this since the former takes care of running the\n    registered hooks while the latter silently ignores them.\nSource:   \n    def forward(self, x):\n        users,items = x[:,0],x[:,1]\n        dot = self.u_weight(users)* self.i_weight(items)\n        res = dot.sum(1) + self.u_bias(users).squeeze() + self.i_bias(items).squeeze()\n        if self.y_range is None: return res\n        return torch.sigmoid(res) * (self.y_range[1]-self.y_range[0]) + self.y_range[0]\nFile:      ~/anaconda3/envs/py37/lib/python3.7/site-packages/fastai/collab.py\nType:      method\n\n\n\n\n\nbias를 제외하면 우리가 짠 모형과 같음!"
  },
  {
    "objectID": "posts/2022_12_21_Extra_1_ipynb의_사본.html#data",
    "href": "posts/2022_12_21_Extra_1_ipynb의_사본.html#data",
    "title": "기계학습 (1221)",
    "section": "data",
    "text": "data\n- 예전에 살펴본 예제\n\ndf = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/main/posts/I.%20Overview/2022-09-08-rcmd_anal.csv')\ndf\n\n\n  \n    \n      \n\n\n\n\n\n\nuser\nitem\nrating\nitem_name\n\n\n\n\n0\n1\n15\n1.084308\n홍차5\n\n\n1\n1\n1\n4.149209\n커피1\n\n\n2\n1\n11\n1.142659\n홍차1\n\n\n3\n1\n5\n4.033415\n커피5\n\n\n4\n1\n4\n4.078139\n커피4\n\n\n...\n...\n...\n...\n...\n\n\n995\n100\n18\n4.104276\n홍차8\n\n\n996\n100\n17\n4.164773\n홍차7\n\n\n997\n100\n14\n4.026915\n홍차4\n\n\n998\n100\n4\n0.838720\n커피4\n\n\n999\n100\n7\n1.094826\n커피7\n\n\n\n\n1000 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n- 기억을 살리기 위해서..\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/main/posts/I.%20Overview/2022-09-08-rcmd_view.csv')\ndf_view\n\n\n\n\n\n\n\n\n커피1\n커피2\n커피3\n커피4\n커피5\n커피6\n커피7\n커피8\n커피9\n커피10\n홍차1\n홍차2\n홍차3\n홍차4\n홍차5\n홍차6\n홍차7\n홍차8\n홍차9\n홍차10\n\n\n\n\n0\n4.149209\nNaN\nNaN\n4.078139\n4.033415\n4.071871\nNaN\nNaN\nNaN\nNaN\n1.142659\n1.109452\nNaN\n0.603118\n1.084308\nNaN\n0.906524\nNaN\nNaN\n0.903826\n\n\n1\n4.031811\nNaN\nNaN\n3.822704\nNaN\nNaN\nNaN\n4.071410\n3.996206\nNaN\nNaN\n0.839565\n1.011315\nNaN\n1.120552\n0.911340\nNaN\n0.860954\n0.871482\nNaN\n\n\n2\n4.082178\n4.196436\nNaN\n3.956876\nNaN\nNaN\nNaN\n4.450931\n3.972090\nNaN\nNaN\nNaN\nNaN\n0.983838\nNaN\n0.918576\n1.206796\n0.913116\nNaN\n0.956194\n\n\n3\nNaN\n4.000621\n3.895570\nNaN\n3.838781\n3.967183\nNaN\nNaN\nNaN\n4.105741\n1.147554\nNaN\n1.346860\nNaN\n0.614099\n1.297301\nNaN\nNaN\nNaN\n1.147545\n\n\n4\nNaN\nNaN\nNaN\nNaN\n3.888208\nNaN\n3.970330\n3.979490\nNaN\n4.010982\nNaN\n0.920995\n1.081111\n0.999345\nNaN\n1.195183\nNaN\n0.818332\n1.236331\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n95\n0.511905\n1.066144\nNaN\n1.315430\nNaN\n1.285778\nNaN\n0.678400\n1.023020\n0.886803\nNaN\n4.055996\nNaN\nNaN\n4.156489\n4.127622\nNaN\nNaN\nNaN\nNaN\n\n\n96\nNaN\n1.035022\nNaN\n1.085834\nNaN\n0.812558\nNaN\n1.074543\nNaN\n0.852806\n3.894772\nNaN\n4.071385\n3.935935\nNaN\nNaN\n3.989815\nNaN\nNaN\n4.267142\n\n\n97\nNaN\n1.115511\nNaN\n1.101395\n0.878614\nNaN\nNaN\nNaN\n1.329319\nNaN\n4.125190\nNaN\n4.354638\n3.811209\n4.144648\nNaN\nNaN\n4.116915\n3.887823\nNaN\n\n\n98\nNaN\n0.850794\nNaN\nNaN\n0.927884\n0.669895\nNaN\nNaN\n0.665429\n1.387329\nNaN\nNaN\n4.329404\n4.111706\n3.960197\nNaN\nNaN\nNaN\n3.725288\n4.122072\n\n\n99\nNaN\nNaN\n1.413968\n0.838720\nNaN\nNaN\n1.094826\n0.987888\nNaN\n1.177387\n3.957383\n4.136731\nNaN\n4.026915\nNaN\nNaN\n4.164773\n4.104276\nNaN\nNaN\n\n\n\n\n100 rows × 20 columns"
  },
  {
    "objectID": "posts/2022_12_21_Extra_1_ipynb의_사본.html#모형",
    "href": "posts/2022_12_21_Extra_1_ipynb의_사본.html#모형",
    "title": "기계학습 (1221)",
    "section": "모형",
    "text": "모형\n(편의상 바이어스를 제외하면)\n- 특징벡터:\n\n유저1의 취향 = [커피를 좋아하는 정도, 홍차를 좋아하는 정도]\n아이템1의 특징 = [커피의 특징, 홍차인 특징]\n\n- 평점\n\n유저1이 아이템1을 먹었을경우 평점: 유저1의 취향과 아이템1의 특징의 내적 = (유저1의 취향 \\(\\odot\\) 아이템1의 특징).sum()"
  },
  {
    "objectID": "posts/2022_12_21_Extra_1_ipynb의_사본.html#학습",
    "href": "posts/2022_12_21_Extra_1_ipynb의_사본.html#학습",
    "title": "기계학습 (1221)",
    "section": "학습",
    "text": "학습\n(1) dls\n\ndls = CollabDataLoaders.from_df(df)\n\n\ndls.items\n\n\n\n\n\n\n\n\nuser\nitem\nrating\nitem_name\n\n\n\n\n192\n20\n1\n3.933610\n커피1\n\n\n794\n80\n12\n4.125577\n홍차2\n\n\n554\n56\n17\n3.826543\n홍차7\n\n\n524\n53\n3\n1.170372\n커피3\n\n\n175\n18\n10\n4.170460\n커피10\n\n\n...\n...\n...\n...\n...\n\n\n896\n90\n12\n4.391382\n홍차2\n\n\n849\n85\n3\n0.693932\n커피3\n\n\n746\n75\n12\n4.301711\n홍차2\n\n\n787\n79\n14\n3.930048\n홍차4\n\n\n100\n11\n20\n1.145191\n홍차10\n\n\n\n\n800 rows × 4 columns\n\n\n\n(2) lrnr\n\nlrnr = collab_learner(dls,n_factors=2) # 교재에는 y_range 를 설정하도록 되어있지만 설정 안해도 적합에는 크게 상관없음..\n\n(3) fit\n\nlrnr.fit(10,0.1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n5.409556\n3.313535\n00:00\n\n\n1\n3.724468\n2.569444\n00:00\n\n\n2\n2.855262\n1.630986\n00:00\n\n\n3\n2.051633\n0.469137\n00:00\n\n\n4\n1.483525\n0.264474\n00:00\n\n\n5\n1.096932\n0.178709\n00:00\n\n\n6\n0.824759\n0.117894\n00:00\n\n\n7\n0.630313\n0.081575\n00:00\n\n\n8\n0.487037\n0.076569\n00:00\n\n\n9\n0.380992\n0.076578\n00:00\n\n\n\n\n\n(4) predict\n(적합된 값 확인)\n\nlrnr.show_results() # 누를때마다 결과다름\n\n\n\n\n\n\n\n\n\n\n\n\nuser\nitem\nrating\nrating_pred\n\n\n\n\n0\n61.0\n19.0\n4.160296\n4.037053\n\n\n1\n22.0\n4.0\n4.192549\n3.940574\n\n\n2\n17.0\n17.0\n1.096392\n0.967445\n\n\n3\n14.0\n4.0\n3.826174\n4.002016\n\n\n4\n88.0\n5.0\n1.197540\n0.968678\n\n\n5\n53.0\n15.0\n3.859582\n3.966616\n\n\n6\n83.0\n5.0\n0.752025\n0.789191\n\n\n7\n10.0\n11.0\n0.676153\n0.978221\n\n\n8\n46.0\n17.0\n0.833476\n0.908008\n\n\n\n\n\n(예측값)\n\ndf_new = pd.DataFrame({'user':[1,1,1,1], 'item':[9,10,11,12]})\ndf_new\n\n\n\n\n\n\n\n\nuser\nitem\n\n\n\n\n0\n1\n9\n\n\n1\n1\n10\n\n\n2\n1\n11\n\n\n3\n1\n12\n\n\n\n\n\n\n\n\nlrnr.get_preds(dl=dls.test_dl(df_new))\n\n\n\n\n\n\n\n\n(tensor([4.0201, 4.0401, 0.9940, 0.8291]), None)"
  },
  {
    "objectID": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html",
    "href": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html",
    "title": "기계학습 (1026) 8주차",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xkHPJ1DiPKfseoBl9yUY4P"
  },
  {
    "objectID": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#강의영상",
    "href": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#강의영상",
    "title": "기계학습 (1026) 8주차",
    "section": "",
    "text": "youtube: https://youtube.com/playlist?list=PLQqh36zP38-xkHPJ1DiPKfseoBl9yUY4P"
  },
  {
    "objectID": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#imports",
    "href": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#imports",
    "title": "기계학습 (1026) 8주차",
    "section": "imports",
    "text": "imports\n\nimport torch \nimport torchvision\nfrom fastai.vision.all import *"
  },
  {
    "objectID": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#transfer-learning",
    "href": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#transfer-learning",
    "title": "기계학습 (1026) 8주차",
    "section": "Transfer Learning",
    "text": "Transfer Learning\n\npath = untar_data(URLs.CIFAR)\n\n\n\n\n\n\n    \n      \n      100.00% [168173568/168168549 00:04&lt;00:00]\n    \n    \n\n\n\npath.ls()\n\n(#3) [Path('/root/.fastai/data/cifar10/train'),Path('/root/.fastai/data/cifar10/test'),Path('/root/.fastai/data/cifar10/labels.txt')]\n\n\n\n수제네트워크\n\ndls\n\n\ndls = ImageDataLoaders.from_folder(path,train='train',valid='test') \n\n\n_X,_y = dls.one_batch()\n_X.shape, _y.shape\n\n(torch.Size([64, 3, 32, 32]), torch.Size([64]))\n\n\n\n!ls /home/cgb4/.fastai/data/cifar10/train # 10개의 클래스\n\nairplane  automobile  bird  cat  deer  dog  frog  horse  ship  truck\n\n\n\ndls.show_batch() #어떠한 이미지가 어떠한 라벨로 되어있는지 확인이 가능하다.\n\n\n\n\n\nlrnr 생성\n\n\nnet1 = torch.nn.Sequential( #수제네트워크: 임의로 지정한 네트워크\n    torch.nn.Conv2d(3,128,(5,5)), #conv.:선형변환 \n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\n\n\nnet1(_X.to(\"cpu\")).shape\n\ntorch.Size([64, 25088])\n\n\n\nnet = torch.nn.Sequential(\n    net1, \n    torch.nn.Linear(25088,10)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=accuracy) \n\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.104867\n1.105857\n0.620600\n00:04\n\n\n1\n0.961969\n1.050836\n0.640000\n00:04\n\n\n2\n0.902597\n1.058793\n0.637600\n00:04\n\n\n3\n0.854093\n1.036581\n0.657200\n00:04\n\n\n4\n0.779191\n1.013788\n0.663400\n00:04\n\n\n5\n0.723487\n1.091586\n0.642500\n00:04\n\n\n6\n0.694052\n1.064836\n0.655700\n00:04\n\n\n7\n0.629718\n1.044633\n0.668900\n00:04\n\n\n8\n0.589516\n1.168362\n0.645100\n00:04\n\n\n9\n0.572035\n1.117689\n0.654800\n00:04\n\n\n\n\n\n\n이게 생각보다 잘 안맞아요.. 70넘기 힘듬\n\n\n\n전이학습 (남이 만든 네트워크)\n\nlrnr 생성\n\n\n#collapse_output\nnet = torchvision.models.resnet18(weights=torchvision.models.resnet.ResNet18_Weights.IMAGENET1K_V1)\nnet\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\n\n\\(k=1000\\) 즉 1000개의 물체를 구분하는 모형임\n\n\nnet.fc = torch.nn.Linear(in_features=512, out_features=10) \n\n\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=accuracy)\n\n\n학습\n\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.813139\n0.803660\n0.735300\n00:10\n\n\n1\n0.667533\n0.742656\n0.756300\n00:11\n\n\n2\n0.544296\n0.735011\n0.755900\n00:10\n\n\n3\n0.449801\n0.671868\n0.784000\n00:10\n\n\n4\n0.390996\n0.657825\n0.780100\n00:11\n\n\n5\n0.310046\n0.690071\n0.788700\n00:10\n\n\n6\n0.259605\n0.671683\n0.802500\n00:10\n\n\n7\n0.199240\n0.715251\n0.796800\n00:10\n\n\n8\n0.195551\n0.772891\n0.795100\n00:10\n\n\n9\n0.150421\n0.764864\n0.801600\n00:10\n\n\n\n\n\n\nCIFAR10을 맞추기 위한 네트워크가 아님에도 불구하고 상당히 잘맞음\n일반인이 거의 밑바닥에서 설계하는것보다 전이학습을 이용하는 것이 효율적일 경우가 많다.\n\n\n\n전이학습 다른 구현: 순수 fastai 이용\n- 예전코드 복습\n\npath = untar_data(URLs.PETS)/'images'\n\n\nfiles= get_image_files(path)\n\n\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.191067\n0.027880\n0.991881\n00:29\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.039166\n0.012174\n0.996617\n00:37\n\n\n\n\n\n- 사실 위의 코드가 transfer learning 이었음.\n\n#collapse_output\nlrnr.model\n\nSequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=False)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2, bias=False)\n  )\n)"
  },
  {
    "objectID": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#cam",
    "href": "posts/2. CNN/2022_10_26_(8주차)_10월26일(2)_ipynb의_사본.html#cam",
    "title": "기계학습 (1026) 8주차",
    "section": "CAM",
    "text": "CAM\n\nCAM이란?\n\nref: http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf\n\n- Class Activation Mapping (CAM)은 설명가능한 인공지능모형 (eXplainable Artificial Intelligence, XAI) 중 하나로 CNN의 판단근거를 시각화하는 기술\n\n\n학습에 사용할 데이터 Load\n\npath = untar_data(URLs.PETS)/'images'\n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 00:18&lt;00:00]\n    \n    \n\n\n\npath.ls()\n\n(#7393) [Path('/root/.fastai/data/oxford-iiit-pet/images/scottish_terrier_46.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Maine_Coon_64.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/pomeranian_82.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_131.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/japanese_chin_38.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/British_Shorthair_18.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_84.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/samoyed_122.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Russian_Blue_253.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/basset_hound_25.jpg')...]\n\n\n\nfiles= get_image_files(path)\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\ndls = ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\n\n구현0단계– 예비학습\n\n# 하나의 이미지 선택\n\nximg = PILImage.create('/home/cgb4/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg')\nximg\n\n\n\n\n\nx = first(dls.test_dl([ximg]))[0] #이미지를 숫자 형태로 가져오고 싶음 이미지에 대응하는 숫자들.. \nx\n\nTensorImage([[[[0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9059, 0.9059, 0.9098,  ..., 0.9059, 0.9059, 0.9059],\n               ...,\n               [0.8745, 0.8784, 0.8824,  ..., 0.8902, 0.8863, 0.8824],\n               [0.9059, 0.8980, 0.8902,  ..., 0.8824, 0.8863, 0.8824],\n               [0.8863, 0.8863, 0.8824,  ..., 0.8784, 0.8863, 0.8863]],\n\n              [[0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n               [0.9137, 0.9137, 0.9176,  ..., 0.9059, 0.9059, 0.9059],\n               ...,\n               [0.8784, 0.8824, 0.8863,  ..., 0.8745, 0.8667, 0.8588],\n               [0.9098, 0.9020, 0.8902,  ..., 0.8745, 0.8706, 0.8627],\n               [0.8902, 0.8902, 0.8784,  ..., 0.8784, 0.8745, 0.8706]],\n\n              [[0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n               [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n               [0.9098, 0.9098, 0.9137,  ..., 0.9137, 0.9137, 0.9137],\n               ...,\n               [0.8863, 0.8902, 0.8980,  ..., 0.8784, 0.8706, 0.8667],\n               [0.9176, 0.9137, 0.9059,  ..., 0.8745, 0.8706, 0.8667],\n               [0.8980, 0.9020, 0.8980,  ..., 0.8745, 0.8706, 0.8667]]]],\n            device='cuda:0')\n\n\n\n\n# AP layer\n\nap = torch.nn.AdaptiveAvgPool2d(output_size=1) # 데이터를 요약하는 방식 중 평균을 내는 방법 \n\n\nX = torch.arange(48).reshape(1,3,4,4)*1.0  #X는 아무 값이나 4*4의 컬러 이미지\nX\n\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])\n\n\n\nap(X) #각 채널들의 평균값 \n\ntensor([[[[ 7.5000]],\n\n         [[23.5000]],\n\n         [[39.5000]]]])\n\n\n\nX[0,0,...].mean(),X[0,1,...].mean(),X[0,2,...].mean()\n\n(tensor(7.5000), tensor(23.5000), tensor(39.5000))\n\n\n\n\n# torch.einsum\n(예시1)\n\ntsr = torch.arange(12).reshape(4,3)\ntsr\n\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n\n\n\ntorch.einsum('ij-&gt;ji',tsr) #tsr.T 해도 됨. \n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n(예시2)\n\ntsr1 = torch.arange(12).reshape(4,3).float()\ntsr2 = torch.arange(15).reshape(3,5).float()\n\n\ntsr1 @ tsr2 #4X5행렬\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n\ntorch.einsum('ij,jk -&gt; ik',tsr1,tsr2) \n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n(예시3)\n\nx.to(\"cpu\").shape #(1,3,512,512) -&gt; (512,512,3)으로 바꾸고 싶다.\n\ntorch.Size([1, 3, 512, 512])\n\n\n\ntorch.einsum('ocij -&gt; ijc',x.to(\"cpu\")).shape\n\ntorch.Size([512, 512, 3])\n\n\n\nplt.imshow(torch.einsum('ocij -&gt; ijc',x.to(\"cpu\")))\n\n&lt;matplotlib.image.AxesImage at 0x7f5fc4136290&gt;\n\n\n\n\n\n\n\n\n구현1단계– 이미지분류 잘하는 네트워크 선택\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/home/cgb4/anaconda3/envs/py37/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.169602\n0.011903\n0.996617\n00:29\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.052203\n0.012352\n0.998647\n00:38\n\n\n\n\n\n\n\n구현2단계– 네트워크의 끝 부분 수정\n- 모형의 분해\n\nnet1= lrnr.model[0]\nnet2= lrnr.model[1]\n\n- net2를 좀더 살펴보자.\n\nnet2\n\nSequential(\n  (0): AdaptiveConcatPool2d(\n    (ap): AdaptiveAvgPool2d(output_size=1)\n    (mp): AdaptiveMaxPool2d(output_size=1)\n  )\n  (1): fastai.layers.Flatten(full=False)\n  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (3): Dropout(p=0.25, inplace=False)\n  (4): Linear(in_features=1024, out_features=512, bias=False)\n  (5): ReLU(inplace=True)\n  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (7): Dropout(p=0.5, inplace=False)\n  (8): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\n_X, _y = dls.one_batch() \n\n\nnet1.to(\"cpu\")\nnet2.to(\"cpu\") \n_X = _X.to(\"cpu\")\n\n\nprint(net1(_X).shape)\nprint(net2[0](net1(_X)).shape)\nprint(net2[1](net2[0](net1(_X))).shape)\nprint(net2[2](net2[1](net2[0](net1(_X)))).shape)\n\n# (64,512,16,16) \n# ↓AP:mean\n# (64,512,1,1) \n# ↓MP(Maxpooling):max\n# (64,512,1,1) \n\ntorch.Size([64, 512, 16, 16])\ntorch.Size([64, 1024, 1, 1])\ntorch.Size([64, 1024])\ntorch.Size([64, 1024])\n\n\n- net2를 아래와 같이 수정하고 재학습하자 (왜?)\n\nnet2= torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), # (64,512,16,16) -&gt; (64,512,1,1) \n    torch.nn.Flatten(), # (64,512,1,1) -&gt; (64,512) \n    torch.nn.Linear(512,2,bias=False) # (64,512) -&gt; (64,2) \n)\n\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\n\n\nlrnr2= Learner(dls,net,metrics=accuracy) # loss_fn??\n\n\nlrnr2.loss_func, lrnr.loss_func ## 알아서 기존의 loss function으로 잘 들어가 있음. \n\n(FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss())\n\n\n\nlrnr2.fine_tune(5) # net2를 수정해서 accuracy가 안좋아지긴 했는데 그래도 쓸만함 \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.252908\n0.741022\n0.755751\n00:38\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.130946\n0.126084\n0.957375\n00:38\n\n\n1\n0.143405\n0.229703\n0.905954\n00:38\n\n\n2\n0.092800\n0.104366\n0.962788\n00:38\n\n\n3\n0.046969\n0.043439\n0.983762\n00:38\n\n\n4\n0.024211\n0.038318\n0.983762\n00:38\n\n\n\n\n\n\n\n구현3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈\n- 1개의 observation을 고정하였을 경우 출력과정 상상\n\nximg = PILImage.create('/home/cgb4/.fastai/data/oxford-iiit-pet/images/staffordshire_bull_terrier_106.jpg')\nx = first(dls.test_dl([ximg]))[0]\n\n\nnet2\n\nSequential(\n  (0): AdaptiveAvgPool2d(output_size=1)\n  (1): Flatten(start_dim=1, end_dim=-1)\n  (2): Linear(in_features=512, out_features=2, bias=False)\n)\n\n\n\nprint(net1(x).shape)\nprint(net2[0](net1(x)).shape)\nprint(net2[1](net2[0](net1(x))).shape)\nprint(net2[2](net2[1](net2[0](net1(x)))).shape)\n\ntorch.Size([1, 512, 16, 16])\ntorch.Size([1, 512, 1, 1])\ntorch.Size([1, 512])\ntorch.Size([1, 2])\n\n\n- 최종결과 확인\n\nnet(x)\n\nTensorImage([[-9.0358,  9.0926]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\ndls.vocab\n\n['cat', 'dog']\n\n\n\nnet(x)에서 뒤쪽의 값이 클수록 ’dog’를 의미한다.\n\n- net2의 순서 바꾸기 전 전체 네트워크:\n\\[\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linear}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [-9.0358,  9.0926]\\]\n- 아래와 같이 순서를 바꿔서 한번 계산해보고 싶다. (왜???..)\n\\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{linear}{\\to} \\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [−9.0358,9.0926]\\]\n\n여기에서 (1,512,16,16) -&gt; (1,2,16,16) 로 가는 선형변환을 적용하는 방법? (16,16) each pixel에 대하여 (512 \\(\\to\\) 2)로 가는 변환을 수행\n\n- 통찰: 이 경우 특이하게도 레이어의 순서를 바꿨을때 출력이 동일함 (선형변환하고 평균내거나 평균내고 선형변환하는건 같으니까)\n\n_x =torch.tensor([1,2,3.14,4]).reshape(4,1)\n_x \n\ntensor([[1.0000],\n        [2.0000],\n        [3.1400],\n        [4.0000]])\n\n\n\n_l1 = torch.nn.Linear(1,1,bias=False)\n_l1(_x).mean() # _x -&gt; 선형변환 -&gt; 평균 \n\ntensor(-1.4045, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\n_l1(_x.mean().reshape(1,1)) # _x -&gt; 평균 -&gt; 선형변환\n\ntensor([[-1.4045]], grad_fn=&lt;MmBackward0&gt;)\n\n\n- 구현해보자.\n\nwhy = torch.einsum('cb,abij-&gt;acij',net2[2].weight,net1(x))\n\n\nnet2[0](why)\n\nTensorImage([[[[-9.0358]],\n\n              [[ 9.0926]]]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nnet(x)\n\nTensorImage([[-9.0358,  9.0926]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\n\n잠깐 멈추고 생각\n- 이미지\n\nximg\n\n\n\n\n- 네트워크의 결과\n\nnet2(net1(x))\n\nTensorImage([[-9.0358,  9.0926]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\n-9.0358 &lt;&lt; 9.0926 이므로 ’ximg’는 높은 확률로 개라는 뜻이다.\n\n- 아래의네트워크를 관찰\n\\[\\underset{(1,2,16,16)}{{\\bf why}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}} = [-9.0358,9.0926]\\]\n\nnet2[0](why)\n\nTensorImage([[[[-9.0358]],\n\n              [[ 9.0926]]]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n더 파고들어서 분석해보자.\n\nwhy.shape\n\ntorch.Size([1, 2, 16, 16])\n\n\n\n(why[0,0,:,:]).mean(), (why[0,1,:,:]).mean()\n\n(TensorImage(-9.0358, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;),\n TensorImage(9.0926, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;))\n\n\nwhy[0,0,:,:]\n\n#collapse_output\n(why[0,0,:,:]).to(torch.int64)\n\nTensorImage([[   0,    0,    0,    0,    0,    0,   -1,   -4,   -5,   -4,   -1,\n                 0,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,  -12,  -26,  -33,  -28,  -14,\n                -3,    0,    0,    0,    0],\n             [   0,    0,    1,    1,    0,   -2,  -22,  -60,  -75,  -73,  -41,\n               -10,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -2,  -25,  -75, -116, -110,  -64,\n               -18,    0,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,  -22,  -76, -147, -132,  -69,\n               -21,   -1,    0,    0,    0],\n             [   0,    0,    0,    0,    0,   -1,  -16,  -60, -112, -110,  -59,\n               -18,   -3,    0,    0,   -7],\n             [   0,    0,    0,    0,    0,    0,   -9,  -38,  -66,  -66,  -37,\n               -12,   -2,    0,    0,   -2],\n             [   0,    1,    1,    0,    0,    0,   -4,  -25,  -34,  -27,  -18,\n                -6,   -1,    0,    0,    0],\n             [   1,    1,    1,    0,    0,    0,   -2,  -11,  -15,  -10,   -5,\n                -2,    0,    0,    0,    0],\n             [   1,    1,    0,    0,    0,    0,   -1,   -2,   -4,   -3,    0,\n                 0,    0,    0,   -1,    0],\n             [   0,    0,    0,   -1,   -3,   -1,   -1,   -1,   -2,   -2,   -2,\n                -1,   -2,   -2,    0,    0],\n             [   0,    0,    0,   -1,   -1,   -1,   -1,   -2,   -5,   -4,   -3,\n                -1,    0,    0,   -1,   -1],\n             [  -1,    0,    0,    0,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n                -2,    0,   -1,   -1,   -1],\n             [  -1,   -2,   -1,    0,   -1,   -3,   -2,    0,    2,    0,    0,\n                -1,    0,   -1,   -2,   -3],\n             [  -3,   -4,   -3,   -3,   -3,   -5,   -3,   -1,   -1,   -3,   -2,\n                -2,   -1,   -2,   -4,   -4],\n             [  -3,   -4,   -4,   -4,   -4,   -3,   -3,   -2,   -3,   -4,   -4,\n                -3,   -2,   -3,   -4,   -4]], device='cuda:0')\n\n\n\n이 값들의 평균은 -9.0358 이다. (이 값이 클수록 이 그림이 고양이라는 의미 = 이 값이 작을수록 이 그림이 고양이가 아니라는 의미)\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 작은값이 있어서 -9.0358이라는 평균값이 나옴 \\(\\to\\) 특정위치에 존재하는 엄청 작은 값들은 ximg가 고양이가 아니라고 판단하는 근거가 된다.\n\nwhy[0,1,:,:]\n\n#collapse_output\n(why[0,1,:,:]).to(torch.int64)\n\nTensorImage([[  0,   0,   0,   0,   0,   0,   1,   4,   5,   4,   1,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,  12,  27,  34,  29,  15,   3,   0,\n                0,   0,   0],\n             [  0,   0,  -1,  -1,   0,   2,  23,  62,  79,  76,  43,  11,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   2,  26,  79, 122, 116,  66,  18,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,  24,  81, 152, 136,  72,  21,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   0,  18,  64, 116, 113,  61,  19,   3,\n                0,   0,   6],\n             [  0,   0,   0,   0,   0,   0,  10,  40,  69,  68,  38,  12,   1,\n                0,   0,   2],\n             [  0,  -1,  -1,   0,   0,   0,   4,  25,  35,  28,  18,   6,   1,\n                0,   0,   0],\n             [ -1,  -1,  -1,   0,   0,   0,   2,  10,  14,  10,   5,   1,   0,\n                0,   0,   0],\n             [  0,  -1,   0,   0,   0,   0,   0,   2,   4,   3,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   3,   1,   0,   1,   2,   2,   2,   0,   1,\n                2,   0,   0],\n             [  0,   0,   0,   0,   0,   1,   1,   2,   5,   3,   3,   1,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   1,   1,   0,\n                0,   0,   1],\n             [  1,   1,   1,   0,   0,   2,   1,   0,  -2,   0,   0,   1,   0,\n                0,   1,   1],\n             [  2,   2,   2,   2,   2,   4,   2,   1,   1,   2,   1,   1,   1,\n                1,   3,   3],\n             [  2,   3,   3,   3,   3,   2,   2,   2,   2,   3,   2,   2,   2,\n                2,   3,   3]], device='cuda:0')\n\n\n\n이 값들의 평균은 9.0926 이다. (이 값이 클수록 이 그림이 강아지라는 의미)\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가짐. 다만 특정위치에서 엄청 큰 값들이 있어서 9.0926이라는 평균값이 나옴 \\(\\to\\) 특정위치에 존재하는 엄청 큰 값들은 결국 ximg를 강아지라고 판단하는 근거가 된다.\n\n- 시각화\n\nwhy_cat = why[0,0,:,:]\nwhy_dog = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_cat.to(\"cpu\").detach(),cmap='magma')\nax[2].imshow(why_dog.to(\"cpu\").detach(),cmap='magma')\n\n&lt;matplotlib.image.AxesImage at 0x7f5fce6d7b90&gt;\n\n\n\n\n\n\nmagma = 검은색 &lt; 보라색 &lt; 빨간색 &lt; 노란색\n왼쪽그림의 검은 부분은 고양이가 아니라는 근거, 오른쪽그림의 노란부분은 강아지라는 근거\n\n- why_cat, why_dog를 (16,16) \\(\\to\\) (512,512) 로 resize\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\nax[2].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\n\n&lt;matplotlib.image.AxesImage at 0x7f5fbd81c890&gt;\n\n\n\n\n\n- 겹쳐그리기\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n&lt;matplotlib.image.AxesImage at 0x7f5fd48cd7d0&gt;\n\n\n\n\n\n- 하니이미지 시각화\n\n#\n#!wget https://github.com/guebin/DL2022/blob/master/_notebooks/2022-09-06-hani01.jpeg?raw=true\nximg= PILImage.create('2022-09-06-hani01.jpeg')\nx= first(dls.test_dl([ximg]))[0]\n\n\nwhy = torch.einsum('cb,abij-&gt;acij',net2[2].weight,net1(x))\nwhy_cat = why[0,0,:,:]\nwhy_dog = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n&lt;matplotlib.image.AxesImage at 0x7f5fbca0ad10&gt;\n\n\n\n\n\n- 하니이미지 시각화 with prob\n\nsftmax=torch.nn.Softmax(dim=1)\n\n\nsftmax(net(x))\n\nTensorImage([[1.5489e-05, 9.9998e-01]], device='cuda:0',\n            grad_fn=&lt;AliasBackward0&gt;)\n\n\n\ncatprob, dogprob = sftmax(net(x))[0,0].item(), sftmax(net(x))[0,1].item()\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_cat.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[0].set_title('catprob= %f' % catprob) \nax[1].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_dog.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].set_title('dogprob=%f' % dogprob)\n\nText(0.5, 1.0, 'dogprob=0.999985')\n\n\n\n\n\n\n\n구현4단계– CAM 시각화\n\nsftmax = torch.nn.Softmax(dim=1)\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=25\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=50\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=75\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_cat = why[0,0,:,:] \n        why_dog = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_cat.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"cat(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_dog.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"dog(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/MachineLearning_midterm(202250926).html",
    "href": "posts/MachineLearning_midterm(202250926).html",
    "title": "기계학습 midterm",
    "section": "",
    "text": "import torch \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom fastai.vision.all import *\n\n\n1. 크롤링을 통한 이미지 분석 및 CAM\n\n#\n# 크롤링에 필요한 준비작업들\n!pip install -Uqq duckduckgo_search\nfrom duckduckgo_search import ddg_images\nfrom fastdownload import download_url\nfrom fastcore.all import *\ndef search_images(term, max_images=200): return L(ddg_images(term, max_results=max_images)).itemgot('image')\n\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nflask 1.1.4 requires click&lt;8.0,&gt;=5.1, but you have click 8.1.3 which is incompatible.\n\n\n\n# \n# 폴더만드는코드 -- 사실 손으로 만들어도 무방함.. \n!mkdir images\n!mkdir images/train\n!mkdir images/test \n!mkdir images/train/Harry Potter\n!mkdir images/train/Ronald Bilius Weasley\n!mkdir images/test/Harry Potter\n!mkdir images/test/Ronald Bilius Weasley\n\nmkdir: cannot create directory ‘images’: File exists\nmkdir: cannot create directory ‘images/train’: File exists\nmkdir: cannot create directory ‘images/test’: File exists\nmkdir: cannot create directory ‘Potter’: File exists\nmkdir: cannot create directory ‘Bilius’: File exists\nmkdir: cannot create directory ‘Weasley’: File exists\n\n\n\ndownload_images(dest='./images/train/Harry Potter',urls=search_images('Harry Potter',max_images=200))\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/Ronald Bilius Weasley',urls=search_images('Ronald Bilius Weasley',max_images=200)) \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/Harry Potter',urls=search_images('Harry Potter movie',max_images=200))  \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/train/Ronald Bilius Weasley',urls=search_images('Ronald Weasley',max_images=200))\ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n\n\ndownload_images(dest='./images/test/Harry Potter',urls=search_images('Harry Potter photo',max_images=50)) \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \ndownload_images(dest='./images/test/Ronald Bilius Weasley',urls=search_images('Ronald Bilius Weasley photo',max_images=50))  \ntime.sleep(10) # 서버과부하를 위한 휴식코드 \n\n\nbad_images = verify_images(get_image_files('./images'))\nbad_images\n\n(#62) [Path('images/train/Harry Potter/d75f9d42-7db5-418a-bc65-8a10c4dd6df3.jpg'),Path('images/train/Harry Potter/fbdce828-967e-4ee0-99dc-74b065cec931.jpg'),Path('images/train/Harry Potter/f2216c3c-9d40-4551-8dbc-0812b61be308.jpg'),Path('images/train/Harry Potter/72319413-8aed-4ff8-bd15-9247c9e6b9fc.jpg'),Path('images/train/Harry Potter/5a5656d6-b298-43f1-88dd-526eb597258a.jpg'),Path('images/train/Harry Potter/cfa5a057-4bbe-43a1-9bdd-7e6214fef746.jpg'),Path('images/train/Harry Potter/6902097c-8e55-4fc7-b5c8-aa6cb88a287e.jpg'),Path('images/train/Harry Potter/e1af5803-a0f0-4311-9c54-95b1506ee512.jpg'),Path('images/train/Harry Potter/1a6e2dd5-d8d0-4220-969f-05aa234af09d.jpg'),Path('images/train/Harry Potter/506feddc-f171-4808-9643-66183bc85d6d.jpg')...]\n\n\n\nbad_images.map(Path.unlink)\n\n(#62) [None,None,None,None,None,None,None,None,None,None...]\n\n\n\ndls = ImageDataLoaders.from_folder(path = './images', train='train',valid='test',item_tfms=Resize(512),bs=8) \n\n\ndls.show_batch()\n\n\n\n\n\nlrnr = vision_learner(dls,resnet34,metrics=accuracy) \n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.944444\n1.663112\n0.458763\n01:01\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.539615\n1.090526\n0.567010\n01:03\n\n\n\n\n\n\nnet1= lrnr.model[0]\nnet2= lrnr.model[1]\n\n\n_X, _y = dls.one_batch() \n\n\nnet1.to(\"cpu\")\nnet2.to(\"cpu\") \n_X = _X.to(\"cpu\")\n\n\nnet2= torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(), \n    torch.nn.Linear(512,2,bias=False) \n)\n\n\nnet = torch.nn.Sequential(\n    net1,\n    net2\n)\n\n\nlrnr2= Learner(dls,net,metrics=accuracy)\n\n\nlrnr2.fine_tune(5) \n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/140 00:00&lt;?]\n    \n    \n\n\nRuntimeError: ignored\n\n\n\ndls.vocab\n# net(x)에서 뒤쪽의 값이 클수록 \"yunakim\" 을 의미한다.\n\n['yeonkyungkim', 'yunakim']\n\n\n\nximg = PILImage.create('/content/images/test/yeonkyungkim/5f00874f-87e0-47ea-b299-411238c078f3.jpg')\nx = first(dls.test_dl([ximg]))[0]\n\n\nwhy = torch.einsum('cb,abij-&gt;acij',net2[2].weight,net1(x))\n\n\nnet2[0](why)\n\nTensorImage([[[[0.2771]],\n\n              [[0.0351]]]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nnet(x)\n\nTensorImage([[0.2771, 0.0351]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nximg\n\n\n\n\n\nnet2(net1(x))\n\nTensorImage([[0.2771, 0.0351]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\n0.2771&gt;0.0421 이므로 ximg는 yenkyungkim일 확률이 더 높다.\n\n\n(why[0,0,:,:]).mean(), (why[0,1,:,:]).mean()\n\n(TensorImage(0.2771, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;),\n TensorImage(0.0351, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;))\n\n\n\n(why[0,0,:,:]).to(torch.int64)\n\nTensorImage([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [ 0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [ 0,  0, -2, -3, -2, -1,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [ 0, -1, -3, -3, -1,  0,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [ 0, -3, -3, -2,  0,  1,  0,  0,  0,  0,  1,  1,  1,  1,  0,  0],\n             [-1, -4, -3,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  0,  0],\n             [-2, -3, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  0,  1],\n             [-1, -2, -1,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  3],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  2,  2],\n             [ 0,  0,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  1,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  1,  2,  2,  1,  2,  2,  2,  1,  0,  0,  0,  0,  0,  0,  0]],\n            device='cuda:0')\n\n\n\nwhy_yeonkyungkim = why[0,0,:,:]\nwhy_yunakim = why[0,1,:,:]\n\n\nfig, ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_yeonkyungkim.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\nax[2].imshow(why_yunakim.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear')\n\n&lt;matplotlib.image.AxesImage at 0x7f48ffaa2ad0&gt;\n\n\n\n\n\n\nfig, ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[0].imshow(why_yeonkyungkim.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -&gt; ijc',dls.decode((x,))[0]).to(\"cpu\"))\nax[1].imshow(why_yunakim.to(\"cpu\").detach(),cmap='magma',extent=(0,511,511,0),interpolation='bilinear',alpha=0.5)\n\n&lt;matplotlib.image.AxesImage at 0x7f4844ce5d10&gt;\n\n\n\n\n\n\nsftmax = torch.nn.Softmax(dim=1)\n\n\npath = './images'\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_yeonkyungkim = why[0,0,:,:] \n        why_yunakim = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yeonkyungkim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yeonkyungkim(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yunakim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yunakim(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=25\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_yeonkyungkim = why[0,0,:,:] \n        why_yunakim = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yeonkyungkim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yeonkyungkim(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yunakim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yunakim(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=50\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_yeonkyungkim = why[0,0,:,:] \n        why_yunakim = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yeonkyungkim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yeonkyungkim(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yunakim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yunakim(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\nfig, ax = plt.subplots(5,5) \nk=100\nfor i in range(5):\n    for j in range(5): \n        x, = first(dls.test_dl([PILImage.create(get_image_files(path)[k])]))\n        why = torch.einsum('cb,abij -&gt; acij', net2[2].weight, net1(x))\n        why_yeonkyungkim = why[0,0,:,:] \n        why_yunakim = why[0,1,:,:] \n        catprob, dogprob = sftmax(net(x))[0][0].item(), sftmax(net(x))[0][1].item()\n        if catprob&gt;dogprob: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yeonkyungkim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yeonkyungkim(%2f)\" % catprob)\n        else: \n            dls.train.decode((x,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(why_yunakim.to(\"cpu\").detach(),alpha=0.5,extent=(0,511,511,0),interpolation='bilinear',cmap='magma')\n            ax[i][j].set_title(\"yunakim(%2f)\" % dogprob)\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n\n\n\n\n2. Overparameterized Model\n\nx = torch.rand([1000,1])*2-1\ny = 3.14 + 6.28*x + torch.randn([1000,1]) \n\n\nplt.plot(x,y,'o',alpha=0.1)\n\n\n\n\n\nx[:5]\n\ntensor([[ 0.5621],\n        [-0.7204],\n        [ 0.2043],\n        [-0.9416],\n        [ 0.7436]])\n\n\n\n# (1) y= beta0 + beta1*x1 + e \nnet = torch.nn.Linear(1,1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(x).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((yhat-y)**2)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(x).data,'-')\n\n\n\n\n\nnet.weight.data, net.bias.data\n\n(tensor([[6.3128]]), tensor([3.1519]))\n\n\nbeta0 = 3.1519, beta1=6.3128\n\n# (2) y= beta0 + e\nw0hat = torch.tensor([0.00],requires_grad=True) \n\n\n# 학습전\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,(x*0+w0hat).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = x*0 + w0hat \n    ## 2 \n    loss = torch.mean((yhat-y)**2)\n    ## 3 \n    loss.backward()\n    ## 4 \n    w0hat.data = w0hat.data - 0.1 * w0hat.grad\n    w0hat.grad = None\n\n\n# 학습 후\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,(x*0+w0hat).data,'-')\n\n\n\n\n\nw0hat\n\ntensor([3.1982], requires_grad=True)\n\n\n\nbeta0 = 3.1982\n\n\n# (3) y=beta1*x + e \n\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) \n\n\n# 학습전\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(x).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3 \n    loss.backward() \n    ## 4\n    optimizr.step()\n    optimizr.zero_grad() \n\n\n# 학습후\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\nnet.weight\n\nParameter containing:\ntensor([[6.3822]], requires_grad=True)\n\n\n\nbeta1 = 6.3822\n\n\n# (4) y= alpha0 + beta0 + beta1*x + e\n_1 = torch.ones([1000,1])\nX = torch.concat([_1,x],axis=1)\n\n\nnet = torch.nn.Linear(in_features=2,out_features=1) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) \n\n\n# 학습전\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(X).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3 \n    loss.backward() \n    ## 4\n    optimizr.step()\n    optimizr.zero_grad() \n\n\n# 학습후\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,net(X).data,'--')\n\n\n\n\n\nnet.bias,net.weight\n\n(Parameter containing:\n tensor([1.3951], requires_grad=True), Parameter containing:\n tensor([[1.7568, 6.3125]], requires_grad=True))\n\n\n\n# alpha0 + beta0\n1.3951+1.7568\n\n3.1519\n\n\n\nalpha0 + beat0 = 3.1519 이며 (1)에서 구한 beta0 값인 3.1519와 동일하다.\n\n\n# (5) y=alpha0 + beta0 + beta1*x + alpha1*x + e\nX = torch.concat([_1,_1,x,x],axis=1) \nX\n\ntensor([[ 1.0000,  1.0000,  0.5621,  0.5621],\n        [ 1.0000,  1.0000, -0.7204, -0.7204],\n        [ 1.0000,  1.0000,  0.2043,  0.2043],\n        ...,\n        [ 1.0000,  1.0000, -0.6327, -0.6327],\n        [ 1.0000,  1.0000,  0.8546,  0.8546],\n        [ 1.0000,  1.0000,  0.3835,  0.3835]])\n\n\n\nnet = torch.nn.Linear(in_features=4,out_features=1,bias=False) \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1) \n\n\n# 학습전\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(X).data,'-')\n\n\n\n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3 \n    loss.backward() \n    ## 4\n    optimizr.step()\n    optimizr.zero_grad() \n\n\n# 학습후\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(x,net(X).data,'-')\n\n\n\n\n\nnet.weight, net.bias\n\n(Parameter containing:\n tensor([[1.7991, 1.3527, 3.3789, 2.9408]], requires_grad=True), None)\n\n\n\n# alpha0 + beta0\n1.7991+1.3527\n\n3.1517999999999997\n\n\n\n# alpha1 + beta1\n3.3789+2.9408\n\n6.319699999999999\n\n\n\nalpha0+beta0 = 3.1518, alpha1+beta1 = 6.3197로 (1)에서 구한 값과 비슷하다.\n\n\n민정, 슬기, 성재, 세민, 구환 모두 옳은 설명\n\n\n\n3. 차원축소기법과 표현학습\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/STML2022/master/posts/iris.csv\")\ndf\n\n\n  \n    \n      \n\n\n\n\n\n\nSepal Length\nSepal Width\nPetal Length\nPetal Width\nSpecies\n\n\n\n\n0\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n1\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n2\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n3\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n4\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n...\n...\n...\n...\n...\n...\n\n\n145\n6.7\n3.0\n5.2\n2.3\nvirginica\n\n\n146\n6.3\n2.5\n5.0\n1.9\nvirginica\n\n\n147\n6.5\n3.0\n5.2\n2.0\nvirginica\n\n\n148\n6.2\n3.4\n5.4\n2.3\nvirginica\n\n\n149\n5.9\n3.0\n5.1\n1.8\nvirginica\n\n\n\n\n150 rows × 5 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nX = torch.tensor(df.drop(columns=['Species']).to_numpy(), dtype=torch.float32)\n\n\nX.shape\n\ntorch.Size([150, 4])\n\n\n\nl1 = torch.nn.Linear(in_features=4, out_features=2, bias=False)\nprint(l1(X).shape)\n\ntorch.Size([150, 2])\n\n\n\n# k=3이상인 경우 softmax와 crossentropyloss사용\n\na1=torch.nn.Softmax(dim=1)\nZ=a1(l1(X))\n\n\nl2 = torch.nn.Linear(in_features=2, out_features=4, bias=False)\n\n\nXhat = l2(l1(X))\n\n\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z.data,Xhat.data],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // before learning',size=25);\n\n\n\n\n\nnet = torch.nn.Sequential(\n    l1,   # 선형변환 \n    l2,\n)\n\nloss_fn= torch.nn.MSELoss()\noptimizr= torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1000): \n    ## 1 \n    Z = net[0](X)\n    Xhat = net[1](Z) \n    ## 2 \n    loss=loss_fn(Xhat,X) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\nfig,ax = plt.subplots(figsize=(10,10)) \nax.imshow(torch.concat([X,Z.data,Xhat.data],axis=1)[:10])\nax.set_xticks(np.arange(0,10)) \nax.set_xticklabels([r'$X_1$',r'$X_2$',r'$X_3$',r'$X_4$',r'$Z_1$',r'$Z_2$',r'$\\hat{X}_1$',r'$\\hat{X}_2$',r'$\\hat{X}_3$',r'$\\hat{X}_4$'])\nax.vlines([3.5,5.5],ymin=-0.5,ymax=9.5,lw=2,color='red',linestyle='dashed')\nax.set_title(r'First 10 obs of $\\bf [X, Z, \\hat{X}]$ // after learning',size=25);\n\n\n\n\n\n# (4) Z -&gt; y 로 가는 네트워크 설계\n\nnet=torch.nn.Linear(2,4)\n\n\nnet(Z)[:5]\n\ntensor([[ 1.9397, -2.4390,  4.0082, -4.5496],\n        [ 1.8009, -2.3025,  3.7815, -4.3085],\n        [ 1.8454, -2.2254,  3.7054, -4.1847],\n        [ 1.8578, -2.2069,  3.6879, -4.1551],\n        [ 1.9715, -2.4088,  3.9845, -4.5026]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\nloss_fn= torch.nn.BCEWithLogitsLoss()\noptimizr= torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(1000): \n    ## 1 \n    Xhat = net(Z)\n    ## 2 \n    loss=loss_fn(Xhat,X) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n    # 오류가 나는데 밑에 글을 봐도 잘 모르겠어용.. ㅠㅠ \n\nRuntimeError: ignored\n\n\n\n규빈, 민정, 성재, 슬기 모두 옳은 설명이다."
  },
  {
    "objectID": "posts/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html",
    "href": "posts/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html",
    "title": "기계학습 final(교수님)",
    "section": "",
    "text": "기말고사\nimport torch \nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html#hihello-90점",
    "href": "posts/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html#hihello-90점",
    "title": "기계학습 final(교수님)",
    "section": "1. hi?hello!! (90점)",
    "text": "1. hi?hello!! (90점)\n아래와 같은 데이터가 있다고 하자.\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5], txt_y[:5]\n\n(['h', 'i', '?', 'h', 'e'], ['i', '?', 'h', 'e', 'l'])\n\n\ntxt_x와 txt_y를 이용하여 아래와 같은 순서로 다음문자를 예측하고 싶은 신경망을 설계하고 싶다.\nh \\(\\to\\) i \\(\\to\\) ? \\(\\to\\) h \\(\\to\\) e \\(\\to\\) l \\(\\to\\) l \\(\\to\\) o \\(\\to\\) ! \\(\\to\\) ! \\(\\to\\) h \\(\\to\\) i \\(\\to\\) ? \\(\\to\\) h \\(\\to\\) e \\(\\to\\) \\(\\dots\\)\n(1)-(6) 의 풀이에 공통적으로 필요한 과정 정리\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n(1) torch.nn.RNN()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\nrnn = torch.nn.RNN(7,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden, hT = rnn(x) # _water 사실 생략할 수 있어요..\n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(2) torch.nn.RNNCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\ntorch.manual_seed(43052)\nrnncell = torch.nn.RNNCell(7,8).to(\"cuda:0\")\nlinr = torch.nn.Linear(8,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = [] \n    ht = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht = rnncell(xt,ht) \n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.005, 0.008, 0.972, 0.014, 0.001, 0.   ],\n       [0.   , 0.997, 0.002, 0.   , 0.   , 0.001, 0.   ],\n       [0.   , 0.001, 0.999, 0.   , 0.001, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.999, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n       [0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.001],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.001, 0.998, 0.   , 0.   , 0.   , 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(3) torch.nn.Module을 상속받은 클래스를 정의하고 (2)의 결과와 동일한 적합값이 나오는 신경망을 설계한 뒤 학습하라. (초기값을 적절하게 설정할 것)\n\nclass를 이용하지 않으면 점수없음.\ntorch.nn.RNN(), torch.nn.RNNCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.RNN(), torch.nn.RNNCell()을 코드에 포함시키는 것이 가능)\n\n(풀이)\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(7,8)\n        self.h2h = torch.nn.Linear(8,8) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,xt,ht):\n        ht = self.tanh(self.i2h(xt)+self.h2h(ht))\n        return ht\n\n\nrnncell = rNNCell().to(\"cuda:0\")\nlinr = torch.nn.Linear(8,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(linr.parameters()),lr=0.1)\n\n\n## 초기화의 설정을 위한 코드\ntorch.manual_seed(43052)\n_rnncell = torch.nn.RNNCell(7,8).to(\"cuda:0\")\n_linr = torch.nn.Linear(8,7).to(\"cuda:0\")\nrnncell.i2h.weight.data = _rnncell.weight_ih.data \nrnncell.h2h.weight.data = _rnncell.weight_hh.data \nrnncell.h2h.bias.data = _rnncell.bias_hh.data\nrnncell.i2h.bias.data = _rnncell.bias_ih.data\nlinr.weight.data = _linr.weight.data \nlinr.bias.data = _linr.bias.data \n\n\nfor epoc in range(100):\n    ## 1\n    hidden = [] \n    ht = torch.zeros(8).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht = rnncell(xt,ht)\n        ot = linr(ht) \n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.005, 0.008, 0.972, 0.014, 0.001, 0.   ],\n       [0.   , 0.997, 0.002, 0.   , 0.   , 0.001, 0.   ],\n       [0.   , 0.001, 0.999, 0.   , 0.001, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.999, 0.   , 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n       [0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.001],\n       [0.999, 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.001, 0.998, 0.   , 0.   , 0.   , 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(4) torch.nn.LSTM()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden, (hT,cT) = lstm(x)\n    output = linr(hidden)\n    ## 2\n    loss = loss_fn(output,y)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nyhat=soft(output)    \nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(5) torch.nn.LSTMCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라.\n(풀이)\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1\n    hidden = []\n    ht = torch.zeros(4).to(\"cuda:0\")\n    ct = torch.zeros(4).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden)\n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\narray([[0.   , 0.014, 0.084, 0.081, 0.822, 0.   , 0.   ],\n       [0.002, 0.91 , 0.   , 0.083, 0.003, 0.   , 0.001],\n       [0.001, 0.   , 0.999, 0.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.001, 0.005, 0.072, 0.917, 0.004, 0.   ],\n       [0.   , 0.   , 0.004, 0.   , 0.001, 0.995, 0.   ],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.999, 0.001],\n       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.999],\n       [0.998, 0.001, 0.   , 0.   , 0.   , 0.   , 0.   ],\n       [0.99 , 0.   , 0.006, 0.001, 0.   , 0.003, 0.   ],\n       [0.007, 0.   , 0.992, 0.   , 0.   , 0.001, 0.   ]], dtype=float32)\n\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);\n\n\n\n\n(6) (5)의 결과와 동일한 적합값을 출력하는 신경망을 직접설계한 뒤 학습시켜라. (초기값을 적절하게 설정할 것)\n\nclass를 이용하지 않아도 무방함.\ntorch.nn.LSTM(), torch.nn.LSTMCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.LSTM(), torch.nn.LSTMCell()을 코드에 포함시키는 것은 가능)\n\n(풀이)\n\nclass lSTMCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(7,16)\n        self.h2h = torch.nn.Linear(4,16) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,xt,past):\n        ht,ct = past \n        ifgo = self.i2h(xt) + self.h2h(ht) \n        it = sig(ifgo[0:4])\n        ft = sig(ifgo[4:8])\n        gt = tanh(ifgo[8:12])\n        ot = sig(ifgo[12:16])\n        ct = ft*ct + it*gt\n        ht = ot*self.tanh(ct) \n        return ht,ct\n\n\nlstmcell = lSTMCell().to(\"cuda:0\")\nlinr = torch.nn.Linear(4,7).to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(linr.parameters()),lr=0.1)\n\n\n# 초기값셋팅\ntorch.manual_seed(43052) \n_lstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\")\n_linr = torch.nn.Linear(4,7).to(\"cuda:0\")\nlstmcell.i2h.weight.data = _lstmcell.weight_ih.data \nlstmcell.h2h.weight.data = _lstmcell.weight_hh.data \nlstmcell.i2h.bias.data = _lstmcell.bias_ih.data\nlstmcell.h2h.bias.data = _lstmcell.bias_hh.data\nlinr.weight.data = _linr.weight.data \nlinr.bias.data = _linr.bias.data \n\n\nfor epoc in range(100):\n    ## 1\n    hidden = []     \n    ht = torch.zeros(4).to(\"cuda:0\")\n    ct = torch.zeros(4).to(\"cuda:0\")\n    for xt,yt in zip(x,y): \n        ht,ct = lstmcell(xt,(ht,ct))\n        hidden.append(ht) \n    hidden = torch.stack(hidden)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(output)\nyhat[:10].to(\"cpu\").detach().numpy().round(3)\n\n\nplt.matshow(yhat.to(\"cpu\").data[:10],cmap='bwr',vmin=-1,vmax=1)\nplt.xticks(range(7),labels=['!','?','h','i','e','l','o']);"
  },
  {
    "objectID": "posts/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html#다음을-읽고-참-거짓을-판단하여라.-10점",
    "href": "posts/2022_11_29_13wk_2_final_checkpoint_ipynb의_사본.html#다음을-읽고-참-거짓을-판단하여라.-10점",
    "title": "기계학습 final(교수님)",
    "section": "2. 다음을 읽고 참 거짓을 판단하여라. (10점)",
    "text": "2. 다음을 읽고 참 거짓을 판단하여라. (10점)\n(1) LSTM은 RNN보다 장기기억에 유리하다. (True)\n(2) torch.nn.Embedding(num_embeddings=2,embedding_dim=1)와 torch.nn.Linear(in_features=1,out_features=1)의 학습가능한 파라메터수는 같다. (True)\n(3) 아래와 같은 네트워크를 고려하자.\nnet = torch.nn.Linear(1,1)\n차원이 (n,1) 인 임의의 텐서에 대하여 net(x)와 net.forward(x)의 출력결과는 같다. (True)\n(4) 아래와 같이 a,b,c,d 가 반복되는 문자열이 반복되는 자료에서 다음문자열을 맞추는 과업을 수행하기 위해서는 반드시 순환신경망의 형태로 설계해야만 한다. (False) –&gt; 오타로인하여 문제삭제\na,b,c,d,a,b,c,d,...\n(5) RNN 혹은 LSTM 으로 신경망을 설계할 시 손실함수는 항상 torch.nn.CrossEntropyLoss 를 사용해야 한다. (False)"
  },
  {
    "objectID": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html",
    "href": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html",
    "title": "기계학습 (1019) 7주차",
    "section": "",
    "text": "import torch\nfrom fastai.vision.all import *\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#imports",
    "href": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#imports",
    "title": "기계학습 (1019) 7주차",
    "section": "",
    "text": "import torch\nfrom fastai.vision.all import *\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#깊은신경망-오버피팅",
    "href": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#깊은신경망-오버피팅",
    "title": "기계학습 (1019) 7주차",
    "section": "깊은신경망– 오버피팅",
    "text": "깊은신경망– 오버피팅\n\n데이터\n- model: \\(y_i = (0\\times x_i) + \\epsilon_i\\)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(100,1)\ny=torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y)\n\n\n\n\n\n\n모든 데이터를 사용하여 적합 (512, relu, 1000 epochs)\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss() #y가 연속형일때는 MSE, 0또는 1일땐 BCE\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y)\nplt.plot(x,net(x).data, '--')\n\n\n\n\n\n\n전체데이터를 8:2로 나누어서 8만을 학습\n- 데이터를 8:2로 나눈다 8:training 훈련 셋 2: 검증셋\n\nxtr = x[:80]\nytr = y[:80] \nxtest = x[80:] \nytest = y[80:] \n\n\nplt.plot(x,y,alpha=0.5)\nplt.plot(xtr,ytr)\nplt.plot(xtest,ytest)\n\n\n\n\n\nx.shape, xtr.shape, xtest.shape\n\n(torch.Size([100, 1]), torch.Size([80, 1]), torch.Size([20, 1]))\n\n\n\ny.shape, ytr.shape, ytest.shape\n\n(torch.Size([100, 1]), torch.Size([80, 1]), torch.Size([20, 1]))\n\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\n\n\n\n\n\n# 처음 80개만 가지고 net를 학습시키면, \n\n- (xtr,ytr) 만 가지고 net를 학습시킨다.\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    #               원래 yhat=net(X)  -&gt; 80개하니까 net(xtr)  -&gt; 변수가 많아져서.. 귀찮아져.. 그냥 loss에 바로 넣자!! \n    ## 2 \n    loss = loss_fn(net(xtr),ytr)    # 원래 loss_fn(yhat,y)  \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\n#plt.plot(xtr,net(xtr).data,'--')\n#plt.plot(xtest,net(xtest).data,'--')\nplt.plot(x,net(x).data,'--k') \n\n# 보여준 파란색 데이터는 잘맞는데.. 노란색 데이터는 잘 안맞는거 같아.\n# 이런 상황을 오버피팅 이라고 한다! -&gt; 파악하지 않아야 할 것까지 파악해 버린것.\n\n\n\n\n\n# 데이터 수에 비해 노드 수(feature수)가 많으면 오버피팅\n# 차원의 저주\n# 언더라인 외 오차항 따라가는거.. 오버피팅\n\n\n# 예시\n# y = 0,1,1,1,0,1,0,0,1\n# x1 = 0,0,0,1,0,0,0\n# x2 = \n# x3 = \n# 변수가 많으면 결정계수 값이 올라가서"
  },
  {
    "objectID": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#깊은신경망-드랍아웃",
    "href": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#깊은신경망-드랍아웃",
    "title": "기계학습 (1019) 7주차",
    "section": "깊은신경망– 드랍아웃",
    "text": "깊은신경망– 드랍아웃\n\n오버피팅의 해결\n\n# 오버피팅을 해결할 방법은 제대로 된 건 없지만.. 그 중 하나인 드랍아웃\n\n- 오버피팅의 해결책: 드랍아웃\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),   # 0.8은 0으로 0.2만 살아남음\n    torch.nn.Linear(in_features=512,out_features=1)  # 보통 linear해서 다 더하고 -&gt; sigmoid로 \n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    #\n    ## 2 \n    loss = loss_fn(net(xtr),ytr) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k') \nplt.title(r\"network is in training mode\",fontsize=15)\n\nText(0.5, 1.0, 'network is in training mode')\n\n\n\n\n\n\n# 더 오차항을 따라가는 거 같어 \n# 오잉 다시 돌려보면 그래프가 바껴 net 넣었는데 바뀌는게 이상해! \n\n- 올바른 사용법\n\nnet.training\n\nTrue\n\n\n\nnet.eval()\nnet.training\n\nFalse\n\n\n\nplt.plot(xtr,ytr,'o')\nplt.plot(xtest,ytest,'o')\nplt.plot(x,net(x).data,'--k') \nplt.title(r\"network is in evaluation mode\",fontsize=15)\n\nText(0.5, 1.0, 'network is in evaluation mode')\n\n\n\n\n\n\n\n드랍아웃 레이어\n\n# 드랍아웃 레이어는 뭔가? 왜 결과가 랜덤으로 나왔는가?\n\n\n_x = torch.linspace(0,1,101) \n_x \n\ntensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n        0.0900, 0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700,\n        0.1800, 0.1900, 0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600,\n        0.2700, 0.2800, 0.2900, 0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500,\n        0.3600, 0.3700, 0.3800, 0.3900, 0.4000, 0.4100, 0.4200, 0.4300, 0.4400,\n        0.4500, 0.4600, 0.4700, 0.4800, 0.4900, 0.5000, 0.5100, 0.5200, 0.5300,\n        0.5400, 0.5500, 0.5600, 0.5700, 0.5800, 0.5900, 0.6000, 0.6100, 0.6200,\n        0.6300, 0.6400, 0.6500, 0.6600, 0.6700, 0.6800, 0.6900, 0.7000, 0.7100,\n        0.7200, 0.7300, 0.7400, 0.7500, 0.7600, 0.7700, 0.7800, 0.7900, 0.8000,\n        0.8100, 0.8200, 0.8300, 0.8400, 0.8500, 0.8600, 0.8700, 0.8800, 0.8900,\n        0.9000, 0.9100, 0.9200, 0.9300, 0.9400, 0.9500, 0.9600, 0.9700, 0.9800,\n        0.9900, 1.0000])\n\n\n\ndout = torch.nn.Dropout(0.9)\ndout(_x)\n\ntensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.6000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  2.5000,  0.0000,  2.7000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  3.7000,  0.0000,  3.9000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  5.9000,  0.0000,  6.1000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         7.2000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  8.3000,  8.4000,  0.0000,  0.0000,  0.0000,\n         0.0000,  8.9000,  0.0000,  0.0000,  9.2000,  0.0000,  0.0000,  0.0000,\n         0.0000,  0.0000,  0.0000,  0.0000, 10.0000])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 랜덤으로 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n\n- 드랍아웃레이어 정리 - 구조: 입력 -&gt; 드랍아웃레이어 -&gt; 출력 - 역할: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 일정하게 되도록 조정 - 효과: 오버피팅을 억제하는 효과가 있음 (왜??) - 의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 로테이션으로 랜덤으로 결정됨. - 느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨"
  },
  {
    "objectID": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-data",
    "href": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-data",
    "title": "기계학습 (1019) 7주차",
    "section": "이미지자료분석– data",
    "text": "이미지자료분석– data\n- download data\n\nimport torch\nimport torchvision\n\n\npath = untar_data(URLs.MNIST)\n\n\n\n\n\n\n    \n      \n      100.03% [15687680/15683414 00:00&lt;00:00]\n    \n    \n\n\n- training set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n- test set\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\nyy = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape,XX.shape,y.shape,yy.shape\n\n(torch.Size([12665, 1, 28, 28]),\n torch.Size([2115, 1, 28, 28]),\n torch.Size([12665, 1]),\n torch.Size([2115, 1]))\n\n\n\n# training 12,656개.. 2,115개는.. test set?"
  },
  {
    "objectID": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-예비학습",
    "href": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-예비학습",
    "title": "기계학습 (1019) 7주차",
    "section": "이미지자료분석– CNN 예비학습",
    "text": "이미지자료분석– CNN 예비학습\n\n기존의 MLP 모형\n- 교재의 모형 (fastai.book)\n\n#collapse\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -&gt; \"node1\"\n    \"x2\" -&gt; \"node1\"\n    \"..\" -&gt; \"node1\"\n    \n    \"x784\" -&gt; \"node1\"\n    \"x1\" -&gt; \"node2\"\n    \"x2\" -&gt; \"node2\"\n    \"..\" -&gt; \"node2\"\n    \"x784\" -&gt; \"node2\"\n    \n    \"x1\" -&gt; \"...\"\n    \"x2\" -&gt; \"...\"\n    \"..\" -&gt; \"...\"\n    \"x784\" -&gt; \"...\"\n\n    \"x1\" -&gt; \"node30\"\n    \"x2\" -&gt; \"node30\"\n    \"..\" -&gt; \"node30\"\n    \"x784\" -&gt; \"node30\"\n\n\n    label = \"Layer 1: ReLU\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"y\"\n    \"node2\" -&gt; \"y\"\n    \"...\" -&gt; \"y\"\n    \"node30\" -&gt; \"y\"\n    label = \"Layer 2: Sigmoid\"\n}\n''')\n\n\n\n\n- 왜 28$$28 이미지를 784개의 벡터로 만든 다음에 모형을 돌려야 하는가?\n\n# nxp 매트릭스 꼴로.. 정리해서 넣으려고\n\n- 기존에 개발된 모형이 회귀분석 기반으로 되어있어서 결국 회귀분석 틀에 짜 맞추어서 이미지자료를 분석하는 느낌\n- observation의 차원은 \\(784\\)가 아니라 \\(1\\times (28\\times 28)\\)이 되어야 맞다.\n\n\n새로운 아키텍처의 제시\n- 예전\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\\(l_1\\): 선형변환, feature를 뻥튀기하는 역할\n\\(relu\\): 뻥튀기된 feature에 비선형을 추가하여 표현력 극대화\n\\(l_2\\): 선형변환, 뻥튀기된 feature를 요약 하는 역할 (=데이터를 요약하는 역할)\n\n- 새로운 아키텍처 - \\(conv\\): feature를 뻥튀기하는 역할 (2d ver \\(l_1\\) 느낌) - \\(relu\\): 뻥튀기된 feature에 비선형을 추가하여 표현력 극대화 - \\(pooling\\): 데이터를 요약하는 역할\n\n\nCONV 레이어 (선형변환의 2D 버전)\n- 우선 연산하는 방법만 살펴보자.\n(예시1)\n\ntorch.nn.Conv2d?\n\n\ntorch.manual_seed(43052)\n_conv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\n_conv.weight.data, _conv.bias.data\n\n(tensor([[[[-0.1733, -0.4235],\n           [ 0.1802,  0.4668]]]]),\n tensor([0.2037]))\n\n\n\n_X = torch.arange(0,4).reshape(1,2,2).float()  #(1,2,2):흑백이미지, 2x2\n_X\n\ntensor([[[0., 1.],\n         [2., 3.]]])\n\n\n\n(-0.1733)*0 + (-0.4235)*1 +\\\n(0.1802)*2 + (0.4668)*3 + 0.2037\n\n1.541\n\n\n\n_conv(_X)\n\ntensor([[[1.5410]]], grad_fn=&lt;SqueezeBackward1&gt;)\n\n\n(예시2) 잘하면 평균도 계산하겠다?\n\n_conv.weight.data = torch.tensor([[[[1/4, 1/4],[1/4,1/4]]]])\n_conv.bias.data = torch.tensor([0.0])\n\n\n_conv(_X) , (0+1+2+3)/4\n\n(tensor([[[1.5000]]], grad_fn=&lt;SqueezeBackward1&gt;), 1.5)\n\n\n(예시3) 이동평균?\n\n_X = torch.arange(0,25).float().reshape(1,5,5) \n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_conv(_X)\n\ntensor([[[ 3.,  4.,  5.,  6.],\n         [ 8.,  9., 10., 11.],\n         [13., 14., 15., 16.],\n         [18., 19., 20., 21.]]], grad_fn=&lt;SqueezeBackward1&gt;)\n\n\n(예시4) window size가 증가한다면? (2d의 이동평균느낌)\n\n_conv = torch.nn.Conv2d(1,1,(3,3)) # 입력1, 출력1, (3,3) window size    (3,3) 대신 3 넣어도 됨\n_conv.bias.data = torch.tensor([0.0])\n_conv.weight.data = torch.tensor([[[[1/9,1/9,1/9],[1/9,1/9,1/9],[1/9,1/9,1/9]]]])\n\n\n_X,_conv(_X)\n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]]),\n tensor([[[ 6.0000,  7.0000,  8.0000],\n          [11.0000, 12.0000, 13.0000],\n          [16.0000, 17.0000, 18.0000]]], grad_fn=&lt;SqueezeBackward1&gt;))\n\n\n\n(1+2+3+6+7+8+11+12+13)/9\n\n7.0\n\n\n(예시5) 피처뻥튀기\n\n_X = torch.tensor([1.0,1.0,1.0,1.0]).reshape(1,2,2)\n_X\n\ntensor([[[1., 1.],\n         [1., 1.]]])\n\n\n\n_conv = torch.nn.Conv2d(1,8,(2,2))\n_conv.weight.data.shape,_conv.bias.data.shape\n\n(torch.Size([8, 1, 2, 2]), torch.Size([8]))\n\n\n\n_conv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=&lt;ReshapeAliasBackward0&gt;)\n\n\n\ntorch.sum(_conv.weight.data[0,...])+_conv.bias.data[0],\\\ntorch.sum(_conv.weight.data[1,...])+_conv.bias.data[1]\n# 여기 이해 안감.. ㅠ \n\n(tensor(-0.3464), tensor(0.2739))\n\n\n결국 아래를 계산한다는 의미\n\ntorch.sum(_conv.weight.data,axis=(2,3)).reshape(-1)+ _conv.bias.data\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345])\n\n\n\n_conv(_X).reshape(-1)\n\ntensor([-0.3464,  0.2739,  0.1069,  0.6105,  0.0432,  0.8390,  0.2353,  0.2345],\n       grad_fn=&lt;ReshapeAliasBackward0&gt;)\n\n\n(잔소리) axis 사용 익숙하지 않으면 아래 꼭 들으세요..\n\nhttps://guebin.github.io/IP2022/2022/04/11/(6주차)-4월11일.html , numpy공부 4단계: 축\n\n\n\nReLU (2d)\n\n_X = torch.randn(25).reshape(1,5,5)\n_X\n\ntensor([[[ 0.2656,  0.0780,  3.0465,  1.0151, -2.3908],\n         [ 0.4749,  1.6519,  1.5454,  1.0376,  0.9291],\n         [-0.7858,  0.4190,  2.6057, -0.4022,  0.2092],\n         [ 0.9594,  0.6408, -0.0411, -1.0720, -2.0659],\n         [-0.0996,  1.1351,  0.9758,  0.4952, -0.5475]]])\n\n\n\na1=torch.nn.ReLU()\n\n\na1(_X)\n\ntensor([[[0.2656, 0.0780, 3.0465, 1.0151, 0.0000],\n         [0.4749, 1.6519, 1.5454, 1.0376, 0.9291],\n         [0.0000, 0.4190, 2.6057, 0.0000, 0.2092],\n         [0.9594, 0.6408, 0.0000, 0.0000, 0.0000],\n         [0.0000, 1.1351, 0.9758, 0.4952, 0.0000]]])\n\n\n\n\nMaxpooling 레이어\n\n_maxpooling = torch.nn.MaxPool2d((2,2))\n\n\n_X = torch.arange(16).float().reshape(1,4,4) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]]]),\n tensor([[[ 5.,  7.],\n          [13., 15.]]]))\n\n\n\n_X = torch.arange(25).float().reshape(1,5,5) \n\n\n_X, _maxpooling(_X) #경계에 있는건 버린당..(데이터를 요약해주는 거니까)\n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.],\n          [ 5.,  6.,  7.,  8.,  9.],\n          [10., 11., 12., 13., 14.],\n          [15., 16., 17., 18., 19.],\n          [20., 21., 22., 23., 24.]]]),\n tensor([[[ 6.,  8.],\n          [16., 18.]]]))\n\n\n\n_X = torch.arange(36).float().reshape(1,6,6) \n\n\n_X, _maxpooling(_X) \n\n(tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.],\n          [ 6.,  7.,  8.,  9., 10., 11.],\n          [12., 13., 14., 15., 16., 17.],\n          [18., 19., 20., 21., 22., 23.],\n          [24., 25., 26., 27., 28., 29.],\n          [30., 31., 32., 33., 34., 35.]]]),\n tensor([[[ 7.,  9., 11.],\n          [19., 21., 23.],\n          [31., 33., 35.]]]))"
  },
  {
    "objectID": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-구현-cpu",
    "href": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-구현-cpu",
    "title": "기계학습 (1019) 7주차",
    "section": "이미지자료분석– CNN 구현 (CPU)",
    "text": "이미지자료분석– CNN 구현 (CPU)\n\nX.shape\n\ntorch.Size([12665, 1, 28, 28])\n\n\n\n(1) Conv2d\n\nc1 = torch.nn.Conv2d(1,16,(5,5)) #16개로뻥튀기하고싶어\nprint(X.shape)\nprint(c1(X).shape)\n\n# 1장의채널이 16장으로 뻥튀기..\n# 28-&gt;24 윈도우사이즈만큼.. 한칸씩 이동하면서 나머지 데이터 빠졌엉. 마지막 4개빠짐\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\n\n\n\n\n(2) ReLU\n\na1 = torch.nn.ReLU()\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\n\n\n\n\n(3) MaxPool2D\n\nm1 =  torch.nn.MaxPool2d((2,2)) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\n\n\n\n# 16, 12, 12 숫자가 1로 바껴야함...\n\n\n\n(4) 적당히 마무리하고 시그모이드 태우자\n- 펼치자.\n(방법1)\n\nm1(a1(c1(X))).reshape(-1,2304).shape #레이어를 통과하는 느낌이 아닌거같ㅇㅏ요\n\ntorch.Size([12665, 2304])\n\n\n\n16*12*12 \n\n2304\n\n\n(방법2)\n\nflttn = torch.nn.Flatten()\n\n\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape) # 레이어...\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\n\n\n- 2304 \\(\\to\\) 1 로 차원축소하는 선형레이어를 설계\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\n\n\n- 시그모이드\n\na2 = torch.nn.Sigmoid()\n\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\nprint(a1(l1(flttn(m1(a1(c1(X)))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\ntorch.Size([12665, 1])\n\n\n- 네트워크 설계\n\nnet = torch.nn.Sequential(\n    c1, # 2d: 컨볼루션(선형변환), 피처 뻥튀기 \n    a1, # 2d: 렐루(비선형변환)\n    m1, # 2d: 맥스풀링: 데이터요약\n    flttn, # 2d-&gt;1d \n    l1, # 1d: 선형변환\n    a2 # 1d: 시그모이드(비선형변환) \n)\n\n\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nt1= time.time()\nfor epoc in range(100): \n    ## 1\n    yhat = net(X) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\nt2= time.time()\nt2-t1\n\n51.493837118148804\n\n\n\nplt.plot(y)\nplt.plot(net(X).data,'.')\nplt.title('Traning Set',size=15)\n\nText(0.5, 1.0, 'Traning Set')\n\n\n\n\n\n\nplt.plot(yy)\nplt.plot(net(XX).data,'.')\nplt.title('Test Set',size=15)\n\nText(0.5, 1.0, 'Test Set')"
  },
  {
    "objectID": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-구현-gpu",
    "href": "posts/2. CNN/기계학습특강2022_10_19_ipynb의_사본.html#이미지자료분석-cnn-구현-gpu",
    "title": "기계학습 (1019) 7주차",
    "section": "이미지자료분석– CNN 구현 (GPU)",
    "text": "이미지자료분석– CNN 구현 (GPU)\n\n1. dls\n\nds1=torch.utils.data.TensorDataset(X,y)\nds2=torch.utils.data.TensorDataset(XX,yy)\n\n\nX.shape\n\ntorch.Size([12665, 1, 28, 28])\n\n\n\nlen(X)/10  # batch_size=1266으로 하면 한 epoc을 10번 정도... 위에 epoc100했는데.. 그 세팅 맞춘거...........\n\n1266.5\n\n\n\nlen(XX)\n\n2115\n\n\n\n# 하나는 training, 하나는 test에 대응하는.. dl\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\n\ndls = DataLoaders(dl1,dl2) # 이거 fastai 지원함수입니다\n\n\n\n2. lrnr 생성: 아키텍처, 손실함수, 옵티마이저\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\n\n#아키텍처: 여기서는 네트워크...\n\n\nlrnr = Learner(dls,net,loss_fn) #architecture자리에 net\n\n\n\n3. 학습\n\nlrnr.fit(10) # fit (숫자:epoc 숫자를 넣는다.)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.904232\n0.605049\n00:01\n\n\n1\n0.661176\n0.371011\n00:00\n\n\n2\n0.507179\n0.213586\n00:00\n\n\n3\n0.392649\n0.113123\n00:00\n\n\n4\n0.304377\n0.065496\n00:00\n\n\n5\n0.238253\n0.043172\n00:00\n\n\n6\n0.188984\n0.031475\n00:00\n\n\n7\n0.151837\n0.024563\n00:00\n\n\n8\n0.123364\n0.020047\n00:00\n\n\n9\n0.101180\n0.016816\n00:00\n\n\n\n\n\n\n\n4. 예측 및 시각화\n\n# lrnr.model\n\n\n# net\n\n\n# id(net), id(lrnr.model)\n\n\nnet.to(\"cpu\")  # 네트워크으ㅔ 있는 모든 parameter를 cpu로 옮긴다\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n- 결과를 시각화하면 아래와 같다.\n\nplt.plot(net(X).data,'.')\nplt.title(\"Training Set\",size=15)\n\nText(0.5, 1.0, 'Training Set')\n\n\n\n\n\n\nplt.plot(net(XX).data,'.')\nplt.title(\"Test Set\",size=15)\n\nText(0.5, 1.0, 'Test Set')\n\n\n\n\n\n- 빠르고 적합결과도 좋음\n\n# accuracy차이가 별로 없어보여. \n\n\n\nLrnr 오브젝트\n\nlrnr.model\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nnet\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n\n\n\nid(lrnr.model), id(net)\n\n(140681387850000, 140681387850000)\n\n\n\nlrnr.model(X)\n\ntensor([[5.4047e-03],\n        [5.1475e-04],\n        [9.8561e-04],\n        ...,\n        [9.9602e-01],\n        [9.9584e-01],\n        [9.9655e-01]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n\nBCEWithLogitsLoss\n- BCEWithLogitsLoss = Sigmoid + BCELoss - 왜 써요? 수치적으로 더 안정\n- 사용방법\n\ndls 만들기\n\n\nds1=torch.utils.data.TensorDataset(X,y)\nds2=torch.utils.data.TensorDataset(XX,yy)\n\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\n\ndls = DataLoaders(dl1,dl2) # 이거 fastai 지원함수입니다\n\n\nlrnr생성\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,1),\n    #torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCEWithLogitsLoss()\nlrnr = Learner(dls,net,loss_fn) \n\n\n학습\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.896794\n0.560268\n00:00\n\n\n1\n0.613384\n0.301413\n00:00\n\n\n2\n0.454223\n0.169741\n00:00\n\n\n3\n0.346758\n0.092166\n00:00\n\n\n4\n0.268065\n0.056573\n00:00\n\n\n5\n0.210524\n0.039757\n00:00\n\n\n6\n0.167973\n0.030431\n00:00\n\n\n7\n0.135910\n0.024560\n00:00\n\n\n8\n0.111290\n0.020503\n00:00\n\n\n9\n0.092058\n0.017516\n00:00\n\n\n\n\n\n\n예측 및 시각화\n\n\nnet.to(\"cpu\")\n\nSequential(\n  (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n  (1): ReLU()\n  (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (3): Flatten(start_dim=1, end_dim=-1)\n  (4): Linear(in_features=2304, out_features=1, bias=True)\n)\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(X).data,',',color=\"C1\")\nax[1].plot(y)\nax[1].plot(a2(net(X)).data,',')\nfig.suptitle(\"Training Set\",size=15)\n\nText(0.5, 0.98, 'Training Set')\n\n\n\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].plot(net(XX).data,',',color=\"C1\")\nax[1].plot(yy)\nax[1].plot(a2(net(XX)).data,',')\nfig.suptitle(\"Test Set\",size=15)\n\nText(0.5, 0.98, 'Test Set')"
  },
  {
    "objectID": "posts/2022_09_07_(1주차)_9월7일_ipynb의_사본.html",
    "href": "posts/2022_09_07_(1주차)_9월7일_ipynb의_사본.html",
    "title": "기계학습 (0907) 1주차",
    "section": "",
    "text": "기계학습특강\n\n# 우리의 1차 목표: 이미지 -&gt; 개/고양이 판단하는 모형을 채용하고, 그 모형에 데이터를 넣어서 학습하고, 그 모형의 결과를 판단하고 싶다. (즉 클래시파이어를 만든다는 소리)\n# 우리의 2차 목표: 그 모형에 \"새로운\" 자료를 전달하여 이미지를 분류할 것이다. (즉 클래시파이어를 쓴다는 소리)\n\n\nfrom fastai.vision.all import *\n\n\npath=untar_data(URLs.PETS)/'images'\n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 01:16&lt;00:00]\n    \n    \n\n\n\npath\n\nPath('/root/.fastai/data/oxford-iiit-pet/images')\n\n\n\nPILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg')\n\n\n\n\n\n_lst = '/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg','/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_10.jpg'\n\n\n_lst[0]\n\n'/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_1.jpg'\n\n\n\nfaaaa = get_image_files(path)\n#교수님은 filenames로 설정함\n\n\nfaaaa[0]\n\nPath('/root/.fastai/data/oxford-iiit-pet/images/leonberger_137.jpg')\n\n\n\nPILImage.create('/root/.fastai/data/oxford-iiit-pet/images/newfoundland_28.jpg')\n\n\n\n\n\nPILImage.create(faaaa[0])\n\n\n\n\n\nprint(faaaa[1])\nPILImage.create(faaaa[1])\n\n/root/.fastai/data/oxford-iiit-pet/images/Birman_139.jpg\n\n\n\n\n\n\nprint(faaaa[3])\nPILImage.create(faaaa[3])\n\n/root/.fastai/data/oxford-iiit-pet/images/Egyptian_Mau_148.jpg\n\n\n\n\n\n\nprint(faaaa[6])\nPILImage.create(faaaa[6])\n\n/root/.fastai/data/oxford-iiit-pet/images/Siamese_79.jpg\n\n\n\n\n\n\n'A'.isupper()\n\nTrue\n\n\n\n'abdjlkfwe.jpg'[0]\n\n'a'\n\n\n\ndef f(fname):\n  if fname[0].isupper():\n    return 'cat'\n  else:\n    return 'dog'\n\n\ndls = ImageDataLoaders.from_name_func(path,faaaa,f,item_tfms=Resize(224))\n\n\ndls.show_batch(max_n=25)\n\n\n\n\n\n# 우리의 1차 목표: 이미지 -&gt; 개/고양이 판단하는 모형을 채용하고, 그 모형에 데이터를 넣어서 학습하고, 그 모형의 결과를 판단하고 싶다. (즉 클래시파이어를 만든다는 소리)\n# 우리의 2차 목표: 그 모형에 \"새로운\" 자료를 전달하여 이미지를 분류할 것이다. (즉 클래시파이어를 쓴다는 소리)\n\n\n\n## 오브젝트.. 오브젝트에는 동사와 명사 가 있어요\n\n### 명사\n# (1) 데이터\n# (2) 채용한 모형의 이론\n# (3) 평가기준 matric\n\n\n\n\n### 동사\n# (1) 학습\n# (2) 판단\n\n\nysj = cnn_learner(dls,resnet34,metrics=error_rate)\n\n##저항률 확인(잘 파악하는지 확인하기 위해서 metrics=error_rate 이용)\n\nysj.fine_tune(1)                  \n              ## 3을 쓰면 1보다는 많이 한다는 뜻  \n              ## 학습하다..동사,,\n\n/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.147350\n0.014042\n0.004060\n00:56\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.053051\n0.012090\n0.004736\n00:52\n\n\n\n\n\n\n?cnn_learner\n\n\nPILImage.create(faaaa[1])\n\n\n\n\n\nysj.predict(PILImage.create(faaaa[1]))\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 3.0773e-10]))\n\n\nysj.predict(PILImage.create(faaaa[6])) #동사이고.. 뒤에 점찍었으니까 함수다 생각하기 # 입력을 이미지 자체로 넣었는데, 이미지가 저장된 path만 넣어도 되지않을까?\n\nysj.predict(faaaa[6])\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 2.2963e-10]))\n\n\n\nysj.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n##ysj가 잘구현이 되는지 체크를 해야함\n# 체크를 하는 object를 만들어야함\nchecker = Interpretation.from_learner(ysj)\n\n\n\n\n\n\n\n\n\nchecker.plot_top_losses(16)\n\n# 첫번째 사진에서 5.59는 로스이고 1퍼의 확률로 강아지라고 생각함\n# 로스는 몇퍼의 확률로 잘못생각했느냐에 따라서 달라질 수 있음\n# 맞추는 걸 넘어서 확실해야 로스가 적다. (확신의여부)\n\n# 오버피팅 아냐..? 과대적합..? 자기들이 이미 다학습된 내용 가지고 보여주는거아냐? 생각-&gt;새로운 이미지 부여\n\n\n\n\n\n\n\n\n\n\n\n\nimg=PILImage.create(requests.get('https://dimg.donga.com/ugc/CDB/SHINDONGA/Article/5e/0d/9f/01/5e0d9f011a9ad2738de6.jpg').content)\nysj.predict(img)\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([2.8106e-06, 1.0000e+00]))\n\n\n\nimg=PILImage.create(requests.get('https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcnSq1X%2Fbtq4o9AdWTH%2FHTm9TZG4AszSwLPFlVfGW0%2Fimg.jpg').content)\nysj.predict(img)\n\n\n\n\n\n\n\n\n('dog', TensorBase(1), TensorBase([1.0909e-06, 1.0000e+00]))\n\n\n\nimg=PILImage.create(requests.get('https://image.edaily.co.kr/images/photo/files/NP/S/2022/04/PS22042501396.jpg').content)\nysj.predict(img)\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([1.0000e+00, 2.6542e-12]))\n\n\n\nimg=PILImage.create(requests.get('https://blog.kakaocdn.net/dn/zfQQi/btrydI0vGzm/3YY3KrPEwKN558e27H6t0k/img.jpg').content)\nysj.predict(img)\n\n\n\n\n\n\n\n\n('cat', TensorBase(0), TensorBase([0.9805, 0.0195]))\n\n\n\nPILImage.create('/강아지사진1.jpg')"
  },
  {
    "objectID": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html",
    "href": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html",
    "title": "기계학습 (1031) 9주차",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#import",
    "href": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#import",
    "title": "기계학습 (1031) 9주차",
    "section": "",
    "text": "import torch\nimport pandas as pd\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#define-some-funtions",
    "href": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#define-some-funtions",
    "title": "기계학습 (1031) 9주차",
    "section": "Define some funtions",
    "text": "Define some funtions\n- 활성화함수들\n\nsig = torch.nn.Sigmoid()\nsoft = torch.nn.Softmax(dim=1)\ntanh = torch.nn.Tanh()\n\n\n_x = torch.linspace(-5,5,100)\nplt.plot(_x,tanh(_x))\nplt.title(\"tanh(x)\", size=15)\n\nText(0.5, 1.0, 'tanh(x)')\n\n\n\n\n\n- 문자열 -&gt; 숫자로 바꾸는 함수\n\ndef f(txt,mapping):\n    return [mapping[key] for key in txt] \n\n(사용예시1)\n\ntxt = ['a','b','a']\nmapping = {'a':33,'b':-22}\nprint('변환전: %s'% txt)\nprint('변환후: %s'% f(txt,mapping))\n\n변환전: ['a', 'b', 'a']\n변환후: [33, -22, 33]\n\n\n(사용예시2)\n\ntxt = ['a','b','a']\nmapping = {'a':[1,0],'b':[0,1]}\nprint('변환전: %s'% txt)\nprint('변환후: %s'% f(txt,mapping))\n\n변환전: ['a', 'b', 'a']\n변환후: [[1, 0], [0, 1], [1, 0]]"
  },
  {
    "objectID": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#exam1-ab",
    "href": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#exam1-ab",
    "title": "기계학습 (1031) 9주차",
    "section": "Exam1: ab",
    "text": "Exam1: ab\n\ndata\n\ntxt = list('ab')*100\ntxt[:10]\n\n['a', 'b', 'a', 'b', 'a', 'b', 'a', 'b', 'a', 'b']\n\n\n\nlen(txt)\n\n200\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\ntxt_x[:5],txt_y[:5] #xa가 입력으로 들어가면 b를 뱉어내고..\n\n(['a', 'b', 'a', 'b', 'a'], ['b', 'a', 'b', 'a', 'b'])\n\n\n\n\n선형모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 – 실패\n- 데이터정리\n\nx = torch.tensor(f(txt_x,{'a':0,'b':1})).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,{'a':0,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습 및 결과 시각화\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5]) #밑에 노란색줄 what=0\n\n\n\n\n\n잘 학습이 안되었다.\n\n- 학습이 잘 안된 이유\n\npd.DataFrame({'x':x[:5].reshape(-1),'y':y[:5].reshape(-1)})\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\n0.0\n1.0\n\n\n1\n1.0\n0.0\n\n\n2\n0.0\n1.0\n\n\n3\n1.0\n0.0\n\n\n4\n0.0\n1.0\n\n\n\n\n\n\n\n현재 \\(\\hat{y}_i = \\hat{w}x_i\\) 꼴의 아키텍처이고 \\(y_i \\approx \\hat{w}x_i\\) 가 되는 적당한 \\(\\hat{w}\\)를 찾아야 하는 상황 - \\((x_i,y_i)=(0,1)\\) 이면 어떠한 \\(\\hat{w}\\)를 선택해도 \\(y_i \\approx \\hat{w}x_i\\)를 만드는 것이 불가능\n- \\((x_i,y_i)=(1,0)\\) 이면 \\(\\hat{w}=0\\)일 경우 \\(y_i \\approx \\hat{w}x_i\\)로 만드는 것이 가능\n상황을 종합해보니 \\(\\hat{w}=0\\)으로 학습되는 것이 그나마 최선\n\n\n(풀이2) 1개의 파라메터 – 성공, but 확장성이 없는 풀이\n- 0이라는 값이 문제가 되므로 인코딩방식의 변경\n\nx = torch.tensor(f(txt_x,{'a':-1,'b':1})).float().reshape(-1,1) \ny = torch.tensor(f(txt_y,{'a':-1,'b':1})).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[-1.],\n         [ 1.],\n         [-1.],\n         [ 1.],\n         [-1.]]),\n tensor([[ 1.],\n         [-1.],\n         [ 1.],\n         [-1.],\n         [ 1.]]))\n\n\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(2000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과는 성공\n\nplt.plot(y[:5],'o')\nplt.plot(net(x).data[:5])\n\n\n\n\n\n딱봐도 클래스가 3개일 경우 확장이 어려워 보인다.\n\n\n\n\n로지스틱 모형을 이용한 풀이\n\n(풀이1) 1개의 파라메터 – 실패\n- 데이터를 다시 a=0, b=1로 정리\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 학습\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=False)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 결과해석: 예상되었던 실패임 - 아키텍처는 \\(\\hat{y}_i = \\text{sig}(\\hat{w}x_i)\\) 꼴이다. - \\((x_i,y_i)=(0,1)\\) 이라면 어떠한 \\(\\hat{w}\\)을 선택해도 \\(\\hat{w}x_i=0\\) 이다. 이경우 \\(\\hat{y}_i = \\text{sig}(0) = 0.5\\) 가 된다. - \\((x_i,y_i)=(1,0)\\) 이라면 \\(\\hat{w}=-5\\)와 같은 값으로 선택하면 \\(\\text{sig}(-5) \\approx 0 = y_i\\) 와 같이 만들 수 있다. - 상황을 종합하면 net의 weight는 \\(\\text{sig}(\\hat{w}x_i) \\approx 0\\) 이 되도록 적당한 음수로 학습되는 것이 최선임을 알 수 있다.\n\nnet.weight # 적당한 음수값으로 학습되어있음을 확인\n\nParameter containing:\ntensor([[-4.0070]], requires_grad=True)\n\n\n\n\n(풀이2) 2개의 파라메터 + 좋은 초기값 – 성공\n- 동일하게 a=0, b=1로 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 네트워크에서 bias를 넣기로 결정함\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- net의 초기값을 설정 (이것은 좋은 초기값임)\n\nnet.weight.data = torch.tensor([[-5.00]])\nnet.bias.data = torch.tensor([+2.500])\n\n\nnet(x)[:10]\n\ntensor([[ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 학습전 결과\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습후결과\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o') #bias가 0값을 뭉개주는..\n\n\n\n\n\n\n(풀이3) 2개의 파라메터 + 나쁜초기값 – 성공\n- a=0, b=1\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 이전과 동일하게 바이어스가 포함된 네트워크 설정\n\nnet = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 초기값설정 (이 초기값은 나쁜 초기값임)\n\nnet.weight.data = torch.tensor([[+5.00]])\nnet.bias.data = torch.tensor([-2.500])\n\n\nnet(x)[:10]\n\ntensor([[-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000],\n        [-2.5000],\n        [ 2.5000]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 학습전상태: 반대모양으로 되어있다.\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:10],'o')\nplt.plot(sig(net(x)).data[:10],'--o')\n\n\n\n\n\n결국 수렴하긴 할듯\n\n\n\n(풀이4) 3개의 파라메터를 쓴다면?\n- a=0, b=1로 코딩\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,1)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,1)\n\n\nx[:5],y[:5]\n\n(tensor([[0.],\n         [1.],\n         [0.],\n         [1.],\n         [0.]]),\n tensor([[1.],\n         [0.],\n         [1.],\n         [0.],\n         [1.]]))\n\n\n- 3개의 파라메터를 사용하기 위해서 아래와 같은 구조를 생각하자.\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n위와 같은 네트워크를 설정하면 3개의 파라메터를 사용할 수 있다. 적절한 ACTIVATION_FUNCTION을 골라야 하는데 실험적으로 tanh가 적절하다고 알려져있다. (\\(\\to\\) 그래서 우리도 실험적으로 이해해보자)\n\n(예비학습1) net(x)와 사실 net.forwardx(x)는 같다.\n\nnet(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n\nnet.forward(x)[:5] # 풀이3에서 학습한 네트워크임\n\ntensor([[-0.1584],\n        [ 0.1797],\n        [-0.1584],\n        [ 0.1797],\n        [-0.1584]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n그래서 net.forward를 재정의하면 net(x)의 기능을 재정의 할 수 있다.\n\n# over riding ? \n\n\nnet.forward = lambda x: 1 \n\n\n“lambda x: 1” 은 입력이 x 출력이 1인 함수를 의미 (즉 입력값에 상관없이 항상 1을 출력하는 함수)\n“net.forward = lambda x:1” 이라고 새롭게 선언하였므로 앞으론 net.forward(x), net(x) 도 입력값에 상관없이 항상 1을 출력하게 될 것임\n\n\nnet(x)\n\n1\n\n\n(예비학습2) torch.nn.Module을 상속받아서 네트워크를 만들면 (= “class XXX(torch.nn.Module):” 와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n(예시1)\n\nclass Mynet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Sigmoid()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet1()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n(예시2)\n\nclass Mynet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.ReLU()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet2()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.RuLU(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n(예시3)\n\nclass Mynet3(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Tanh()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet3()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n클래스에 대한 이해가 부족한 학생을 위한 암기방법\nstep1: 아래와 코드를 복사하여 틀을 만든다. (이건 무조건 고정임, XXXX 자리는 원하는 이름을 넣는다)\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        \n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\n\nnet(x)에 사용하는 x임, yhat은 net.forward(x) 함수의 리턴값임\n사실, x/yhat은 다른 변수로 써도 무방하나 (예를들면 input/output 이라든지) 설명의 편의상 x와 yhat을 고정한다.\n\nstep2: def __init__(self):에 사용할 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx 와 같은 식으로 정의한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\nstep3: def forward:에 “x –&gt; yhat” 으로 가는 과정을 묘사한 코드를 작성하고 yhat을 리턴하도록 한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Tanh()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 레이어 정의 끝\n    def forward(self,x):\n        ## yhat을 어떻게 구할것인지 정의 \n        u = self.xxx1(x) \n        v = self.xxx2(u)\n        yhat = self.xxx3(v) \n        ## 정의 끝\n        return yhat\n예비학습 끝\n\n- 우리가 하려고 했던 것: 아래의 아키텍처에서\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.ACTIVATION_FUNCTION(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\nACTIVATION의 자리에 tanh가 왜 적절한지 직관을 얻어보자.\n- 실험결과1(Sig): Sigmoid activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet1()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_1(x):=Sigmoid(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 실험결과2(ReLU): RuLU activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet2()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=ReLU(x)$\",size=20)\nfig.tight_layout()\n\n\n\n\n- 실험결과3(Tanh): Tanh activation을 포함한 아키텍처로 학습시킨 25개의 적합결과\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Mynet3()\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        optimizr = torch.optim.Adam(net.parameters())\n        for epoc in range(1000):\n            ## 1\n            yhat = net(x)\n            ## 2\n            loss = loss_fn(yhat,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        ax[i][j].plot(y[:5],'o')\n        ax[i][j].plot(sig(net(x[:5])).data,'--o')\nfig.suptitle(r\"$a_2(x):=Tanh(x)$\",size=20)        \nfig.tight_layout()\n\n\n\n\n- 실험해석 - sig: 주황색선의 변동폭이 작음 + 항상 0.5근처로 머무는 적합값이 존재 - relu: 주황색선의 변동폭이 큼 + 항상 0.5근처로 머무는 적합값이 존재 - tanh: 주황색선의 변동폭이 큼 + 0.5근처로 머무는 적합값이 존재X\n- 실험해보니까 tanh가 우수한것 같다. \\(\\to\\) 앞으로는 tanh를 쓰자.\n\n\n\n소프트맥스로 확장\n\n(풀이1) 로지스틱모형에서 3개의 파라메터 버전을 그대로 확장\n\nmapping = {'a':[1,0],'b':[0,1]}\nx = torch.tensor(f(txt_x,mapping)).float().reshape(-1,2)\ny = torch.tensor(f(txt_y,mapping)).float().reshape(-1,2)\nx[:5],y[:5]\n\n(tensor([[1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.]]),\n tensor([[0., 1.],\n         [1., 0.],\n         [0., 1.],\n         [1., 0.],\n         [0., 1.]]))\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=2,bias=False)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\ny[:5][:,0]\n\ntensor([0., 1., 0., 1., 0.])\n\n\n\nplt.plot(y[:5][:,1],'o')\nplt.plot(soft(net(x[:5]))[:,1].data,'--r')\n\n\n\n\n\nfig,ax = plt.subplots(1,2)\nax[0].imshow(y[:5])\nax[1].imshow(soft(net(x[:5])).data)\n\n&lt;matplotlib.image.AxesImage at 0x7f2633e40f90&gt;"
  },
  {
    "objectID": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#embedding-layer",
    "href": "posts/3. RNN/2022_10_31_(9주차)_10월31일_ipynb의_사본.html#embedding-layer",
    "title": "기계학습 (1031) 9주차",
    "section": "Embedding Layer",
    "text": "Embedding Layer\n\nmotive\n- 결국 최종적으로는 아래와 같은 맵핑방식이 확장성이 있어보인다.\n\nmapping = {'a':[1,0,0],'b':[0,1,0],'c':[0,0,1]} # 원핫인코딩 방식 \n\n- 그런데 매번 \\(X\\)를 원핫인코딩하고 Linear 변환하는것이 번거로운데 이를 한번에 구현하는 함수가 있으면 좋겠다. \\(\\to\\) torch.nn.Embedding Layer가 그 역할을 한다.\n\nmapping = {'a':0,'b':1,'c':2}\nx = torch.tensor(f(list('abc')*100,mapping))\ny = torch.tensor(f(list('bca')*100,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 2, 0, 1]), tensor([1, 2, 0, 1, 2]))\n\n\n\ntorch.manual_seed(43052)\nebdd = torch.nn.Embedding(num_embeddings=3,embedding_dim=1) # x-&gt; Xonehot (n,1)-&gt;(n,3)\n\n\nebdd(x)[:5]\n\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843],\n        [-0.8178],\n        [-0.7052]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 그런데 사실 언뜻보면 아래의 linr 함수와 역할의 차이가 없어보인다.\n\ntorch.manual_seed(43052)\nlinr = torch.nn.Linear(in_features=1,out_features=1)\n\n\nlinr(x.float().reshape(-1,1))[:5]\n\ntensor([[-0.8470],\n        [-1.1937],\n        [-1.5404],\n        [-0.8470],\n        [-1.1937]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 차이점: 파라메터수에 차이가 있다.\n\nebdd.weight\n\nParameter containing:\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843]], requires_grad=True)\n\n\n\nlinr.weight, linr.bias\n\n(Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n결국 ebdd는 아래의 구조에 해당하는 파라메터들이고\n\n$=\n\\[\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix}\\]\n\n\\[\\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\]\nnet(x)=\n\\[\\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\end{bmatrix}\\]\n=\n\\[\\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\\\ -0.8178 \\\\ -0.7052  \\end{bmatrix}\\]\n$\n\nlinr는 아래의 구조에 해당하는 파라메터이다.\n\n\\(\\text{x[:5]}= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\quad net(x)= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\times (-0.3467) + (-0.8470)=\\begin{bmatrix} -0.8470 \\\\ -1.1937 \\\\ -1.5404 \\\\ -0.8470 \\\\ -1.1937 \\end{bmatrix}\\)\n\n\n\n연습 (ab문제 소프트맥스로 확장한 것 다시 풀이)\n- 맵핑\n\nmapping = {'a':0,'b':1}\nx = torch.tensor(f(txt_x,mapping))\ny = torch.tensor(f(txt_y,mapping))\nx[:5],y[:5]\n\n(tensor([0, 1, 0, 1, 0]), tensor([1, 0, 1, 0, 1]))\n\n\n- torch.nn.Embedding 을 넣은 네트워크\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=2,embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=2)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- 학습\n\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y[:5],'o')\nplt.plot(soft(net(x[:5]))[:,1].data,'--r')\n\n\n\n\n\nplt.imshow(soft(net(x[:5])).data)\n\n&lt;matplotlib.image.AxesImage at 0x7f2633f7f450&gt;"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html",
    "title": "기계학습 (1130) 12주차",
    "section": "",
    "text": "순환신경망 minor topics"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-abcabc",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-abcabc",
    "title": "기계학습 (1130) 12주차",
    "section": "data: abcabC",
    "text": "data: abcabC\n\ntxt = list('abcabC')*100\ntxt[:8]\ntxt_x = txt[:-1] \ntxt_y = txt[1:]\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\") \n\n\nx.shape\n\ntorch.Size([599, 4])"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실험",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실험",
    "title": "기계학습 (1130) 12주차",
    "section": "실험",
    "text": "실험\n- 실험1\n\nHIDDEN = 3\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment1: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험2\n\nHIDDEN = 4\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment2: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n\n\n\n- 실험3\n\nHIDDEN = 8\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,8))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, hT = rnn(x,_water)\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combind = torch.concat([hidden,yhat],axis=1)\n        ax[i][j].matshow(combind.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment3: RNN with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#결론",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#결론",
    "title": "기계학습 (1130) 12주차",
    "section": "결론",
    "text": "결론\n- 노드수가 많으면 학습에 유리함"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-abcc",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-abcc",
    "title": "기계학습 (1130) 12주차",
    "section": "data: ab(c,C)",
    "text": "data: ab(c,C)\n\n# torch.manual_seed(43052)\n# txta = 'a'*50\n# txtb = 'b'*50\n# prob_upper = torch.bernoulli(torch.zeros(50)+0.5) \n# txtc = list(map(lambda x: 'c' if x==1 else 'C', prob_upper))\n# txt = ''.join([txta[i]+','+txtb[i]+','+txtc[i]+',' for i in range(50)]).split(',')[:-1]\n# txt_x = txt[:-1] \n# txt_y = txt[1:]\n# pd.DataFrame({'txt_x':txt_x,'txt_y':txt_y}).to_csv(\"2022-11-25-ab(c,C).csv\",index=False)\n\n\ndf= pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2022/main/posts/IV.%20RNN/2022-11-25-ab(c%2CC).csv\")\ndf\n\n\n\n\n\n\n\n\ntxt_x\ntxt_y\n\n\n\n\n0\na\nb\n\n\n1\nb\nc\n\n\n2\nc\na\n\n\n3\na\nb\n\n\n4\nb\nc\n\n\n...\n...\n...\n\n\n144\na\nb\n\n\n145\nb\nC\n\n\n146\nC\na\n\n\n147\na\nb\n\n\n148\nb\nc\n\n\n\n\n149 rows × 2 columns\n\n\n\n\nmapping = {'a':0,'b':1,'c':2,'C':3} \nx= torch.nn.functional.one_hot(torch.tensor(f(df.txt_x,mapping))).float()\ny= torch.nn.functional.one_hot(torch.tensor(f(df.txt_y,mapping))).float()\n\n\nx = x.to(\"cuda:0\")\ny = y.to(\"cuda:0\")"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실험-1",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실험-1",
    "title": "기계학습 (1130) 12주차",
    "section": "실험",
    "text": "실험\n- 실험1\n\nHIDDEN = 3\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combinded = torch.concat([yhat,y],axis=1)\n        ax[i][j].matshow(combinded.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment1: LSTM with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()\n\n# 2행 4열-&gt;과적합되어있음.. c,C 확실히 알수 없는데 확실하게 맞추고있네? -&gt; 과적합이라고 보자!\n\n\n\n\n- 실험2\n\nHIDDEN = 16\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,HIDDEN).to(\"cuda:0\")\n        linr = torch.nn.Linear(HIDDEN,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n        _water = torch.zeros(1,HIDDEN).to(\"cuda:0\")\n        for epoc in range(500):\n            ## 1\n            hidden, (hT,cT) = lstm(x,(_water,_water))\n            output = linr(hidden)\n            ## 2\n            loss = loss_fn(output,y)\n            ## 3\n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        yhat=soft(output)    \n        combinded = torch.concat([yhat,y],axis=1)\n        ax[i][j].matshow(combinded.to(\"cpu\").data[-6:],cmap='bwr',vmin=-1,vmax=1)\nfig.suptitle(\"experiment2: LSTM with {} hidden nodes\".format(HIDDEN),size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#결론-1",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#결론-1",
    "title": "기계학습 (1130) 12주차",
    "section": "결론",
    "text": "결론\n- 노드수가 너무 많으면 오버피팅 경향도 있음"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-human-numbers-5",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-human-numbers-5",
    "title": "기계학습 (1130) 12주차",
    "section": "data: human numbers 5",
    "text": "data: human numbers 5\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n\n\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \nmapping\n\n{',': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:] \n\n\ntxt_x[0:5], txt_y[0:5]\n\n(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#torch를-이용한-learn",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#torch를-이용한-learn",
    "title": "기계학습 (1130) 12주차",
    "section": "torch를 이용한 learn",
    "text": "torch를 이용한 learn\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(6,20).to(\"cuda:0\")                  #히든레이어 20개\nlinr = torch.nn.Linear(20,6).to(\"cuda:0\") \nloss_fn = torch.nn.CrossEntropyLoss()                    #손실함수 적당히 정의해주기\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\n_water = torch.zeros(1,20).to(\"cuda:0\")\nfor epoc in range(50):\n    ## 1 \n    hidden, (hT,cT) =lstm(x,(_water,_water))\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()     \n\n\nplt.matshow(soft(output).data[-10:].to(\"cpu\"),cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f6bbf69b890&gt;"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#fastai-이용한-learn",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#fastai-이용한-learn",
    "title": "기계학습 (1130) 12주차",
    "section": "fastai 이용한 learn",
    "text": "fastai 이용한 learn\n\nds1 = torch.utils.data.TensorDataset(x,y)\nds2 = torch.utils.data.TensorDataset(x,y) # dummy \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=998)  #X의 full batch사이즈임\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=998) # dummy    #test에 해당하는 거.. 그냥 트레이닝이랑 똑같이 만들자. dls가 두개를 이용해서 만들어야 하니까 \ndls = DataLoaders(dl1,dl2) #데이터로드 두개를 이용해서 만들어야 한다.\n\n\n# lrnr=Learner(dls,net,loss_fn) 이렇게 하려고 했는데 \n# loss_fn은 만들 수 있어\n# 근데 net에서.. 두개의 네트워크를 같이 쓰고 있으니까 이걸 하나의 네트워크로 통일해서 넣기가 애매하다. lstm을 넣어야할지? linear를 넣어야할지? 애매함.\n# 두개이 연속동작을 한번에 해야해\n# class이용해서 해보자!\n\n\nclass MyLSTM(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.lstm = torch.nn.LSTM(6,20)\n        self.linr = torch.nn.Linear(20,6) \n    def forward(self,x):\n        _water = torch.zeros(1,20).to(\"cuda:0\")\n        hidden, (hT,cT) =self.lstm(x,(_water,_water))\n        output = self.linr(hidden)\n        return output         \n\n\nnet = MyLSTM().to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\nlrnr = Learner(dls,net,loss_fn,lr=0.1)\n\n\nlrnr.fit(50)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.918821\n1.547683\n00:00\n\n\n1\n1.731377\n1.771274\n00:00\n\n\n2\n1.744945\n1.490624\n00:00\n\n\n3\n1.679425\n1.400951\n00:00\n\n\n4\n1.621457\n1.431488\n00:00\n\n\n5\n1.588175\n1.398044\n00:00\n\n\n6\n1.559340\n1.291965\n00:00\n\n\n7\n1.523507\n1.127941\n00:00\n\n\n8\n1.475921\n0.959611\n00:00\n\n\n9\n1.419471\n0.861778\n00:00\n\n\n10\n1.363497\n0.815888\n00:00\n\n\n11\n1.312624\n0.780459\n00:00\n\n\n12\n1.266544\n0.742232\n00:00\n\n\n13\n1.223979\n0.715809\n00:00\n\n\n14\n1.185103\n0.671282\n00:00\n\n\n15\n1.147897\n0.620188\n00:00\n\n\n16\n1.111588\n0.575581\n00:00\n\n\n17\n1.076424\n0.529901\n00:00\n\n\n18\n1.042135\n0.475089\n00:00\n\n\n19\n1.008015\n0.418487\n00:00\n\n\n20\n0.973913\n0.368120\n00:00\n\n\n21\n0.940148\n0.322788\n00:00\n\n\n22\n0.906926\n0.285818\n00:00\n\n\n23\n0.874595\n0.254371\n00:00\n\n\n24\n0.843313\n0.218208\n00:00\n\n\n25\n0.812716\n0.187723\n00:00\n\n\n26\n0.782985\n0.158780\n00:00\n\n\n27\n0.754088\n0.133884\n00:00\n\n\n28\n0.726112\n0.112403\n00:00\n\n\n29\n0.699107\n0.093460\n00:00\n\n\n30\n0.673082\n0.075678\n00:00\n\n\n31\n0.647987\n0.059713\n00:00\n\n\n32\n0.623807\n0.047068\n00:00\n\n\n33\n0.600592\n0.037162\n00:00\n\n\n34\n0.578363\n0.029585\n00:00\n\n\n35\n0.557125\n0.023816\n00:00\n\n\n36\n0.536864\n0.019337\n00:00\n\n\n37\n0.517551\n0.015811\n00:00\n\n\n38\n0.499145\n0.013043\n00:00\n\n\n39\n0.481606\n0.010892\n00:00\n\n\n40\n0.464891\n0.009220\n00:00\n\n\n41\n0.448957\n0.007893\n00:00\n\n\n42\n0.433761\n0.006812\n00:00\n\n\n43\n0.419261\n0.005925\n00:00\n\n\n44\n0.405417\n0.005203\n00:00\n\n\n45\n0.392191\n0.004621\n00:00\n\n\n46\n0.379547\n0.004154\n00:00\n\n\n47\n0.367454\n0.003775\n00:00\n\n\n48\n0.355879\n0.003463\n00:00\n\n\n49\n0.344794\n0.003202\n00:00\n\n\n\n\n\n\nplt.matshow(soft(lrnr.model(x)[-10:]).data.to(\"cpu\"),cmap = 'bwr', vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f6bbbb779d0&gt;"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-hihello",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-hihello",
    "title": "기계학습 (1130) 12주차",
    "section": "data: hi?hello!!",
    "text": "data: hi?hello!!\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트1-_water의-생략",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트1-_water의-생략",
    "title": "기계학습 (1130) 12주차",
    "section": "세트1: _water의 생략",
    "text": "세트1: _water의 생략\n- 코드1: 정석코드\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\n_water = torch.zeros(1,4).to(\"cuda:0\")\nlstm(x, (_water,_water))\n\n(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],\n         [-0.0786, -0.1430, -0.0250,  0.1189],\n         [-0.0300, -0.2256, -0.1324,  0.1439],\n         ...,\n         [-0.0723,  0.0620,  0.1913,  0.2015],\n         [-0.1155,  0.0746,  0.1747,  0.2938],\n         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;)))\n\n\n\n# 히든레이거 값\n# HT\n# CT\n\n- 코드2: _water 는 사실 없어도 괜찮았어..\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\nlstm(x)\n\n(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],\n         [-0.0786, -0.1430, -0.0250,  0.1189],\n         [-0.0300, -0.2256, -0.1324,  0.1439],\n         ...,\n         [-0.0723,  0.0620,  0.1913,  0.2015],\n         [-0.1155,  0.0746,  0.1747,  0.2938],\n         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;)))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트2-x.shape-l-h_in-or-lnh_in",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트2-x.shape-l-h_in-or-lnh_in",
    "title": "기계학습 (1130) 12주차",
    "section": "세트2: x.shape = (\\(L\\), \\(H_{in}\\)) or (\\(L\\),\\(N\\),\\(H_{in}\\))",
    "text": "세트2: x.shape = (\\(L\\), \\(H_{in}\\)) or (\\(L\\),\\(N\\),\\(H_{in}\\))\n- 파라메터 설명\n\n\\(L\\) = sequece length = 시계열의 길이 = 간장을 몇 년 전통으로 이어갈지 (time시리지의 length)\n\\(N\\) = batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의 시계열로 쪼갤지 &lt;– 왜 이걸 해야해?\n\\(H_{in}\\) = input_size = 시점을 고정하였을 경우 입력자료의 차원 = 입력시계열이 시점별로 몇개의 변수로 나타내어 지는지? = 만약에 원핫인코딩으로 단어를 정리하면 단어수를 의미함\n\n\n# x.shape = [999,7]  &lt;- len가 999이고 구별되는 것이 7개 \n# 7개 이거를 Hin으로 생각.. \n# Hin: Hnet 라고 생각..\n# x,shape=[999,N,Hin] 이렇게 생긴 N이 있대 \n\n# Hin \"시점을 고정했을때\"   만약 x[0] = 0., 0., 1., 0., 0.,  h를 2로 맵핑했으니까 저 1은 h를 의미해 \n# 즉 하나의 시점에는 7개 차원인 정보들에 대한 입력..! \n\n# 만약 x.shape=[1000,7] dlaus 1000x7인데, 반으로 쪼개서 500x7, 500x7로 만들면 여기서 N=2이다.\n# 지금우리는 쪼개고 있지 않고 N=1로ㅓ만 진행하눈중 \n\n- 코드2: _water 는 사실 없어도 괜찮았어..\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\nlstm(x)\n\n(tensor([[-0.1547,  0.0673,  0.0695,  0.1563],\n         [-0.0786, -0.1430, -0.0250,  0.1189],\n         [-0.0300, -0.2256, -0.1324,  0.1439],\n         ...,\n         [-0.0723,  0.0620,  0.1913,  0.2015],\n         [-0.1155,  0.0746,  0.1747,  0.2938],\n         [-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n (tensor([[-0.2350, -0.1559, -0.1093,  0.2682]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;),\n  tensor([[-0.4451, -0.2456, -0.1900,  0.6232]], device='cuda:0',\n         grad_fn=&lt;SqueezeBackward1&gt;)))\n\n\n- 코드3: x의 차원은 사실 엄밀하게는 (\\(L\\),\\(N\\),\\(H_{in}\\)) 와 같다…\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\nlstm(x.reshape(999,1,7))\n# lstm(x) 한것과 같은 숫자가 나온당.\n# batch_first=False가 기본 \n\n(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563]],\n \n         [[-0.0786, -0.1430, -0.0250,  0.1189]],\n \n         [[-0.0300, -0.2256, -0.1324,  0.1439]],\n \n         ...,\n \n         [[-0.0723,  0.0620,  0.1913,  0.2015]],\n \n         [[-0.1155,  0.0746,  0.1747,  0.2938]],\n \n         [[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n        grad_fn=&lt;CudnnRnnBackward0&gt;),\n (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;),\n  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;)))\n\n\n- 코드4: batch_first=True옵션을 사용하여 lstm을 만든경우\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4,batch_first=True).to(\"cuda:0\")\n\n\n# lstm(x.reshape(999,1,7)) 하면 값이 이상하게 나온다! \n# batch_first=true옵션을 사용하면 (N,L,Hin) 으로 써줘야 한당. \n\n\nlstm(x.reshape(1,999,7))\n\n(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563],\n          [-0.0786, -0.1430, -0.0250,  0.1189],\n          [-0.0300, -0.2256, -0.1324,  0.1439],\n          ...,\n          [-0.0723,  0.0620,  0.1913,  0.2015],\n          [-0.1155,  0.0746,  0.1747,  0.2938],\n          [-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n        grad_fn=&lt;CudnnRnnBackward0&gt;),\n (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;),\n  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;)))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트3-hidden.shape-dtimes-num_layers-h_out-or-dtimes-num_layers-n-h_out",
    "title": "기계학습 (1130) 12주차",
    "section": "세트3: hidden.shape = (\\(D\\times\\) num_layers, \\(H_{out}\\)) or (\\(D\\times\\) num_layers, \\(N\\), \\(H_{out}\\))",
    "text": "세트3: hidden.shape = (\\(D\\times\\) num_layers, \\(H_{out}\\)) or (\\(D\\times\\) num_layers, \\(N\\), \\(H_{out}\\))\n- 파라메터 설명\n\n\\(D\\) = 2 if bidirectional=True otherwise 1 = 양방향이면 2, 단방향이면 1 (우리는 단방향만 배움)\nnum_layres = 중첩된 RNN일 경우 (우리는 중첩을 안시켰음)\n\\(N\\) = batch size = 전체데이터는 몇 개의 시계열이 있는지 = 전체 데이터를 몇개의 시계열로 쪼갤지 &lt;– 왜 이걸 해야해?\n\\(H_{out}\\) = 히든노드의 수\n\n\n# _water는 (1,히든)이였는데 여기서 1은 D X num_layers의 계산값이였다. \n# num_layres는 중첩시킨적없어서 이값도 1\n# N= 쪼갠적없으니까 1\n\n- 코드5: x.shape = (\\(L\\),\\(1\\),\\(H_{in}\\)) \\(\\to\\) hidden.shape = (\\(1\\),\\(1\\),\\(H_{out}\\))\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(7,4).to(\"cuda:0\")\n\n\n_water = torch.zeros(1,1,4).to(\"cuda:0\")    #zeros(1,4)하면 차원 에러가남 \nlstm(x.reshape(999,1,7),(_water,_water))\n\n(tensor([[[-0.1547,  0.0673,  0.0695,  0.1563]],\n \n         [[-0.0786, -0.1430, -0.0250,  0.1189]],\n \n         [[-0.0300, -0.2256, -0.1324,  0.1439]],\n \n         ...,\n \n         [[-0.0723,  0.0620,  0.1913,  0.2015]],\n \n         [[-0.1155,  0.0746,  0.1747,  0.2938]],\n \n         [[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n        grad_fn=&lt;CudnnRnnBackward0&gt;),\n (tensor([[[-0.2350, -0.1559, -0.1093,  0.2682]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;),\n  tensor([[[-0.4451, -0.2456, -0.1900,  0.6232]]], device='cuda:0',\n         grad_fn=&lt;CudnnRnnBackward0&gt;)))\n\n\n- 사실 _water.shape = (1,\\(H_{out}\\)) 에서 1은 observation의 차원을 의미하는게 아님 (그런데 대충 그렇게 생각해도 무방함)\n\n한 시점의 콩물에 대하여 양방향으로 간장을 만들면 _water.shape = (2,h)\n한 시점의 콩물에 대하여 3중첩으로 간장을 만들면 _water.shape = (3,h)\n한 시점의 콩물에 대하여 3중첩간장을 양방향으로 만들면 _water.shape = (6,h)\n\n\n# 원래 1은 D X 넘버오브레이어인데"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-hihello-1",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-hihello-1",
    "title": "기계학습 (1130) 12주차",
    "section": "data: hi?hello!!",
    "text": "data: hi?hello!!\n\ntxt = list('hi?hello!!')*100 \ntxt_x = txt[:-1]\ntxt_y = txt[1:]\n\n\nmapping = {'!':0, '?':1,'h':2,'i':3,'e':4,'l':5,'o':6} \nx= torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny= torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트1-_water의-생략-1",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트1-_water의-생략-1",
    "title": "기계학습 (1130) 12주차",
    "section": "세트1: _water의 생략",
    "text": "세트1: _water의 생략\n- 코드1: 정석코드\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[[1]]\n_water = torch.zeros(1,4).to(\"cuda:0\")\nxt.shape, _water.shape\n\n(torch.Size([1, 7]), torch.Size([1, 4]))\n\n\n\nlstmcell(xt,(_water,_water))\n\n(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;),\n tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;))\n\n\n- 코드2: _water의 생략\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[[1]]\nxt.shape\n\ntorch.Size([1, 7])\n\n\n\nlstmcell(xt)\n\n(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;),\n tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트2-xt.shape-nh_in-or-h_in",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트2-xt.shape-nh_in-or-h_in",
    "title": "기계학습 (1130) 12주차",
    "section": "세트2: xt.shape = (\\(N\\),\\(H_{in}\\)) or (\\(H_{in}\\))",
    "text": "세트2: xt.shape = (\\(N\\),\\(H_{in}\\)) or (\\(H_{in}\\))\n- 코드2: _water의 생략\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[[1]]\nxt.shape\n\ntorch.Size([1, 7])\n\n\n\nlstmcell(xt)\n\n(tensor([[-0.0290, -0.1758, -0.0537,  0.0598]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;),\n tensor([[-0.0582, -0.4566, -0.1256,  0.1922]], device='cuda:0',\n        grad_fn=&lt;ThnnFusedLstmCellBackward0&gt;))\n\n\n- 코드3:\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[1]\nxt.shape\n\ntorch.Size([7])\n\n\n\nlstmcell(xt)\n\n(tensor([-0.0290, -0.1758, -0.0537,  0.0598], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([-0.0582, -0.4566, -0.1256,  0.1922], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트3-hidden.shape-nh_out-or-h_out",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#세트3-hidden.shape-nh_out-or-h_out",
    "title": "기계학습 (1130) 12주차",
    "section": "세트3: hidden.shape = (\\(N\\),\\(H_{out}\\)) or (\\(H_{out}\\))",
    "text": "세트3: hidden.shape = (\\(N\\),\\(H_{out}\\)) or (\\(H_{out}\\))\n- 코드4: xt.shape = (\\(H_{in}\\)) \\(\\to\\) _water.shape = \\((H_{out})\\)\n\ntorch.manual_seed(43052) \nlstmcell = torch.nn.LSTMCell(7,4).to(\"cuda:0\") \n\n\nxt = x[1]\n_water = torch.zeros(4).to(\"cuda:0\")\nxt.shape,_water.shape\n\n(torch.Size([7]), torch.Size([4]))\n\n\n\nlstmcell(xt, (_water,_water))\n\n(tensor([-0.0290, -0.1758, -0.0537,  0.0598], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([-0.0582, -0.4566, -0.1256,  0.1922], device='cuda:0',\n        grad_fn=&lt;SqueezeBackward1&gt;))"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#똑같은-코드들-정리",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#똑같은-코드들-정리",
    "title": "기계학습 (1130) 12주차",
    "section": "똑같은 코드들 정리",
    "text": "똑같은 코드들 정리\n- 원래 1은 단순히 observation의 차원이 아니다. 즉 \\({\\bf X}_{n \\times p}\\)에서 \\(n\\)에 대응하는 차원으로 생각할 수 없다.\n- 그런데 (1) 단방향 (2) 조각내지 않은 시계열 (3) 중첩하지 않은 순환망에 한정하여서는 observation 처럼 생각해도 무방하다. &lt;– 엄밀하게는 이게 위험한 생각임. 하지만 정식으로 모두 따지려면 너무 헷갈림"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실제구현시-기억할-것",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#실제구현시-기억할-것",
    "title": "기계학습 (1130) 12주차",
    "section": "실제구현시 기억할 것",
    "text": "실제구현시 기억할 것\n- 현실적으로 (1)-(3)이 아닌 조건에서는 Cell 단위로 연산을 이용할 일이 없다. (느리거든요) // 그냥 이해용으로 구현\n- torch.nn.RNN 혹은 torch.nn.LSTM 으로 네트워크를 구성할시 _water의 dim을 명시할 일도 없다.\n- 오로지 고려해야 할 것은 입력시계열을 조각낼지 조각내지 않을지"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data",
    "title": "기계학습 (1130) 12주차",
    "section": "data",
    "text": "data\n\ntxt = list('hi!')*3 + list('hi?')*3"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#조각내지-않은-시계열",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#조각내지-않은-시계열",
    "title": "기계학습 (1130) 12주차",
    "section": "조각내지 않은 시계열",
    "text": "조각내지 않은 시계열\n\ntxt_x = txt[:-1] \ntxt_y = txt[1:] \n\n\nmapping = {'!':0, '?':1, 'h':2, 'i':3} \nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")\n\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.matshow(soft(output)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n# 이것도 밑 그래프랑 같은! \n\n\nhidden, _ = lstm(x)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f6b994a6f50&gt;"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#조각난-시계열",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#조각난-시계열",
    "title": "기계학습 (1130) 12주차",
    "section": "조각난 시계열",
    "text": "조각난 시계열\n\ntxt1= txt[:9]\ntxt2= txt[9:]\n\n\ntxt1,txt2\n\n(['h', 'i', '!', 'h', 'i', '!', 'h', 'i', '!'],\n ['h', 'i', '?', 'h', 'i', '?', 'h', 'i', '?'])\n\n\n\ntxt1_x = txt1[:-1] \ntxt1_y = txt1[1:] \ntxt2_x = txt2[:-1] \ntxt2_y = txt2[1:] \n\n\nmapping = {'!':0, '?':1, 'h':2, 'i':3} \nx1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_x,mapping))).float().to(\"cuda:0\")\ny1 = torch.nn.functional.one_hot(torch.tensor(f(txt1_y,mapping))).float().to(\"cuda:0\")\nx2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_x,mapping))).float().to(\"cuda:0\")\ny2 = torch.nn.functional.one_hot(torch.tensor(f(txt2_y,mapping))).float().to(\"cuda:0\")\n\n\nx1.shape, y1.shape, x2.shape, y2.shape\n\n(torch.Size([8, 4]),\n torch.Size([8, 4]),\n torch.Size([8, 4]),\n torch.Size([8, 4]))\n\n\n\nxx = torch.stack([x1,x2],axis=1)   # x1과 x2를 합치자\nyy = torch.stack([y1,y2],axis=1)\nxx.shape, yy.shape\n\n(torch.Size([8, 2, 4]), torch.Size([8, 2, 4]))\n\n\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(xx) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output[:,0,:],yy[:,0,:]) + loss_fn(output[:,1,:],yy[:,1,:])\n    # (8,4), (8,4)가 stack되어있는데 첫번째 스택 봅고. yy도 뽑고.. 그럼 로스가 한번 계산이 되는데 다시 로스를 더하면 \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nfig , ax = plt.subplots(1,2) \nax[0].matshow(soft(output[:,0,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\nax[1].matshow(soft(output[:,1,:]).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f6b70111650&gt;\n\n\n\n\n\n\nhidden, _ = lstm(x)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f6b70111350&gt;\n\n\n\n\n\n- 조각난 시계열로 학습한 경우는 hi!에서 hi?로 바뀔 수 없다. 왜냐햐면 그러한 연결정보가 끊어져 있으니까"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#재미있는-실험",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#재미있는-실험",
    "title": "기계학습 (1130) 12주차",
    "section": "재미있는 실험",
    "text": "재미있는 실험\n- x1만 배운다면?\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x1) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y1)\n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhidden, _ = lstm(x2)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f6b701ba890&gt;\n\n\n\n\n\n- x2만 배운다면?\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(4,10).to(\"cuda:0\")\nlinr = torch.nn.Linear(10,4).to(\"cuda:0\")\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(100):\n    ## 1 \n    hidden, _ = lstm(x2) \n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y2)\n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhidden, _ = lstm(x1)\nplt.matshow(soft(linr(hidden)).to(\"cpu\").data,cmap='bwr',vmin=-1,vmax=1)\n\n&lt;matplotlib.image.AxesImage at 0x7f6b9809ef50&gt;"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-human-numbers-5-1",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#data-human-numbers-5-1",
    "title": "기계학습 (1130) 12주차",
    "section": "data: human numbers 5",
    "text": "data: human numbers 5\n\ntxt = (['one',',','two',',','three',',','four',',','five',',']*100)[:-1]\n\n\nmapping = {',':0, 'one':1, 'two':2, 'three':3, 'four':4, 'five':5} \nmapping\n\n{',': 0, 'one': 1, 'two': 2, 'three': 3, 'four': 4, 'five': 5}\n\n\n\ntxt_x = txt[:-1]\ntxt_y = txt[1:] \n\n\ntxt_x[0:5], txt_y[0:5]\n\n(['one', ',', 'two', ',', 'three'], [',', 'two', ',', 'three', ','])\n\n\n\nx = torch.nn.functional.one_hot(torch.tensor(f(txt_x,mapping))).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(torch.tensor(f(txt_y,mapping))).float().to(\"cuda:0\")"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#fastai-이용한-learn-1",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#fastai-이용한-learn-1",
    "title": "기계학습 (1130) 12주차",
    "section": "fastai 이용한 learn",
    "text": "fastai 이용한 learn\n\nds1 = torch.utils.data.TensorDataset(x,y)\nds2 = torch.utils.data.TensorDataset(x,y) # dummy \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=998)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=998) # dummy \ndls = DataLoaders(dl1,dl2) \n\n\nclass MyLSTM(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        torch.manual_seed(43052)\n        self.lstm = torch.nn.LSTM(6,20)\n        self.linr = torch.nn.Linear(20,6) \n    def forward(self,x):\n        _water = torch.zeros(1,20).to(\"cuda:0\")\n        hidden, (hT,cT) =self.lstm(x,(_water,_water))\n        output = self.linr(hidden)\n        return output         \n\n\nnet = MyLSTM().to(\"cuda:0\")\nloss_fn = torch.nn.CrossEntropyLoss()\n\n\nlrnr = Learner(dls,net,loss_fn,lr=0.1)\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.762846\n1.502211\n00:00\n\n\n1\n1.631212\n1.620583\n00:00\n\n\n2\n1.627597\n1.443686\n00:00\n\n\n3\n1.580216\n1.368762\n00:00\n\n\n4\n1.536200\n1.307310\n00:00\n\n\n5\n1.496099\n1.216339\n00:00\n\n\n6\n1.453670\n1.113821\n00:00\n\n\n7\n1.408125\n1.019931\n00:00\n\n\n8\n1.361426\n0.941434\n00:00\n\n\n9\n1.315507\n0.884034\n00:00\n\n\n\n\n\n\nsoft(lrnr.model(x)).data.to(\"cpu\").numpy().round(3)\n\narray([[0.935, 0.009, 0.015, 0.011, 0.016, 0.014],\n       [0.133, 0.164, 0.242, 0.172, 0.141, 0.147],\n       [0.982, 0.003, 0.004, 0.003, 0.004, 0.003],\n       ...,\n       [0.122, 0.171, 0.242, 0.174, 0.146, 0.144],\n       [0.984, 0.003, 0.004, 0.002, 0.004, 0.003],\n       [0.119, 0.172, 0.244, 0.175, 0.144, 0.145]], dtype=float32)"
  },
  {
    "objectID": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#torch를-이용한-learn-1",
    "href": "posts/3. RNN/2022_11_30_12wk_checkpoint_ipynb의_사본.html#torch를-이용한-learn-1",
    "title": "기계학습 (1130) 12주차",
    "section": "torch를 이용한 learn",
    "text": "torch를 이용한 learn\n\ntorch.manual_seed(43052) \nlstm = torch.nn.LSTM(6,20).to(\"cuda:0\") \nlinr = torch.nn.Linear(20,6).to(\"cuda:0\") \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = Adam(list(lstm.parameters())+list(linr.parameters()),lr=0.1)\n\n\nfor epoc in range(10):\n    ## 1 \n    hidden, _ = lstm(x)\n    output = linr(hidden) \n    ## 2 \n    loss = loss_fn(output,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()     \n\n\nhidden, _ = lstm(x)\noutput = linr(hidden) \nsoft(output).data.to(\"cpu\").numpy().round(3)\n\narray([[0.935, 0.009, 0.015, 0.011, 0.016, 0.014],\n       [0.133, 0.164, 0.242, 0.172, 0.141, 0.147],\n       [0.982, 0.003, 0.004, 0.003, 0.004, 0.003],\n       ...,\n       [0.122, 0.171, 0.242, 0.174, 0.146, 0.144],\n       [0.984, 0.003, 0.004, 0.002, 0.004, 0.003],\n       [0.119, 0.172, 0.244, 0.175, 0.145, 0.145]], dtype=float32)"
  },
  {
    "objectID": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html",
    "href": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html",
    "title": "기계학습 (0914) 2주차",
    "section": "",
    "text": "#\nfrom fastai.vision.all import *  ## 이미지분석\nfrom fastai.collab import * ## 추천시스템\nfrom fastai.text.all import * ## 텍스트분석 \nfrom fastai.vision.gan import * ## GAN (이미지생성)\n\n\nimport pandas as pd"
  },
  {
    "objectID": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#imports",
    "href": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#imports",
    "title": "기계학습 (0914) 2주차",
    "section": "",
    "text": "#\nfrom fastai.vision.all import *  ## 이미지분석\nfrom fastai.collab import * ## 추천시스템\nfrom fastai.text.all import * ## 텍스트분석 \nfrom fastai.vision.gan import * ## GAN (이미지생성)\n\n\nimport pandas as pd"
  },
  {
    "objectID": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#이미지-자료분석-실습-지난시간-복습",
    "href": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#이미지-자료분석-실습-지난시간-복습",
    "title": "기계학습 (0914) 2주차",
    "section": "이미지 자료분석 실습 (지난시간 복습)",
    "text": "이미지 자료분석 실습 (지난시간 복습)\n\n1단계: 데이터의 정리\n\npath=untar_data(URLs.PETS)/'images'\n\n\n\n\n\n\n    \n      \n      100.00% [811712512/811706944 00:09&lt;00:00]\n    \n    \n\n\n\npath\n\n#path뒤에 점찍으면 뒤에 함수 나옴. \n#path.ls 하면 뒤에 목록이 나온다!!\n\nPath('/root/.fastai/data/oxford-iiit-pet/images')\n\n\n\n#path에서 이미지 파일만 가져오기\nfnames = get_image_files(path)\n\n\nfnames\n#이미지 파일이라는 것만 가져옴\n\n(#7390) [Path('/root/.fastai/data/oxford-iiit-pet/images/Maine_Coon_52.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/newfoundland_73.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Siamese_75.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/samoyed_170.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/basset_hound_172.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_37.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_186.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/leonberger_152.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/pug_188.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_156.jpg')...]\n\n\n\npath.ls()\n#위에랑 다른것=이미지파일이 아닌게 3개가 있겠지!\n\n(#7393) [Path('/root/.fastai/data/oxford-iiit-pet/images/Maine_Coon_52.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/newfoundland_73.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Siamese_75.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/samoyed_170.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/basset_hound_172.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_37.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_186.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/leonberger_152.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/pug_188.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/saint_bernard_156.jpg')...]\n\n\n\n\n\n # f(x)=x+1이라는 함수가 있는데\n # lambda=x+1이라는 식으로 표현하고 싶어. 그럼 f:lamda x: x+1 하면 이 자체가 함수가 되는거임!\n\n f=lambda fname: 'cat' if fname[0].isupper() else 'dog'\n\n\n\ndls = ImageDataLoaders.from_name_func(\n    path, \n    fnames,\n    f, # f대신 (lambda fname: 'cat' if fname[0].isupper() else 'dog') 를 넣어도 가능\n    item_tfms=Resize(224))\n\n#함수잘 모르면 ? 물음표해서 성질 보기!!\n\n\ndls.show_batch()\n\n\n\n\n\n#object를 하나 만드는데, 학습을 하고 학습된 결과를 토대로 예측데이터를만드는거!\n\n\n\n2단계: lrnr 오브젝트 생성\n\n# 러너 오브젝트 만들기 위해서\n# cnn_learner?\ncnn_learner?\n\n#코드가 있는 곳에 들어가서 찾아보면.. file로 찾아가 봅시다!!\n#return이 비전러너,, \n\n#Signature: cnn_learner(*args, **kwargs)\n#Docstring: Deprecated name for `vision_learner` -- do not use\n#File:      /usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py\n#Type:      function\n\n\ncnn_learner??\n\n\n?cnn_learner\n\n\nlrnr = cnn_learner(dls,resnet34,metrics=error_rate)\n\n/usr/local/lib/python3.7/dist-packages/fastai/vision/learner.py:284: UserWarning: `cnn_learner` has been renamed to `vision_learner` -- please update your code\n  warn(\"`cnn_learner` has been renamed to `vision_learner` -- please update your code\")\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n\n\n\n\n\n\nlrnr.dls.show_batch()\n\n\n\n\n\nid(dls)\n\n139724031921680\n\n\n\nid(lrnr.dls)\n\n# 위와 아래의 주소값이 같다! 등호(=)는 포스트잇?같은걸 붙여서 너는 부르면,, 나와야햄 \n# 숫자가 의미하는 것은 dls는 이름일 뿐이고 실제 오브젝트 메모리가 있는 장소\n# dls 에도 포스트잇 붙여놓고 lrnr.dls에도 포스트잇 붙여논당..\n\n139724031921680\n\n\n\n\n3단계: lrnr.학습()\n\nlrnr.fine_tune(1)\n\n#이거 너무 오래걸려.. 그래서 그때 GPU인가 뭐로 바꾸라고 했는데 바꿔도 너어어어어어무 느림..ㅠㅠ  그래서 뒤에 내용 다 놓쳤어 엉엉\n\n# 오! 다시 됬땅.\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.094556\n0.028600\n0.007442\n32:59\n\n\n\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/1 00:00&lt;?]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n\n\n\n    \n      \n      60.87% [56/92 27:03&lt;17:23 0.0558]\n    \n    \n\n\n\n# 학습을 하는 방법은 fine_tune만 있는 것이 아니다. \n# fit, method... 등등 \n# mbti확인할때 장례식장이라는 특수한 상황에서 튜닝을 해야함-&gt;fine_tune   \n# 이미학습된 내 정보를 일부는 유지하고 미세한 영향을 주는 것만 조정하는 것. 기존 모델은 활용하고 새로운 모델을 조금 반영-&gt; trnasfer model\n# CNN에서 투디아키펙처? 원..?아키펙처,,,가있고 원 어쩌고 아키펙처에서 튜닝...@@@@@ \n\n\nfine_tune()은 모든 가중치를 학습하는 것이 아니라 일부만 학습하는 것임.\nfine_tune()이외이 방법으로 학습할 수도 있음.\n\n\n\n4단계: lrnr.예측()\n(방법1) lrnr.predict() 함수를 이용\n\n#lrnr.predict('2022-09-06-hani03.jpg')\n\n\n# X,y=dis.one_batch()\n# X.shape\n# torch\n## 이쪽 잘 못들었어!! 다시들어야함!1\n# 왼쪼\n\n\n#type(_rtn)\n#튜플,, 대괄호면 튜플\n\n(방법2) lrnr.model(X) 를 이용: X의 shape이 (?,3,224,224)의 형태의 텐서이어야함"
  },
  {
    "objectID": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#프로그래밍-과정",
    "href": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#프로그래밍-과정",
    "title": "기계학습 (0914) 2주차",
    "section": "프로그래밍 과정",
    "text": "프로그래밍 과정\n\n프로그래밍 과정 overview\n- overview\n\ndls 오브젝트 생성\nlrnr 오브젝트 생성\nlrnr.학습()\nlrnr.예측()\n\n\n\n이미지분석, 추천시스템, 텍스트분석, GAN 분석과정 비교\n- 비교\n\n\n\n\n\n\n\n\n\n\n\n이미지분석(CNN)\n추천시스템\n텍스트분석\nGAN\n\n\n\n\n1단계\nImageDataLoaders\nCollabDataLoaders\nTextDataLoaders\nDataBlock -&gt; dls\n\n\n2단계\ncnn_learner()\ncollab_learner()\nlanguage_model_learner()\nGANLearner.wgan()\n\n\n3단계\nlrnr.fine_tune(1)\nlrnr.fit()\nlrnr.fit()\nlrnr.fit()\n\n\n4단계\nlrnr.predict(), lrnr.model(X)\nlrnr.model(X)\nlrnr.predict()"
  },
  {
    "objectID": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#추천시스템-실습",
    "href": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#추천시스템-실습",
    "title": "기계학습 (0914) 2주차",
    "section": "추천시스템 실습",
    "text": "추천시스템 실습\n\n1단계\n\ndf_view=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_view.csv')\n#웹에 있는걸 바로 가져오기\ndf_view\n# !wget ~뒤에 링크 하면 옆에 파일로 떠서 볼수있다는듯\n# 빈칸이 있는 건 메모리를 많이 잡아 먹음,\n\n\n  \n    \n      \n\n\n\n\n\n\n커피1\n커피2\n커피3\n커피4\n커피5\n커피6\n커피7\n커피8\n커피9\n커피10\n홍차1\n홍차2\n홍차3\n홍차4\n홍차5\n홍차6\n홍차7\n홍차8\n홍차9\n홍차10\n\n\n\n\n0\n4.149209\nNaN\nNaN\n4.078139\n4.033415\n4.071871\nNaN\nNaN\nNaN\nNaN\n1.142659\n1.109452\nNaN\n0.603118\n1.084308\nNaN\n0.906524\nNaN\nNaN\n0.903826\n\n\n1\n4.031811\nNaN\nNaN\n3.822704\nNaN\nNaN\nNaN\n4.071410\n3.996206\nNaN\nNaN\n0.839565\n1.011315\nNaN\n1.120552\n0.911340\nNaN\n0.860954\n0.871482\nNaN\n\n\n2\n4.082178\n4.196436\nNaN\n3.956876\nNaN\nNaN\nNaN\n4.450931\n3.972090\nNaN\nNaN\nNaN\nNaN\n0.983838\nNaN\n0.918576\n1.206796\n0.913116\nNaN\n0.956194\n\n\n3\nNaN\n4.000621\n3.895570\nNaN\n3.838781\n3.967183\nNaN\nNaN\nNaN\n4.105741\n1.147554\nNaN\n1.346860\nNaN\n0.614099\n1.297301\nNaN\nNaN\nNaN\n1.147545\n\n\n4\nNaN\nNaN\nNaN\nNaN\n3.888208\nNaN\n3.970330\n3.979490\nNaN\n4.010982\nNaN\n0.920995\n1.081111\n0.999345\nNaN\n1.195183\nNaN\n0.818332\n1.236331\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n95\n0.511905\n1.066144\nNaN\n1.315430\nNaN\n1.285778\nNaN\n0.678400\n1.023020\n0.886803\nNaN\n4.055996\nNaN\nNaN\n4.156489\n4.127622\nNaN\nNaN\nNaN\nNaN\n\n\n96\nNaN\n1.035022\nNaN\n1.085834\nNaN\n0.812558\nNaN\n1.074543\nNaN\n0.852806\n3.894772\nNaN\n4.071385\n3.935935\nNaN\nNaN\n3.989815\nNaN\nNaN\n4.267142\n\n\n97\nNaN\n1.115511\nNaN\n1.101395\n0.878614\nNaN\nNaN\nNaN\n1.329319\nNaN\n4.125190\nNaN\n4.354638\n3.811209\n4.144648\nNaN\nNaN\n4.116915\n3.887823\nNaN\n\n\n98\nNaN\n0.850794\nNaN\nNaN\n0.927884\n0.669895\nNaN\nNaN\n0.665429\n1.387329\nNaN\nNaN\n4.329404\n4.111706\n3.960197\nNaN\nNaN\nNaN\n3.725288\n4.122072\n\n\n99\nNaN\nNaN\n1.413968\n0.838720\nNaN\nNaN\n1.094826\n0.987888\nNaN\n1.177387\n3.957383\n4.136731\nNaN\n4.026915\nNaN\nNaN\n4.164773\n4.104276\nNaN\nNaN\n\n\n\n\n100 rows × 20 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#위에 링크: 교수님 깃허브-&gt; DL2022/_notebooks/2022-09-08-rcmd_anal.csv\n#컴퓨터가 좋아하는 타입이 아님. 컴퓨터가 좋아하는 타입으로...\n\n\n#'-' 컴퓨터가 좋아하는 데이터 타입\n# https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\n\n\n!wget https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\n\n--2022-09-14 11:32:06--  https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 31987 (31K) [text/plain]\nSaving to: ‘2022-09-08-rcmd_anal.csv’\n\n2022-09-08-rcmd_ana 100%[===================&gt;]  31.24K  --.-KB/s    in 0.002s  \n\n2022-09-14 11:32:06 (13.2 MB/s) - ‘2022-09-08-rcmd_anal.csv’ saved [31987/31987]\n\n\n\n\ndf= pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-09-08-rcmd_anal.csv')\n\n\ndls = CollabDataLoaders.from_df(df)\n\n\nCollabDataLoaders.from_df?\n\n\ndls.show_batch()\n\n\n\n\n\nuser\nitem\nrating\n\n\n\n\n0\n47\n12\n0.937742\n\n\n1\n29\n12\n0.964676\n\n\n2\n96\n4\n1.315430\n\n\n3\n9\n13\n0.967607\n\n\n4\n8\n14\n1.092273\n\n\n5\n91\n10\n1.453194\n\n\n6\n41\n11\n0.973238\n\n\n7\n26\n10\n3.794259\n\n\n8\n23\n2\n4.048529\n\n\n9\n45\n17\n0.608018\n\n\n\n\n\n\ndls.one_batch()\n#가로로시자하니까 타입이 튜플\n\n(tensor([[84, 10],\n         [55, 16],\n         [62, 10],\n         [91,  8],\n         [98,  2],\n         [60, 17],\n         [92,  4],\n         [58, 13],\n         [58,  8],\n         [99,  6],\n         [30,  5],\n         [96,  4],\n         [15, 20],\n         [59, 12],\n         [ 3, 20],\n         [ 9, 10],\n         [77,  1],\n         [67, 14],\n         [71, 15],\n         [ 4, 13],\n         [27, 16],\n         [67, 17],\n         [15,  1],\n         [36, 11],\n         [41,  2],\n         [76, 18],\n         [52,  8],\n         [10, 18],\n         [ 9,  7],\n         [22, 15],\n         [42,  1],\n         [33,  7],\n         [74, 13],\n         [67, 18],\n         [36,  6],\n         [83,  1],\n         [33, 16],\n         [24, 18],\n         [97, 20],\n         [51,  7],\n         [84,  2],\n         [76,  1],\n         [74,  5],\n         [44,  6],\n         [98, 15],\n         [75, 13],\n         [62, 18],\n         [53, 15],\n         [26, 10],\n         [25,  9],\n         [55,  9],\n         [52,  6],\n         [57, 17],\n         [37, 11],\n         [73,  4],\n         [86,  4],\n         [ 1,  6],\n         [26,  4],\n         [64, 16],\n         [33, 14],\n         [83, 18],\n         [70,  2],\n         [75,  1],\n         [33, 12]]), tensor([[1.2715],\n         [4.0267],\n         [0.7438],\n         [0.9987],\n         [1.1155],\n         [3.8992],\n         [1.0577],\n         [3.9485],\n         [0.8547],\n         [0.6699],\n         [4.0411],\n         [1.3154],\n         [0.8391],\n         [4.0661],\n         [0.9562],\n         [3.6942],\n         [1.2878],\n         [4.1035],\n         [4.1144],\n         [1.3469],\n         [1.1454],\n         [3.7744],\n         [4.2453],\n         [1.4332],\n         [3.8708],\n         [4.1442],\n         [0.9954],\n         [0.7891],\n         [4.1260],\n         [0.5774],\n         [4.3466],\n         [4.1756],\n         [4.2065],\n         [3.5310],\n         [4.0288],\n         [0.9260],\n         [0.8332],\n         [0.9404],\n         [4.2671],\n         [0.9587],\n         [1.0322],\n         [1.2164],\n         [1.0687],\n         [4.0421],\n         [4.1446],\n         [3.7454],\n         [4.2632],\n         [3.8596],\n         [3.7943],\n         [3.9132],\n         [0.7096],\n         [0.7217],\n         [4.0679],\n         [1.1996],\n         [1.1524],\n         [0.9177],\n         [4.0719],\n         [4.1183],\n         [3.7412],\n         [1.0213],\n         [3.7535],\n         [0.8947],\n         [0.8515],\n         [1.3081]]))\n\n\n\ntype(dls.one_batch())\n\ntuple\n\n\n\nX,y=dls.one_batch()\n\n\nX[:5]\n\ntensor([[29,  8],\n        [41, 15],\n        [27, 17],\n        [58, 19],\n        [87, 11]])\n\n\n\ny[:5]\n\n#y는 평점 x는 사람의 인덱스,아이템인덱스\n#파이썬은 인덱스가 0번으로 되어잇는지 1번으로 되어잇는지 헷갈료\n#dls를 만들때 제일작은게 0인지 1인지 궁금쓰\n\ntensor([[4.1002],\n        [0.7859],\n        [1.0369],\n        [4.0163],\n        [4.0558]])\n\n\n\ndf.user\n\n0        1\n1        1\n2        1\n3        1\n4        1\n      ... \n995    100\n996    100\n997    100\n998    100\n999    100\nName: user, Length: 1000, dtype: int64\n\n\n\ndf.user.unique(), df.item.unique()\n#중복제거하고 유니크한 숫자만 보고싶을때\n#유저는 1~100까지, 아이템은 1~20까지 있다는 걸 확인할 수 있음\n\n(array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n         92,  93,  94,  95,  96,  97,  98,  99, 100]),\n array([15,  1, 11,  5,  4, 14,  6, 20, 12, 17,  8,  9, 13, 19, 18, 16,  2,\n         3, 10,  7]))\n\n\n\n\n2단계\n\n?collab_learner\n\n\nlrnr = collab_learner(dls, y_range=(0.5))\n\n\n\n3단계\n\nlrnr.fit(10) \n#이거왜안되지?ㅠㅠ 위에 파인튠학습안되서 그런가...흠 \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ngen_loss\ncrit_loss\ntime\n\n\n\n\n0\n-0.564446\n0.408502\n0.408502\n-0.763844\n02:29\n\n\n1\n-0.580162\n0.261919\n0.261919\n-0.767689\n02:27\n\n\n2\n-0.573394\n0.211019\n0.211019\n-0.748596\n02:26\n\n\n3\n-0.565945\n0.312586\n0.312586\n-0.731640\n02:26\n\n\n4\n-0.533000\n0.208635\n0.208635\n-0.709664\n02:26\n\n\n5\n-0.563198\n0.189235\n0.189235\n-0.736768\n02:26\n\n\n6\n-0.565810\n0.210935\n0.210935\n-0.741373\n02:26\n\n\n7\n-0.565554\n0.257288\n0.257288\n-0.737568\n02:26\n\n\n8\n-0.562049\n0.309152\n0.309152\n-0.743085\n02:26\n\n\n9\n-0.565225\n0.227808\n0.227808\n-0.726368\n02:27\n\n\n\n\n\n\n\n4단계\n\n!nvidia-smi\n#GPU를 써야 학습이 빨리 된다... \n#CPU로 되어있어서?.. .?????? batch라는 개념을 알아야함..\n\nNVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n\n\n\n\n#lrnr.model(X.to(\"cuda:0\"))\n#y.reshpe(-1) 학습이 얼마 안된면 잘 몰라,, 그래서 위에 3단계에서 fit옆에 좀더 숫자를 키워,,\n#3단계안되서 4단계 다 안되는듯..\n\nRuntimeError: ignored"
  },
  {
    "objectID": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#텍스트분석-실습",
    "href": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#텍스트분석-실습",
    "title": "기계학습 (0914) 2주차",
    "section": "텍스트분석 실습",
    "text": "텍스트분석 실습\n\n1단계\n\n# 텍스트 데이터는 순환신경망을 사용한다!!\n# 만약 hello라는 단어를 생각할때, \n# h -&gt; e\n# e -&gt; l\n# l -&gt; l\n# l -&gt; o\n# 근데 l이 애매하다!! 그래서 두개 시점으로 하는게 좋을 거 같아\n\n# he -&gt; l\n# el -&gt; l\n# ll -&gt; o\n\n\n#순서가 중요한게 있음. 텍스트랑 시계열~~\n\n# 다음텍스트가 뭐가 나오는지 적용시키는것 중 하나가 챗봇!\n# 나는 학교에 갔다.\n# 나는 다음에 학교에 가 나와야함. 반복되는 단위가 단어... 또는 문장 단위로 반복될 수도 있음!!\n\n# 나는 학교에 갔다. =&gt; 공부를 했다. =&gt; 집에 왓당..\n\n# 텍스트는 문맥에 맞게 그럴듯한걸 결과값을 주면 된다. cf)주식은 그 뒤에 값을 정해야함!! ㅠ 내일의 주식장...\n\n'h e l l o . h e l l o ! h e l l o ? h e l l o !!'\n\n\n\n2단계\n\n\n3단계\n\n\n4단계"
  },
  {
    "objectID": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#gan-intro",
    "href": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#gan-intro",
    "title": "기계학습 (0914) 2주차",
    "section": "GAN intro",
    "text": "GAN intro\n- 저자: 이안굿펠로우 (이름이 특이함. 좋은친구..) - 천재임 - 지도교수가 요수아 벤지오\n- 논문 NIPS, 저는 이 논문 읽고 소름돋았어요.. - https://arxiv.org/abs/1406.2661 (현재시점, 38751회 인용되었음 \\(\\to\\) 48978회 인용..)\n- 최근 10년간 머신러닝 분야에서 가장 혁신적인 아이디어이다. (얀르쿤, 2014년 시점..)\n- 무슨내용? 생성모형\n\n생성모형이란? (쉬운 설명)\n\n만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)\n\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼수 있는가?\n- 진정으로 인공지능이 이미지를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공\n\n\nGAN의 응용분야\n- 내가 찍은 사진이 피카소의 화풍으로 표현된다면? - https://www.lgsl.kr/sto/stories/60/ALMA2020070001\n- 퀸의 라이브에이드가 4k로 나온다면?\n- 1920년대 서울의 모습이 칼라로 복원된다면?\n- 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소)\n- 게임영상 (파이널판타지)\n- 거북이의 커버..\n- 너무 많아요…..\n\n\n\n생성모형이란? 통계학과 버전의 설명\n\n제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고, 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 이미지 \\(\\boldsymbol{x}\\)가 주어졌을 경우 라벨을 \\(y\\)라고 하자.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{x})\\)에 관심이 있다.\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{x},y)\\)에 관심이 있는것이다.\n- 데이터의 생성확률 \\(p(\\boldsymbol{x},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{x})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|x) = \\frac{p(x,y)}{p(x)} = \\frac{p(x,y)}{\\sum_{y}p(x,y)} \\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능\n\n- 따라서 배프닉의 원리에 의하면 식별적 분류가 생성적 분류보다 바람직한 접근법이라 할 수 있음.\n- 하지만 다양한 현실문제에서 생성모형이 유용할때가 많다.\n\n\nGAN의 원리\n- GAN은 생성모형중 하나임\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of counterfeiters, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n경찰: 이건 진짠가?… –&gt; 상사에게 혼남. 그것도 구분못하냐고\n위조범: 더 정교하게 만들자..\n경찰: 더 판별능력을 업그레이드 하자!\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다."
  },
  {
    "objectID": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#gan-실습",
    "href": "posts/2022_09_14_(2주차)_9월14일_ipynb의_사본.html#gan-실습",
    "title": "기계학습 (0914) 2주차",
    "section": "GAN 실습",
    "text": "GAN 실습\n\n1단계\n\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\n\n\n\n\n    \n      \n      100.14% [3219456/3214948 00:00&lt;00:00]\n    \n    \n\n\n\ndblock = DataBlock(blocks=(TransformBlock,ImageBlock),\n          get_x = generate_noise,\n          get_items=get_image_files,\n          item_tfms=Resize(32))\ndls = dblock.dataloaders(path) \n\n\ndls.show_batch()\n\n\n\n\n\n\n2단계\n\ncounterfeiter = basic_generator(32,n_channels=3,n_extra_layers=1)\npolice = basic_critic(32,n_channels=3,n_extra_layers=1)\n\n\nlrnr = GANLearner.wgan(dls,counterfeiter,police) \n\n\n\n3단계\n- lrnr.fit(10) 진행\n\nlrnr.fit(10)\n\n/usr/local/lib/python3.7/dist-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (generator) that exists in the learner. Use `self.learn.generator` to avoid this\n  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n/usr/local/lib/python3.7/dist-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (critic) that exists in the learner. Use `self.learn.critic` to avoid this\n  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n/usr/local/lib/python3.7/dist-packages/fastai/callback/core.py:69: UserWarning: You are shadowing an attribute (gen_mode) that exists in the learner. Use `self.learn.gen_mode` to avoid this\n  warn(f\"You are shadowing an attribute ({name}) that exists in the learner. Use `self.learn.{name}` to avoid this\")\n\n\n\n\n\n\n\n    \n      \n      0.00% [0/10 00:00&lt;?]\n    \n    \n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ngen_loss\ncrit_loss\ntime\n\n\n\n\n\n\n\n    \n      \n      51.67% [93/180 01:13&lt;01:08 -0.4932]\n    \n    \n\n\nKeyboardInterrupt: ignored\n\n\n\nlrnr.show_results()\n\n- lrnr.fit(10) 추가로 진행 // 총20회\n\nlrnr.fit(10)\n\n\nlrnr.show_results()\n\n- lrnr.fit(10) 추가로 진행 // 총30회\n\nlrnr.fit(10)\n\n\nlrnr.show_results()\n\n\n\n4단계 (없음)"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html",
    "title": "기계학습 (1012) 6주차",
    "section": "",
    "text": "깊은신경망(2)– 시벤코정리, 신경망의표현, CPU vs GPU, 확률적경사하강법, 오버피팅"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#지난시간-논리전개",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#지난시간-논리전개",
    "title": "기계학습 (1012) 6주차",
    "section": "지난시간 논리전개",
    "text": "지난시간 논리전개\n- 아이디어: linear -&gt; relu -&gt; linear (-&gt; sigmoid) 조합으로 꺽은선으로 표현되는 underlying 을 표현할 수 있었다.\n\n아이디어의 실용성: 실제자료에서 꺽은선으로 표현되는 underlying은 몇개 없을 것 같음. 그건 맞는데 꺽이는 점을 많이 설정하면 얼추 비슷하게는 “근사” 시킬 수 있음.\n아이디어의 확장성: 이러한 논리전개는 X:(n,2)인 경우도 가능했음. (이 경우 꺽인선은 꺽인평면이 된다)\n아이디어에 해당하는 용어정리: 이 구조가 x-&gt;y 로 바로 가는 것이 아니라 x-&gt;(u1-&gt;v1)-&gt;(u2-&gt;v2)=y 의 구조인데 이러한 네트워크를 하나의 은닉층을 포함하는 네트워크라고 표현한다. (이 용어는 이따가..)"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#시벤코정리-1",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#시벤코정리-1",
    "title": "기계학습 (1012) 6주차",
    "section": "시벤코정리",
    "text": "시벤코정리\nuniversal approximation thm: (범용근사정리,보편근사정리,시벤코정리), 1989\n\n하나의 은닉층을 가지는 “linear -&gt; sigmoid -&gt; linear” 꼴의 네트워크를 이용하여 세상에 존재하는 모든 (다차원) 연속함수를 원하는 정확도로 근사시킬 수 있다. (계수를 잘 추정한다면)\n\n- 사실 엄청 이해안되는 정리임. 왜냐햐면,\n\n그렇게 잘 맞추면 1989년에 세상의 모든 문제를 다 풀어야 한거 아니야?\n요즘은 “linear -&gt; sigmoid -&gt; linear” 가 아니라 “linear -&gt; relu -&gt; linear” 조합으로 많이 쓰던데?\n요즘은 하나의 은닉층을 포함하는 네트워크는 잘 안쓰지 않나? 은닉층이 여러개일수록 좋다고 어디서 본 것 같은데?\n\n- 약간의 의구심이 있지만 아무튼 universal approximation thm에 따르면 우리는 아래와 같은 무기를 가진 꼴이 된다.\n\n우리의 무기: \\({\\bf X}: (n,p)\\) 꼴의 입력에서 \\({\\bf y}:(n,1)\\) 꼴의 출력으로 향하는 맵핑을 “linear -&gt; relu -&gt; linear”와 같은 네트워크를 이용해서 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#그림으로-보는-증명과정",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#그림으로-보는-증명과정",
    "title": "기계학습 (1012) 6주차",
    "section": "그림으로 보는 증명과정",
    "text": "그림으로 보는 증명과정\n- 데이터\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\n\n- 아래와 같은 네트워크를 고려하자.\n\nl1 = torch.nn.Linear(in_features=1,out_features=2)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=2,out_features=1)\n\n- 직관1: \\(l_1\\),\\(l_2\\)의 가중치를 잘 결합하다보면 우연히 아래와 같이 만들 수 있다.\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,color='C2'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$') #모자의 시프팅(왼족아래쪽이동), 모자높이 이동 (1-&gt;2...)\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ \\\\l_1)(x)$')\n\n\n\n\n\n- 직관2: 아래들도 가능할듯?\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data,'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data,'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\n\n\n\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+0.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nax[0].plot(x,l1(x).data,'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data,'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nfig\n\n\n\n\n- 은닉층의노드수=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 주황색선 + 파란색선도 가능할 것 같다. \\(\\to\\) 실제로 가능함\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data)\n\n\n\n\n- 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 함수 \\(h\\)를 만들 수 있다.\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n- 위와 같은 함수 \\(h\\)를 활성화함수로 하고 \\(m\\)개의 노드를 가지는 은닉층을 생각해보자. 이러한 은닉층을 사용한다면 전체 네트워크를 아래와 같이 표현할 수 있다.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- \\(h(x)\\)를 활성화함수로 가지는 네트워크를 설계하여 보자.\n\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input): #forward: x에서 y로가는거.. \n        return h(input) # activation 의 출력 \n\n\na1=MyActivation()\n# a1 = torch.nn.Sigmoid(), a1 = torch.nn.ReLU() 대신에 a1 = MyActivation()\n\n\nplt.plot(x,a1(x)) \n\n\n\n\n히든레이어가 1개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,1),\n            MyActivation(),\n            torch.nn.Linear(1,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 2개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,2),\n            MyActivation(),\n            torch.nn.Linear(2,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 3개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,3),\n            MyActivation(),\n            torch.nn.Linear(3,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')\n\n\n\n\n히든레이어가 1024개의 노드를 가지는 경우\n\ntorch.manual_seed(43052)\nfig, ax = plt.subplots(4,4,figsize=(12,12))\nfor i in range(4):\n    for j in range(4):\n        net = torch.nn.Sequential(\n            torch.nn.Linear(1,1024),\n            MyActivation(),\n            torch.nn.Linear(1024,1)\n        )\n        ax[i,j].plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제1-sin-exp",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제1-sin-exp",
    "title": "기계학습 (1012) 6주차",
    "section": "예제1 (sin, exp)",
    "text": "예제1 (sin, exp)\n\ntorch.manual_seed(43052)\nx = torch.linspace(-10,10,200).reshape(-1,1)\nunderlying = torch.sin(2*x) + torch.sin(0.5*x) + torch.exp(-0.2*x)\neps = torch.randn(200).reshape(-1,1)*0.1  #오차항\ny = underlying + eps \nplt.plot(x,y,'o',alpha=0.5)\nplt.plot(x,underlying,lw=3)\n\n\n\n\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) \n\n\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(200):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2)\nplt.plot(x,underlying,lw=3)\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제2-스펙높아도-취업x",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제2-스펙높아도-취업x",
    "title": "기계학습 (1012) 6주차",
    "section": "예제2 (스펙높아도 취업X)",
    "text": "예제2 (스펙높아도 취업X)\n\ndf=pd.read_csv('https://raw.githubusercontent.com/guebin/DL2022/master/_notebooks/2022-10-04-dnnex0.csv')\ndf\n\n\n\n\n\n\n\n\nx\nunderlying\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).reshape(-1,1).float()\ny = torch.tensor(df.y).reshape(-1,1).float()\nplt.plot(x,y,'o',alpha=0.1)\nplt.plot(df.x,df.underlying,lw=3)\n\n\n\n\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__() \n    def forward(self, input):\n        return h(input) \n\n\ntorch.manual_seed(43052)\nnet= torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters()) \n\n\nfor epoc in range(100):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2)\nplt.plot(df.x,df.underlying,lw=3)\nplt.plot(x,net(x).data,'--')"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제3-mnist-data-with-dnn",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제3-mnist-data-with-dnn",
    "title": "기계학습 (1012) 6주차",
    "section": "예제3 (MNIST data with DNN)",
    "text": "예제3 (MNIST data with DNN)\n\n# 예비학습\n(예비학습1) Path\n\npath = untar_data(URLs.MNIST) \npath\n\nPath('/home/cgb4/.fastai/data/mnist_png')\n\n\n\npath 도 오브젝트임\npath 도 정보+기능이 있음\n\n- path의 정보\n\npath._str # 숨겨놓았네? #path도 object 동작을 정의하는 기능이 있을거야..\n#path 오브젝트에 저장된 정보(attribute, 기능은 method)\n\n'/home/cgb4/.fastai/data/mnist_png'\n\n\n- 기능1\n\npath.ls()  # path 오브젝트의 안에 있는 목록(폴더)를 보여줘!\n\n(#2) [Path('/home/cgb4/.fastai/data/mnist_png/training'),Path('/home/cgb4/.fastai/data/mnist_png/testing')]\n\n\n- 기능2\n\npath/'training'  #경로를 결합\n\nPath('/home/cgb4/.fastai/data/mnist_png/training')\n\n\n\npath/'testing'\n\nPath('/home/cgb4/.fastai/data/mnist_png/testing')\n\n\n- 기능1과 기능2의 결합\n\n(path/'training/3').ls()\n\n(#6131) [Path('/home/cgb4/.fastai/data/mnist_png/training/3/37912.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/12933.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/3576.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/59955.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/23144.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/40836.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/25536.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/42669.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/7046.png'),Path('/home/cgb4/.fastai/data/mnist_png/training/3/47380.png')...]\n\n\n\n‘/home/cgb4/.fastai/data/mnist_png/training/3/37912.png’ 이 파일을 더블클릭하면 이미지가 보인단 말임\n\n(예비학습2) plt.imshow\n\n# plt.imshow 값에 따라 밝게 어둡게 보여줌\n\n\nimgtsr = torch.tensor([[1.0,2],[2.0,4.0]])\nimgtsr\n\ntensor([[1., 2.],\n        [2., 4.]])\n\n\n\nplt.imshow(imgtsr,cmap='gray')\nplt.colorbar()\n\n&lt;matplotlib.colorbar.Colorbar at 0x7fceac108e50&gt;\n\n\n\n\n\n(예비학습3) torchvision\n- ’/home/cgb4/.fastai/data/mnist_png/training/3/37912.png’의 이미지파일을 torchvision.io.read_image 를 이용하여 텐서로 만듬\n\n#!s /home/cgb4/.fastai/data/mnist_png/training/3\n#ls아닌가? 뭐지\n\n\nimgtsr = torchvision.io.read_image('/home/cgb4/.fastai/data/mnist_png/training/3/37912.png')\nimgtsr\n\ntensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66, 138,\n          149, 180, 138, 138,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,  22, 162, 161, 228, 252, 252,\n          253, 252, 252, 252, 252,  74,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 253, 252, 252, 252, 189,\n          184, 110, 119, 252, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,  74, 161, 160,  77,  45,   4,\n            0,   0,  70, 252, 210,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,  22, 205, 252,  32,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0, 162, 253, 245,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n           36, 219, 252, 139,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          222, 252, 202,  13,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,\n          253, 252,  89,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 240,\n          253, 157,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   7, 160, 253,\n          231,  42,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 142, 252, 252,\n           42,  30,  78, 161,  36,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,\n          185, 228, 252, 252, 168,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 184, 252, 252,\n          253, 252, 252, 252, 116,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 101, 179, 252,\n          253, 252, 252, 210,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  22,\n          255, 253, 215,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  34,  89, 244,\n          253, 223,  98,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 116, 123, 142, 234, 252, 252,\n          184,  67,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 230, 253, 252, 252, 252, 168,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0, 126, 253, 252, 168,  43,   2,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]],\n       dtype=torch.uint8)\n\n\n- 이 텐서는 (1,28,28)의 shape을 가짐\n\nimgtsr.shape\n\ntorch.Size([1, 28, 28])\n\n\n\n# 1: 채널의 숫자, 28*28은 픽셀의 숫자\n\n- imgtsr를 plt.imshow 로 시각화\n\nplt.imshow(imgtsr.reshape(28,28),cmap='gray')\n\n&lt;matplotlib.image.AxesImage at 0x7fceabd49a90&gt;\n\n\n\n\n\n\n진짜 숫자3이 있음\n\n\n\n# 데이터정리\n- 데이터정리\n\nthrees = (path/'training/3').ls() #6131개, 1,28,28\nsevens = (path/'training/7').ls() #6265개, 1,28,28\nlen(threes),len(sevens)\n\n(6131, 6265)\n\n\n\nX3 = torch.stack([torchvision.io.read_image(str(threes[i])) for i in range(6131)]) #리스트 형태로 만들고.. \nX7 = torch.stack([torchvision.io.read_image(str(sevens[i])) for i in range(6265)])\n\n\n# X3 = torch.stack([torchvision.io.read_image(str(fn)])) for i in three_fnames]) \n# X7 = torch.stack([torchvision.io.read_image(str(fn)])) for i in seven_fnames])\n# 위와 같은 코드\n\n\nX3.shape,X7.shape\n\n(torch.Size([6131, 1, 28, 28]), torch.Size([6265, 1, 28, 28]))\n\n\n\nX=torch.concat([X3,X7]) #n * p 의 shape \n#float로 바꿔줘야함\nX.shape\n\ntorch.Size([12396, 1, 28, 28])\n\n\n\nXnp = X.reshape(-1,1*28*28).float()\nXnp.shape\n\ntorch.Size([12396, 784])\n\n\n\ny = torch.tensor([0.0]*6131 + [1.0]*6265).reshape(-1,1)  # 3을 0으로 7을 1로.. 나중에 sigmoin하기 편하게 하려고  6131대신에 len(X3)이렇게 써도 됨\ny.shape\n\ntorch.Size([12396, 1])\n\n\n\nplt.plot(y,'o')\n\n\n\n\n\n“y=0”은 숫자3을 의미, “y=1”은 숫자7을 의미\n숫자3은 6131개, 숫자7은 6265개 있음\n\n\n\n# 학습\n- 네트워크의 설계\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(  #묶어주기..\n    torch.nn.Linear(in_features=1*28*28,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)\n\n\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\nloss_fn = torch.nn.BCELoss()\n\n\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(200):\n    ## 1\n    yhat = net(Xnp) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'o')\nplt.plot(net(Xnp).data,'.',alpha=0.2)\n\n\n\n\n\n대부분 잘 적합되었음"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "title": "기계학습 (1012) 6주차",
    "section": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\nCode\ngv(''' \n    \"1\" -&gt; \"ŵ₀ + xₙ*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"xₙ\" -&gt; \"ŵ₀ + xₙ*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + xₙ*ŵ₁,    bias=False\" -&gt; \"ŷₙ\"[label=\"sigmoid\"]\n\n    \".\" -&gt; \"....................................\"[label=\"* ŵ₀\"]\n    \"..\" -&gt; \"....................................\"[label=\"* ŵ₁\"]\n    \"....................................\" -&gt; \"...\"[label=\" \"]\n\n    \"1 \" -&gt; \"ŵ₀ + x₂*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x₂\" -&gt; \"ŵ₀ + x₂*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x₂*ŵ₁,    bias=False\" -&gt; \"ŷ₂\"[label=\"sigmoid\"]\n    \n    \"1  \" -&gt; \"ŵ₀ + x₁*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x₁\" -&gt; \"ŵ₀ + x₁*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x₁*ŵ₁,    bias=False\" -&gt; \"ŷ₁\"[label=\"sigmoid\"]\n''')\n\n\n\n\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n\nCode\ngv(''' \n    \"1\" -&gt; \"ŵ₀ + xᵢ*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"xᵢ\" -&gt; \"ŵ₀ + xᵢ*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + xᵢ*ŵ₁,    bias=False\" -&gt; \"ŷᵢ\"[label=\"sigmoid\"]\n\n''')\n\n\n\n\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n\nCode\ngv(''' \n    \"1\" -&gt; \"ŵ₀ + x*ŵ₁,    bias=False\"[label=\"* ŵ₀\"]\n    \"x\" -&gt; \"ŵ₀ + x*ŵ₁,    bias=False\"[label=\"* ŵ₁\"]\n    \"ŵ₀ + x*ŵ₁,    bias=False\" -&gt; \"ŷ\"[label=\"sigmoid\"]\n\n''')\n\n\n\n\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n\nCode\ngv('''\n\"x\" -&gt; \"x*ŵ₁,    bias=True\"[label=\"*ŵ₁\"] ;\n\"x*ŵ₁,    bias=True\" -&gt; \"ŷ\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n\nCode\ngv('''\n\"x\" -&gt; \"x*ŵ,    bias=True\"[label=\"*ŵ\"] ;\n\"x*ŵ,    bias=True\" -&gt; \"ŷ\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\nCode\ngv('''\n\"x\" -&gt; \"u\";\n\"u\" -&gt; \"y\"[label=\"sigmoid\"] ''')\n\n\n\n\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "title": "기계학습 (1012) 6주차",
    "section": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 10월4일 강의노트에서 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n\nCode\ngv('''\n\"x\" -&gt; \" -x\"[label=\"*(-1)\"];\n\"x\" -&gt; \" x\"[label=\"*1\"]\n\" x\" -&gt; \"rlu(x)\"[label=\"relu\"] \n\" -x\" -&gt; \"rlu(-x)\"[label=\"relu\"] \n\"rlu(x)\" -&gt; \"u\"[label=\"*(-4.5)\"] \n\"rlu(-x)\" -&gt; \"u\"[label=\"*(-9.0)\"] \n\"u\" -&gt; \"sig(u)=yhat\"[label=\"sig\"] \n'''\n)\n\n\n\n\n\n(좀 더 일반화된 표현) 10월4일 강의노트 상황을 일반화하면 아래와 같다.\n\n\nCode\ngv('''\n\"x\" -&gt; \"u1[:,0]\"[label=\"*(-1)\"];\n\"x\" -&gt; \"u1[:,1]\"[label=\"*1\"]\n\"u1[:,0]\" -&gt; \"v1[:,0]\"[label=\"relu\"] \n\"u1[:,1]\" -&gt; \"v1[:,1]\"[label=\"relu\"] \n\"v1[:,0]\" -&gt; \"u2\"[label=\"*(-9.0)\"] \n\"v1[:,1]\" -&gt; \"u2\"[label=\"*(-4.5)\"] \n\"u2\" -&gt; \"v2=yhat\"[label=\"sig\"] \n'''\n)\n\n\n\n\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\n\nCode\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -&gt; \"u1[:,0]\"\n    \"X\" -&gt; \"u1[:,1]\"\n    \"u1[:,0]\" -&gt; \"v1[:,0]\"[label=\"relu\"]\n    \"u1[:,1]\" -&gt; \"v1[:,1]\"[label=\"relu\"]\n    label = \"Layer 1\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"v1[:,0]\" -&gt; \"u2\"\n    \"v1[:,1]\" -&gt; \"u2\"\n    \"u2\" -&gt; \"v2=yhat\"[label=\"sigmoid\"]\n    label = \"Layer 2\"\n}\n''')\n\n\n\n\n\nLayer를 세는 방법\n\n정석: 학습가능한 파라메터가 몇층으로 있는지…\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음.\n위의 예제의 경우 number of layer = 2 이다.\n\n\n사실 input layer, activation layer 등의 표현을 자주 사용해서 layer를 세는 방법이 처음에는 헷갈립니다..\n\nHidden Layer의 수를 세는 방법\n\nLayer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n\nCode\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -&gt; \"node1\"\n    \"X\" -&gt; \"node2\"\n    label = \"Layer 1:relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"node1\" -&gt; \"yhat \"\n    \"node2\" -&gt; \"yhat \"\n    label = \"Layer 2:sigmoid\"\n}\n''')\n\n\n\n\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\nCode\ngv('''\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"X\" \n    label = \"Layer 0\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"X\" -&gt; \"feature1\"\n    \"X\" -&gt; \"feature2\"\n    label = \"Layer 1:relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n    \"feature1\" -&gt; \"yhat \"\n    \"feature2\" -&gt; \"yhat \"\n    label = \"Layer 2:sigmoid\"\n}\n''')\n\n\n\n\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "title": "기계학습 (1012) 6주차",
    "section": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n(다이어그램표현)\n\n\nCode\ngv('''\nsplines=line\nsubgraph cluster_1{\n    style=filled;\n    color=lightgrey;\n    \"x1\"\n    \"x2\"\n    \"..\"\n    \"x784\"\n    label = \"Input Layer\"\n}\nsubgraph cluster_2{\n    style=filled;\n    color=lightgrey;\n    \"x1\" -&gt; \"node1\"\n    \"x2\" -&gt; \"node1\"\n    \"..\" -&gt; \"node1\"\n    \n    \"x784\" -&gt; \"node1\"\n    \"x1\" -&gt; \"node2\"\n    \"x2\" -&gt; \"node2\"\n    \"..\" -&gt; \"node2\"\n    \"x784\" -&gt; \"node2\"\n    \n    \"x1\" -&gt; \"...\"\n    \"x2\" -&gt; \"...\"\n    \"..\" -&gt; \"...\"\n    \"x784\" -&gt; \"...\"\n\n    \"x1\" -&gt; \"node32\"\n    \"x2\" -&gt; \"node32\"\n    \"..\" -&gt; \"node32\"\n    \"x784\" -&gt; \"node32\"\n\n\n    label = \"Hidden Layer: relu\"\n}\nsubgraph cluster_3{\n    style=filled;\n    color=lightgrey;\n\n    \"node1\" -&gt; \"yhat\"\n    \"node2\" -&gt; \"yhat\"\n    \"...\" -&gt; \"yhat\"\n    \"node32\" -&gt; \"yhat\"\n    \n    label = \"Outplut Layer: sigmoid\"\n}\n''')\n\n\n\n\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#gpu-사용방법",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#gpu-사용방법",
    "title": "기계학습 (1012) 6주차",
    "section": "GPU 사용방법",
    "text": "GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) #net에 넣어야니까 shape을 바꿔주기\ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\")  #net_cpu.to(\"cuda:0\") 하게 되면 net_cpu도 gpu로 넘어가게 되므로 그대로 써주면 안뎀 \n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#시간측정-예비학습",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#시간측정-예비학습",
    "title": "기계학습 (1012) 6주차",
    "section": "시간측정 (예비학습)",
    "text": "시간측정 (예비학습)\n\nimport time \n\n\nt1 = time.time()  #현재시각\n\n\nt2 = time.time()\n\n\nt2-t1  # 현재시간 - 현재시간 : 위아래 실행하는 만큼의 초 나옴 \n\n4.9920783042907715"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-512",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-512",
    "title": "기계학습 (1012) 6주차",
    "section": "CPU (512)",
    "text": "CPU (512)\n- 데이터준비\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\n- for문 준비\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- for문 + 학습시간측정\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.28586554527282715"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#gpu-512",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#gpu-512",
    "title": "기계학습 (1012) 6주차",
    "section": "GPU (512)",
    "text": "GPU (512)\n- 데이터준비\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\n- for문돌릴준비\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n- for문 + 학습시간측정\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5355696678161621\n\n\n\n!! CPU가 더 빠르다?"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-vs-gpu-20480",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-vs-gpu-20480",
    "title": "기계학습 (1012) 6주차",
    "section": "CPU vs GPU (20480)",
    "text": "CPU vs GPU (20480)\n- CPU (20480)\n\n#은닉충의 노드수: 20480\n\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n2.380666494369507\n\n\n- GPU (20480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5442469120025635\n\n\n- 왜 이런 차이가 나는가? 연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-vs-gpu-204800",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#cpu-vs-gpu-204800",
    "title": "기계학습 (1012) 6주차",
    "section": "CPU vs GPU (204800)",
    "text": "CPU vs GPU (204800)\n- CPU (204800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n51.95550894737244\n\n\n- GPU (204800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nt1= time.time()\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.3824031352996826"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#좀-이상하지-않아요",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#좀-이상하지-않아요",
    "title": "기계학습 (1012) 6주차",
    "section": "좀 이상하지 않아요?",
    "text": "좀 이상하지 않아요?\n- 우리가 쓰는 GPU: 다나와 PC견적 - GPU 메모리 끽해봐야 24GB\n- 우리가 분석하는 데이터: 빅데이터..?\n- 데이터의 크기가 커지는순간 X.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸?\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,2*x)\n\n\n\n\n- 데이터를 100개중에 1개만 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x)\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "기계학습 (1012) 6주차",
    "section": "X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "기계학습 (1012) 6주차",
    "section": "경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n- ver1: 모든 샘플을 이용하여 slope 계산\n(epoch1) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\)\n(epoch2) \\(loss=\\sum_{i=1}^{10}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\)\n…\n- ver2: 하나의 샘플만을 이용하여 slope 계산\n(epoch1) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\to slope \\to update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\to slope \\to update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n(epoch2) - \\(loss=(y_1-\\beta_0-\\beta_1x_1)^2 \\to slope \\to update\\) - \\(loss=(y_2-\\beta_0-\\beta_1x_2)^2 \\to slope \\to update\\) - … - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n…\n- ver3: \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch1) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n(epoch2) - \\(loss=\\sum_{i=1}^{3}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=4}^{6}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=\\sum_{i=7}^{9}(y_i-\\beta_0-\\beta_1x_i)^2 \\to slope \\to update\\) - \\(loss=(y_{10}-\\beta_0-\\beta_1x_{10})^2 \\to slope \\to update\\)\n…"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#용어의-정리",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#용어의-정리",
    "title": "기계학습 (1012) 6주차",
    "section": "용어의 정리",
    "text": "용어의 정리\n옛날\n- ver1: gradient descent, batch gradient descent\n- ver2: stochastic gradient descent\n- ver3: mini-batch gradient descent, mini-batch stochastic gradient descent\n\n# gpu메모리가 떨어져서 ver1은 못쓴당.. ver2는 불안한 느낌 for문이 너무 많이 돌ㄹ아가-&gt;느림..\n\n요즘\n- ver1: gradient descent\n- ver2: stochastic gradient descent with batch size = 1\n- ver3: stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고."
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#ds-dl",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#ds-dl",
    "title": "기계학습 (1012) 6주차",
    "section": "ds, dl",
    "text": "ds, dl\n\n# 데이터셋\n\n- ds\n\nx=torch.tensor(range(10)).float()#.reshape(-1,1) reshape원래는 해야는데 보여주기 위해서 생략쓰,,\ny=torch.tensor([1.0]*5+[0.0]*5)#.reshape(-1,1)\n\n\nds=torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x7f62db294710&gt;\n\n\n\nds.tensors # 그냥 (x,y)의 튜플\n\n(tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.]))\n\n\n\n# 데이터로더\n\n- dl\n\ndl=torch.utils.data.DataLoader(ds,batch_size=3) #batch_size: 3개씩 묶어서 배치를 해줌\n#set(dir(dl)) & {'__iter__'}\n\n#dir(dl):숨겨진 습성 \n#dl.__ : 숨겨진 습성\n# iter 오브젝트: for문에 돌릴수 있다는 특성..!\n\n\nfor xx,yy in dl:  #in 뒤에 iter오브젝트는 다 쓸수 있음\n    print(xx,yy)\n\ntensor([0., 1., 2.]) tensor([1., 1., 1.])\ntensor([3., 4., 5.]) tensor([1., 1., 0.])\ntensor([6., 7., 8.]) tensor([0., 0., 0.])\ntensor([9.]) tensor([0.])"
  },
  {
    "objectID": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#ds-dl을-이용한-mnist-구현",
    "href": "posts/1. DNN/2022_10_12_6wk_checkpoint.html#ds-dl을-이용한-mnist-구현",
    "title": "기계학습 (1012) 6주차",
    "section": "ds, dl을 이용한 MNIST 구현",
    "text": "ds, dl을 이용한 MNIST 구현\n- 데이터정리\n\npath = untar_data(URLs.MNIST)\n\n\nzero_fnames = (path/'training/0').ls()\none_fnames = (path/'training/1').ls()\n\n\nX0 = torch.stack([torchvision.io.read_image(str(zf)) for zf in zero_fnames])\nX1 = torch.stack([torchvision.io.read_image(str(of)) for of in one_fnames])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255  #255로나누는 이유 숙제\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n\n\nX.shape,y.shape\n\n(torch.Size([12665, 784]), torch.Size([12665, 1]))\n\n\n- ds \\(\\to\\) dl\n\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048) \n\n\n12665/2048\n\n6.18408203125\n\n\n\ni = 0 \nfor xx,yy in dl: # 총 7번 돌아가는 for문 \n    print(i)\n    i=i+1\n\n0\n1\n2\n3\n4\n5\n6\n\n\n- 미니배치 안쓰는 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(70): \n    ## 1 \n    yhat = net(X) \n    ## 2 \n    loss= loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n\ntorch.sum((yhat&gt;0.5) == y) / len(y) \n# 분자: 전체 데이터 중 잘 맞춘게 몇개인지.\n# 분모: y의 갯수???\n# torch.mean((yhat&gt;0.5) == y)*1.0) 계산하면 위와 같음\n\ntensor(0.9981)\n\n\n- 미니배치 쓰는 학습 (GPU 올리고 내리는 과정은 생략)\n\n# len(y)/2048 = 6.18408203125 \n# 1~2048, 2049~ 하면 6번 조금넘게나옴 (7번)\n\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\n\nfor epoc in range(10):\n    for xx,yy in dl: ## 7번\n        ## 1\n        #yhat = net(xx)\n        ## 2 \n        loss = loss_fn(net(xx),yy) \n        ## 3 \n        loss.backward() \n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\ntorch.mean(((net(X)&gt;0.5) == y)*1.0)\n\ntensor(0.9950)"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html",
    "title": "기계학습 (0921) 3주차",
    "section": "",
    "text": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#imports",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#imports",
    "title": "기계학습 (0921) 3주차",
    "section": "",
    "text": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#로드맵",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#로드맵",
    "title": "기계학습 (0921) 3주차",
    "section": "로드맵",
    "text": "로드맵\n- 회귀분석 \\(\\to\\) 로지스틱 \\(\\to\\) 심층신경망(DNN) \\(\\to\\) 합성곱신경망(CNN)\n- 강의계획서"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#ref",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#ref",
    "title": "기계학습 (0921) 3주차",
    "section": "ref",
    "text": "ref\n- 넘파이 문법이 약하다면? (reshape, concatenate, stack)\n\nreshape: 아래 링크의 넘파이공부 2단계 reshape 참고\n\nhttps://guebin.github.io/IP2022/2022/04/06/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%946%EC%9D%BC.html\n\nconcatenate, stack: 아래 링크의 넘파이공부 4단계 참고\n\nhttps://guebin.github.io/IP2022/2022/04/11/(6%EC%A3%BC%EC%B0%A8)-4%EC%9B%9411%EC%9D%BC.html"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형-소개",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형-소개",
    "title": "기계학습 (0921) 3주차",
    "section": "회귀모형 소개",
    "text": "회귀모형 소개\n- model: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n- model: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형에서-데이터-생성",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형에서-데이터-생성",
    "title": "기계학습 (0921) 3주차",
    "section": "회귀모형에서 데이터 생성",
    "text": "회귀모형에서 데이터 생성\n\n_rnt=torch.randn(100).sort() #100개의 난수 생성 .sort()는 정렬된 값 표현\n\n\ntype(_rnt) #type해보니까 모르는 거네? lengh를 보면 2니까 리스트를 해볼수 있음!\n\ntorch.return_types.sort\n\n\n\na,_ = _rnt[0], _rnt[1] #첫번쨰 원소가 a에 들어가고 두번째 원소가 언더바에 들어가게 된다.\n\n\nx,_ = torch.randn(100).sort()\nx     # X벡터 안에 들어가는 x1, x2, x3 ... \n\ntensor([-2.6694e+00, -2.6132e+00, -2.2525e+00, -2.0763e+00, -1.9791e+00,\n        -1.8444e+00, -1.7486e+00, -1.7284e+00, -1.6991e+00, -1.6634e+00,\n        -1.6364e+00, -1.5948e+00, -1.5710e+00, -1.5043e+00, -1.5002e+00,\n        -1.4035e+00, -1.3328e+00, -1.3239e+00, -1.2964e+00, -1.2064e+00,\n        -1.1857e+00, -1.1184e+00, -1.0559e+00, -1.0148e+00, -1.0105e+00,\n        -9.7771e-01, -9.2156e-01, -8.9929e-01, -8.8333e-01, -7.6213e-01,\n        -6.8896e-01, -6.2386e-01, -6.0660e-01, -5.9161e-01, -5.7884e-01,\n        -4.4417e-01, -4.3631e-01, -3.8129e-01, -3.5062e-01, -3.4311e-01,\n        -3.1632e-01, -2.7753e-01, -2.7065e-01, -2.7020e-01, -2.6189e-01,\n        -2.2925e-01, -1.4359e-01, -1.2405e-01, -6.8853e-02, -5.1603e-02,\n        -4.9887e-02, -2.3798e-02, -1.6275e-03,  7.4200e-02,  1.6760e-01,\n         1.7279e-01,  2.3754e-01,  2.5730e-01,  2.6886e-01,  2.8250e-01,\n         2.9296e-01,  3.0017e-01,  3.1466e-01,  3.2627e-01,  3.5380e-01,\n         3.5664e-01,  3.6345e-01,  3.6429e-01,  4.3469e-01,  4.3551e-01,\n         4.6556e-01,  4.9491e-01,  4.9940e-01,  5.4481e-01,  6.4859e-01,\n         6.7236e-01,  6.8683e-01,  7.2763e-01,  7.3832e-01,  7.8508e-01,\n         8.0376e-01,  8.1716e-01,  8.2234e-01,  8.8814e-01,  9.1453e-01,\n         9.8436e-01,  1.0107e+00,  1.0332e+00,  1.0441e+00,  1.0577e+00,\n         1.1333e+00,  1.1406e+00,  1.2557e+00,  1.3057e+00,  1.3221e+00,\n         1.3361e+00,  1.6109e+00,  1.7063e+00,  1.8415e+00,  2.0672e+00])\n\n\n\nones= torch.ones(100)   #torch.ones(100) 1이 100개 들어간거. X벡터만들기 위해서 \n\n\ntorch.stack([ones, x]) #stack 쌓는다!!!   근데 우리가 원하는 건 이거의 T (트랜스)를 가지고 싶으니까 벡터T 해주기!\n\ntensor([[ 1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n          1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00],\n        [-2.6694e+00, -2.6132e+00, -2.2525e+00, -2.0763e+00, -1.9791e+00,\n         -1.8444e+00, -1.7486e+00, -1.7284e+00, -1.6991e+00, -1.6634e+00,\n         -1.6364e+00, -1.5948e+00, -1.5710e+00, -1.5043e+00, -1.5002e+00,\n         -1.4035e+00, -1.3328e+00, -1.3239e+00, -1.2964e+00, -1.2064e+00,\n         -1.1857e+00, -1.1184e+00, -1.0559e+00, -1.0148e+00, -1.0105e+00,\n         -9.7771e-01, -9.2156e-01, -8.9929e-01, -8.8333e-01, -7.6213e-01,\n         -6.8896e-01, -6.2386e-01, -6.0660e-01, -5.9161e-01, -5.7884e-01,\n         -4.4417e-01, -4.3631e-01, -3.8129e-01, -3.5062e-01, -3.4311e-01,\n         -3.1632e-01, -2.7753e-01, -2.7065e-01, -2.7020e-01, -2.6189e-01,\n         -2.2925e-01, -1.4359e-01, -1.2405e-01, -6.8853e-02, -5.1603e-02,\n         -4.9887e-02, -2.3798e-02, -1.6275e-03,  7.4200e-02,  1.6760e-01,\n          1.7279e-01,  2.3754e-01,  2.5730e-01,  2.6886e-01,  2.8250e-01,\n          2.9296e-01,  3.0017e-01,  3.1466e-01,  3.2627e-01,  3.5380e-01,\n          3.5664e-01,  3.6345e-01,  3.6429e-01,  4.3469e-01,  4.3551e-01,\n          4.6556e-01,  4.9491e-01,  4.9940e-01,  5.4481e-01,  6.4859e-01,\n          6.7236e-01,  6.8683e-01,  7.2763e-01,  7.3832e-01,  7.8508e-01,\n          8.0376e-01,  8.1716e-01,  8.2234e-01,  8.8814e-01,  9.1453e-01,\n          9.8436e-01,  1.0107e+00,  1.0332e+00,  1.0441e+00,  1.0577e+00,\n          1.1333e+00,  1.1406e+00,  1.2557e+00,  1.3057e+00,  1.3221e+00,\n          1.3361e+00,  1.6109e+00,  1.7063e+00,  1.8415e+00,  2.0672e+00]])\n\n\n\ntype(torch.stack([ones, x]))\n\ntorch.Tensor\n\n\n\n# 역슬래시 하고 입실론 쓰고 탭 누르면 입실론 수학기호생김 신기하군\n\n\nW = torch.tensor([2.5,4])\nW\nW.shape #원래 shape이 매트릭스여야 하는데 벡터네? 그럼 X@W하면 매트릭스가 아닌 벡터가 된다. ~~~~~~~~~~ 2차원 1차원,,, 훔 \n\ntorch.Size([2])\n\n\n\ntorch.manual_seed(43052) #이건 원래 난수가 봅히는건뎅 교수님이 설명하기 편하게 ,, 숫자 정해논고\nones= torch.ones(100) #torch.ones(100) 1이 100개 들어간거. X벡터만들기 위해서 \nx,_ = torch.randn(100).sort()\nX = torch.stack([ones,x]).T # torch.stack([ones,x],axis=1)    T:트랜스포 해주는거. 근데 그렇게 안하고 axis=1해도 된당!\nW = torch.tensor([2.5,4])\nϵ = torch.randn(100)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--') #트루펑션 점선으로 찍어보기\n\n#언더라인펑션~= Y=4x+2.5 \n# w0, w1를 추정하면 언더라인 펑션을 잘 추정했다고 확인 할 수 잇어염 \n\n\n\n\n\n# 파란점은 기본 데이터. 입실론을 뺀거(오차항 뺸거)=TRUU FUNCTION을 찾고 싶어!"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형에서-학습이란",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#회귀모형에서-학습이란",
    "title": "기계학습 (0921) 3주차",
    "section": "회귀모형에서 학습이란?",
    "text": "회귀모형에서 학습이란?\n\n# x에서 y로가는 맵핑 \n# 리니어 맵핑,, 2.5랑 4에 가깝게 맞추는거!!\n\n- 파란점만 주어졌을때, 주황색 점선을 추정하는것. 좀 더 정확하게 말하면 given data로 \\(\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)를 최대한 \\(\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}\\)와 비슷하게 찾는것.\n\ngiven data : \\(\\big\\{(x_i,y_i) \\big\\}_{i=1}^{n}\\)\nparameter: \\({\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}\\)\nestimated parameter: \\({\\bf \\hat{W}}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\)\n\n- 더 쉽게 말하면 아래의 그림을 보고 적당한 추세선을 찾는것이다.\n\n# \"적당한\" 추세선이 뭐냐? 하면 웱,,\n# 숫자로 만드는게 제일 편하다!!\n# 적당한게 정도가 있어서 일단 안적당한 거 먼저 해볼게용\n\n\nplt.plot(x,y,'o')\nplt.plot(x, -5+10*x, '--')\n\n# 원데이터가 y1, y2 되고.. 언더바에 잇는게 y1 hat, y2 hat ..... \n\n\n\n\n- 시도: \\((\\hat{w}_0,\\hat{w}_1)=(-5,10)\\)을 선택하여 선을 그려보고 적당한지 판단.\n\n\\(\\hat{y}_i=-5 +10 x_i\\) 와 같이 \\(y_i\\)의 값을 적합시키겠다는 의미\n\n- 벡터표현으로 주황색점선을 계산\n\nWhat= torch.tensor([-5.0, 10.0])\nWhat\n\ntensor([-5., 10.])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What,'--')\n\n# 모델링: 데이터를 보고 아키텍처 설정,,"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#파라메터를-학습하는-방법-적당한-선으로-업데이트-하는-방법",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#파라메터를-학습하는-방법-적당한-선으로-업데이트-하는-방법",
    "title": "기계학습 (0921) 3주차",
    "section": "파라메터를 학습하는 방법 (적당한 선으로 업데이트 하는 방법)",
    "text": "파라메터를 학습하는 방법 (적당한 선으로 업데이트 하는 방법)\n- 이론적으로 추론 &lt;- 회귀분석시간에 배운것\n- 컴퓨터의 반복계산을 이용하여 추론 (손실함수도입 + 경사하강법) &lt;- 우리가 오늘 파이토치로 실습해볼 내용.\n- 전략: 아래와 같은 3단계 전략을 취한다.\n\nstage1: 아무 점선이나 그어본다..\nstage2: stage1에서 그은 점선보다 더 좋은 점선으로 바꾼다.\nstage3: stage1 - 2 를 반복한다.\n\n\nStage1: 첫번째 점선 – 임의의 선을 일단 그어보자\n- \\(\\hat{w}_0=-5, \\hat{w}_1 = 10\\) 으로 설정하고 (왜? 그냥) 임의의 선을 그어보자.\n\nWhat= torch.tensor([-5.0, 10.0], requires_grad=True)\nWhat # 나중에 미분하기 위해서 requires_grad 필요한 옵션\n\n# 뒤에 꼬리표가 붙어있음! 따라다녀,, \n\n#텐서플로우 패키지에서 tf.variable이랑 tf. 어ㅓㅉ고 랑 선언하는데 tf.variable로 설정한거\n\ntensor([-5., 10.], requires_grad=True)\n\n\n\nWhat + 1\n# 뒤에 grad_fn 어쩌고가 따라오지만 신경쓰지 않아도 된당 ,, 벡터처럼 계산도 가능해!!\n# 꼬리표를 빼고싶을땐...... \nWhat.detach()\nWhat.data\n\ntensor([-5., 10.])\n\n\n\n처음에는 ${}=\n\\[\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\]\n=\n\\[\\begin{bmatrix} -5 \\\\ 10 \\end{bmatrix}\\]\n$ 를 대입해서 주황색 점선을 적당히 그려보자는 의미\n끝에 requires_grad=True는 나중에 미분을 위한 것\n\n그려보자!\n\n\nStage2: 첫번째 수정 – 최초의 점선에 대한 ‘적당한 정도’를 판단하고 더 ’적당한’ 점선으로 업데이트 한다.\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n- loss 함수의 특징 - \\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다. - \\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다. - (중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\n# y와 yhat의 값이 비슷하면 loss값이 0에 가까워진다.\n\n\nloss=torch.sum((y-X@What)**2) #이 값이 주황색 점선에 대한 loss!!!\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자. - 궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (stage2에서 할일은 아님)\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다. - 적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값을 찾자.\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라. - 단순한 수학문제가 되었다. 마치 \\(loss(w)=w^2-2w+3\\) 을 최소화하는 \\(w\\)를 찾으라는 것과 같음. - 즉 “적당한 선으로 업데이트 하라 = 파라메터를 학습 하라 = 손실함수를 최소화 하라”\n\n# 그 function을 minimize하는 정의역의 세트를 찾으면 된다. = 적당한 선으로 업데이트 하라= ...=\n\n- 우리의 무기: 경사하강법, 벡터미분\n\n\nStage2를 위한 경사하강법 복습\n경사하강법 아이디어 (1차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다.\n\n# 접선의 기울기가 만약 -4 라는 음수가 나오면 양수값으로 가면 된다.. \n# 미분계수의 절대값이 작아지는 정도로.. 보폭 조절!!\n\n경사하강법 아이디어 (2차원)\n(step 1) 임의의 점을 찍는다.\n(step 2) 그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n(step 3) 순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n(팁) 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다.\n\n# 왼쪽으로 갈래? 오른쪽으로 갈래?\n# 위로 갈래? 아래로 갈래? -&gt;점에서 한쪽방향을 고정되어있다 생각하고 왼오, 또는 위아래로만 -&gt; 편미분으로 가넝!!\n# 2차원, 3차원,, 원리는 결국 1차원과 똑같당!\n\nloss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n- $수정값 원래값 - 기울어진크기(=미분계수) $\n\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다.\n\n\n# 반대방향으로 가야하니까 - 를 붙인다. \n# a 알파값은 .. 만약 미분계수가 -8이 나왔엉. 근데 그렇다고 8곱해버리면 너무 크니까 0.8 이든 0.08이든.. 그런 알파값을 곱해줘야해!!\n\n# a 값은 양수여야함!!! 음수면 방향이 바꾸기 때문에 a는 정답이 없어. 0.0001 이렇게 걍 맞춰가면 뎀..\n\n- \\({\\bf W} \\leftarrow {\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)\n\n마이너스의 의미: 기울기의 부호를 보고 반대방향으로 움직여라.\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1):\\) 기울기의 절대값 크기와 비례하여 움직이는 정도를 조정하라.\n\\(\\alpha\\)의 의미: 전체적인 보폭의 속도를 조절, \\(\\alpha\\)가 크면 전체적으로 빠르게 움직인다. 다리의 길이로 비유할 수 있다.\n\n\n\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n- 우리의 목표: loss=8587.6875 인데, 이걸 줄이는 것이 목표라고 했었음. 이것을 줄이는 방법이 경사하강법이다.\n- 경사하강법으로 loss를 줄이기 위해서는 \\(\\frac{\\partial}{\\partial {\\bf W}}loss(w_0,w_1)\\)의 계산이 필요한데, 이를 위해서 벡터미분이 필요하다. (loss.backward()로 하면된다)\n\nWhat.grad\n\n\nloss.backward()\n\n# 자기 혼자 미분하고 결과값을 안보여죵  \n# 뭘로 미분하라는거야? -&gt;꼬리표 추적... What까지 가서 얘를 미분하라는 거구나 하고 미분해줌\n\n\nX@What #꼬리표가 있어!!!\n\ntensor([-29.8211, -28.6215, -24.9730, -21.2394, -19.7919, -19.6354, -19.5093,\n        -19.4352, -18.7223, -18.0793, -16.9040, -16.0918, -16.0536, -15.8746,\n        -14.4690, -14.3193, -13.6426, -12.8578, -12.5486, -12.4213, -11.9484,\n        -11.1034, -10.8296, -10.6210, -10.5064, -10.0578,  -9.8063,  -9.7380,\n         -9.7097,  -9.6756,  -8.8736,  -8.7195,  -8.6880,  -8.1592,  -7.7752,\n         -7.7716,  -7.7339,  -7.7208,  -7.6677,  -7.1551,  -7.0004,  -6.8163,\n         -6.7081,  -6.5655,  -6.4480,  -6.3612,  -6.0566,  -5.6031,  -5.5589,\n         -5.2137,  -4.3446,  -4.3165,  -3.8047,  -3.5801,  -3.4793,  -3.4325,\n         -2.3545,  -2.3440,  -1.8434,  -1.7799,  -1.5386,  -1.0161,  -0.8103,\n          0.4426,   0.5794,   0.9125,   1.1483,   1.4687,   1.4690,   1.5234,\n          1.6738,   2.0592,   2.1414,   2.8221,   3.1536,   3.6682,   4.2907,\n          4.8037,   4.8531,   4.9414,   5.3757,   5.3926,   5.6973,   6.0239,\n          6.1261,   6.5317,   7.2891,   8.4032,   8.4936,   9.2794,   9.9943,\n         10.0310,  10.4369,  11.7886,  15.8323,  17.4440,  18.9350,  21.0560,\n         21.0566,  21.6324], grad_fn=&lt;MvBackward0&gt;)\n\n\n\ny-X@What #꼬리표가 있는 걸로 파생된 모든 것들은 다 꼬리표가 있땅\n\ntensor([21.2791, 22.0448, 19.0234, 16.7600, 15.5403, 16.5028, 15.4853, 15.2491,\n        15.3820, 15.8766, 14.8778, 13.5299, 14.7183, 13.8280, 14.0026, 12.9680,\n        11.9954, 12.7489, 12.2415, 11.7914, 11.9046, 11.5198, 11.2462, 10.5267,\n        10.7726, 10.5168, 10.6967, 10.6377, 10.3411, 11.0601,  9.6820,  9.9789,\n         9.8090, 10.0825,  8.8370,  9.1268,  9.8500,  8.8644,  9.2922,  8.9190,\n         8.6027,  8.5628,  7.6912,  8.3478,  8.5596,  9.2232,  8.1731,  7.1257,\n         8.1160,  8.0498,  7.7402,  6.3844,  6.6187,  7.0653,  7.0851,  6.0290,\n         5.2399,  6.2613,  5.4961,  5.8827,  5.8510,  4.4186,  4.0283,  4.1260,\n         3.7978,  3.3949,  3.3412,  3.0141,  3.8481,  3.9753,  3.7895,  3.9736,\n         3.1428,  2.2318,  2.3002,  2.3654,  1.4343,  0.9550,  1.3489,  1.6579,\n         1.0864,  1.1214,  0.9873,  1.3258,  1.9648,  0.5476, -0.4224, -0.9803,\n        -1.2392, -2.0827, -0.4937, -0.9971, -2.9482, -2.7127, -4.7377, -7.1180,\n        -6.6685, -7.9578, -8.5098, -7.7984], grad_fn=&lt;SubBackward0&gt;)\n\n\n\nloss.backward()의 의미: loss를 미분해라! 뭘로? requires_grad=True를 가진 텐서로!!\n\n\nloss=torch.sum((y-yhat)**2)= torch.sum((y-X@What)**2)\n# 이었고 \nWhat=torch.tensor([-5.0,10.0],requires_grad=True)\n# 이므로 결국 What으로 미분하라는 의미. \n# 미분한 식이 나오는 것이 아니고, \n# 그 식에 (-5.0, 10.0)을 대입한 계수값이 계산됨. \n- 위에서 loss.backward()의 과정은 미분을 활용하여 \\((-5,10)\\)에서의 순간기울기를 구했다는 의미임.\n\nWhat.grad\n\ntensor([-1342.2522,  1188.9305])\n\n\n- (-5,10)에서 loss의 순간기울기 값은 What.grad로 확인가능하다.\n\n이것이 의미하는건 \\((-5,10)\\)에서의 \\(loss(w_0,w_1)\\)의 순간기울기가 \\((-1342.2523, 1188.9307)\\) 이라는 의미\n\n- (확인1) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 손계산으로 검증하여 보자.\n\n\\(loss(w_0,w_1)=({\\bf y}-\\hat{\\bf y})^\\top ({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf XW})^\\top ({\\bf y}-{\\bf XW})\\)\n\\(\\frac{\\partial}{\\partial {\\bf W} }loss(w_0,w_1)=-2{\\bf X}^\\top {\\bf y}+2{\\bf X}^\\top {\\bf X W}\\)\n\n\n- 2 * X.T @ y + 2 * X.T @ X @ What\n\ntensor([-1342.2523,  1188.9305], grad_fn=&lt;AddBackward0&gt;)\n\n\n- (확인2) loss.backward()가 미분을 잘 계산해 주는 것이 맞는가? 편미분을 간단히 구현하여 검증하여 보자.\n\n\\(\\frac{\\partial}{\\partial {\\bf W} } loss(w_0,w_1)=\\begin{bmatrix}\\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\end{bmatrix}loss(w_0,w_1) =\\begin{bmatrix}\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\end{bmatrix}\\)\n\\(\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\)\n\\(\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\)\n\n\n_lossfn = lambda w0,w1: torch.sum((y-w0-w1*x)**2)\n_lossfn(-5,10)\n\ntensor(8587.6875)\n\n\n\nh=0.001\n(_lossfn(-5+h,10) - _lossfn(-5,10))/h,  (_lossfn(-5,10+h) - _lossfn(-5,10))/h\n\n(tensor(-1341.7968), tensor(1190.4297))\n\n\n\n약간 오차가 있지만 얼추비슷 \\(\\to\\) 잘 계산했다는 소리임\n\n- 수정전, 수정하는폭, 수정후의 값은 차례로 아래와 같다.\n\nWhat.data\n\ntensor([-5., 10.])\n\n\n\nstr(What.data) #문자열이 됨! \n\n'tensor([-5., 10.])'\n\n\n\nalpha=0.001 \nprint('수정전: ' + str(What.data)) # What 에서 미분꼬리표를 떼고 싶다면? What.data or What.detach()\nprint('수정하는폭: ' +str(-alpha * What.grad)) #1341*0.001, 1190*0.001\nprint('수정후: ' +str(What.data-alpha * What.grad))\nprint('*참값: (2.5,4)' )\n\n수정전: tensor([-5., 10.])\n수정하는폭: tensor([ 1.3423, -1.1889])\n수정후: tensor([-3.6577,  8.8111])\n*참값: (2.5,4)\n\n\n- Wbefore, Wafter 계산\n\nWbefore = What.data\nWafter = What.data- alpha * What.grad\nWbefore, Wafter\n\n(tensor([-5., 10.]), tensor([-3.6577,  8.8111]))\n\n\n- Wbefore, Wafter의 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,X@Wbefore,'--')  #주황색\nplt.plot(x,X@Wafter,'--')  #초록색\n\n\n\n\n\n\n\nStage3: Learn (=estimate \\(\\bf\\hat{W})\\)\n- 이 과정은 Stage1,2를 반복하면 된다.\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True) \nWhat\n\ntensor([-5., 10.], requires_grad=True)\n\n\n\nalpha=0.001 \nfor epoc in range(30): ## 30번 반복합니다!! \n    yhat=X@What \n    loss=torch.sum((y-yhat)**2)\n    loss.backward() #미분.. what.grad로 미분이 된 것을 볼 수 있따-&gt;편미분계수값\n    What.data = What.data-alpha * What.grad #경사하강법~~\n    What.grad=None  # 파이토치 특징.. 미분된 grad값에 새 미분값이 안들어가있고.. 이전미분값에 그다음미분값이 더해져서 들어가기 때문에-&gt;defalut기 대문에 초기상태로 바꿔줘야햄....\n\n\nWhat\n\ntensor([2.4290, 4.0144], requires_grad=True)\n\n\n\n원래 철자는 epoch이 맞아요\n\n- 반복결과는?! (최종적으로 구해지는 What의 값은?!) - 참고로 true\n\nWhat.data ## true인 (2.5,4)와 상당히 비슷함\n\ntensor([2.4290, 4.0144])\n\n\n- 반복결과를 시각화하면?\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--') #그림을 그리기위해서 꼬리표를 떼준당.."
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#파라메터의-학습과정-음미-학습과정-모니터링",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#파라메터의-학습과정-음미-학습과정-모니터링",
    "title": "기계학습 (0921) 3주차",
    "section": "파라메터의 학습과정 음미 (학습과정 모니터링)",
    "text": "파라메터의 학습과정 음미 (학습과정 모니터링)\n\n학습과정의 기록\n- 기록을 해보자.\n\nloss_history = [] # 기록하고 싶은것 1  .\nyhat_history = [] # 기록하고 싶은것 2  yhat이 어떻게 변하는지\nWhat_history = [] # 기록하고 싶은것 3 \n\n\n#loss_history #처음엔 비어있지만.. 값을 점점 넣고 싶어!!!\n\n\n#loss_history.append(loss)\n#loss_history\n\n\n#loss.item()\n\n\n#loss_history.append(loss.item())\n#loss_history # 텐서를 리스트로 바꿔줘서 넣어주기..\n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())  #세미콜론만 주석처리하면.. 위랑 똑같은 코드..\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nloss_history\n\n[8587.6875,\n 5675.2109375,\n 3755.637451171875,\n 2489.581787109375,\n 1654.0390625,\n 1102.3206787109375,\n 737.8441162109375,\n 496.96514892578125,\n 337.7142028808594,\n 232.39694213867188,\n 162.72906494140625,\n 116.63263702392578,\n 86.1263656616211,\n 65.93397521972656,\n 52.566444396972656,\n 43.71583557128906,\n 37.855220794677734,\n 33.974090576171875,\n 31.403636932373047,\n 29.701112747192383,\n 28.57339096069336,\n 27.826366424560547,\n 27.331483840942383,\n 27.003639221191406,\n 26.78643798828125,\n 26.642536163330078,\n 26.547197341918945,\n 26.48402976989746,\n 26.442174911499023,\n 26.414440155029297]\n\n\n- \\(\\hat{y}\\) 관찰 (epoch=3, epoch=10, epoch=15)\n\nyhat_history\n\n[[-29.821128845214844,\n  -28.621461868286133,\n  -24.97295379638672,\n  -21.239360809326172,\n  -19.791915893554688,\n  -19.635364532470703,\n  -19.50925064086914,\n  -19.435216903686523,\n  -18.722301483154297,\n  -18.079282760620117,\n  -16.903972625732422,\n  -16.09178924560547,\n  -16.053556442260742,\n  -15.874590873718262,\n  -14.468965530395508,\n  -14.31933879852295,\n  -13.642648696899414,\n  -12.857781410217285,\n  -12.548619270324707,\n  -12.421306610107422,\n  -11.94838809967041,\n  -11.103449821472168,\n  -10.829590797424316,\n  -10.621047973632812,\n  -10.506429672241211,\n  -10.05777359008789,\n  -9.80626392364502,\n  -9.737953186035156,\n  -9.709654808044434,\n  -9.67557144165039,\n  -8.873588562011719,\n  -8.719473838806152,\n  -8.687962532043457,\n  -8.159214973449707,\n  -7.775153636932373,\n  -7.771570682525635,\n  -7.733872890472412,\n  -7.7207512855529785,\n  -7.667671203613281,\n  -7.155084609985352,\n  -7.000405311584473,\n  -6.816307067871094,\n  -6.708141326904297,\n  -6.565457820892334,\n  -6.4479804039001465,\n  -6.361170768737793,\n  -6.056612968444824,\n  -5.603134632110596,\n  -5.558872222900391,\n  -5.213672637939453,\n  -4.34455680847168,\n  -4.3164825439453125,\n  -3.8046953678131104,\n  -3.5801002979278564,\n  -3.479255437850952,\n  -3.4324843883514404,\n  -2.3544726371765137,\n  -2.3440215587615967,\n  -1.843425989151001,\n  -1.7798891067504883,\n  -1.5385699272155762,\n  -1.016080617904663,\n  -0.8102789521217346,\n  0.44257819652557373,\n  0.5793601274490356,\n  0.9125399589538574,\n  1.1482644081115723,\n  1.468665599822998,\n  1.468990445137024,\n  1.5233922004699707,\n  1.673753261566162,\n  2.059195041656494,\n  2.141373634338379,\n  2.8221492767333984,\n  3.1536107063293457,\n  3.6682331562042236,\n  4.290748119354248,\n  4.803698539733887,\n  4.853081226348877,\n  4.9413557052612305,\n  5.375688076019287,\n  5.392560005187988,\n  5.697267055511475,\n  6.023870468139648,\n  6.126120090484619,\n  6.531744956970215,\n  7.289087772369385,\n  8.403202056884766,\n  8.493597030639648,\n  9.279403686523438,\n  9.994264602661133,\n  10.030980110168457,\n  10.436870574951172,\n  11.788615226745605,\n  15.832330703735352,\n  17.444000244140625,\n  18.93501091003418,\n  21.05604362487793,\n  21.05657958984375,\n  21.632400512695312],\n [-25.527816772460938,\n  -24.470781326293945,\n  -21.25605583190918,\n  -17.96636199951172,\n  -16.691007614135742,\n  -16.553070068359375,\n  -16.44194793701172,\n  -16.37671661376953,\n  -15.748562812805176,\n  -15.181994438171387,\n  -14.1464204788208,\n  -13.430801391601562,\n  -13.397112846374512,\n  -13.239425659179688,\n  -12.000919342041016,\n  -11.869081497192383,\n  -11.272846221923828,\n  -10.581294059753418,\n  -10.30888843536377,\n  -10.196712493896484,\n  -9.780020713806152,\n  -9.035539627075195,\n  -8.794240951538086,\n  -8.610491752624512,\n  -8.509501457214355,\n  -8.114187240600586,\n  -7.892580509185791,\n  -7.832390785217285,\n  -7.807457447052002,\n  -7.777426242828369,\n  -7.070793151855469,\n  -6.935001850128174,\n  -6.907237529754639,\n  -6.441354274749756,\n  -6.102954864501953,\n  -6.09979772567749,\n  -6.066582202911377,\n  -6.055020809173584,\n  -6.008251190185547,\n  -5.556607723236084,\n  -5.420318603515625,\n  -5.258108615875244,\n  -5.1628031730651855,\n  -5.037083625793457,\n  -4.933573246002197,\n  -4.85708475112915,\n  -4.588736534118652,\n  -4.189174175262451,\n  -4.150174140930176,\n  -3.8460164070129395,\n  -3.0802321434020996,\n  -3.0554959774017334,\n  -2.6045565605163574,\n  -2.4066641330718994,\n  -2.3178091049194336,\n  -2.2765989303588867,\n  -1.326755166053772,\n  -1.3175466060638428,\n  -0.8764684200286865,\n  -0.8204857110977173,\n  -0.6078576445579529,\n  -0.14748874306678772,\n  0.03384458273649216,\n  1.13774573802948,\n  1.2582652568817139,\n  1.5518323183059692,\n  1.759530782699585,\n  2.0418384075164795,\n  2.0421247482299805,\n  2.0900585651397705,\n  2.2225425243377686,\n  2.5621581077575684,\n  2.634566307067871,\n  3.2344024181365967,\n  3.5264554023742676,\n  3.9798927307128906,\n  4.528395175933838,\n  4.980359077453613,\n  5.023870468139648,\n  5.101649761199951,\n  5.4843430519104,\n  5.499208927154541,\n  5.767688751220703,\n  6.055461406707764,\n  6.145554065704346,\n  6.502953052520752,\n  7.170252799987793,\n  8.151906967163086,\n  8.231554985046387,\n  8.923933982849121,\n  9.553803443908691,\n  9.586153030395508,\n  9.94378662109375,\n  11.134817123413086,\n  14.69776439666748,\n  16.117816925048828,\n  17.431556701660156,\n  19.300413131713867,\n  19.300886154174805,\n  19.808244705200195],\n [-22.067176818847656,\n  -21.124095916748047,\n  -18.25593376159668,\n  -15.320884704589844,\n  -14.183019638061523,\n  -14.059952735900879,\n  -13.960810661315918,\n  -13.90261173248291,\n  -13.34217643737793,\n  -12.836686134338379,\n  -11.912752151489258,\n  -11.274280548095703,\n  -11.244223594665527,\n  -11.103535652160645,\n  -9.998546600341797,\n  -9.880922317504883,\n  -9.348963737487793,\n  -8.731964111328125,\n  -8.48892593383789,\n  -8.388842582702637,\n  -8.017072677612305,\n  -7.352850437164307,\n  -7.137564659118652,\n  -6.9736247062683105,\n  -6.883521556854248,\n  -6.530824184417725,\n  -6.333107948303223,\n  -6.279407024383545,\n  -6.257161617279053,\n  -6.230367660522461,\n  -5.599913597106934,\n  -5.478761196136475,\n  -5.4539899826049805,\n  -5.038331031799316,\n  -4.73641300201416,\n  -4.733596324920654,\n  -4.703961372375488,\n  -4.693646430969238,\n  -4.651918888092041,\n  -4.248964786529541,\n  -4.127368450164795,\n  -3.982645273208618,\n  -3.8976142406463623,\n  -3.7854480743408203,\n  -3.69309663772583,\n  -3.6248538494110107,\n  -3.385435104370117,\n  -3.028947353363037,\n  -2.9941515922546387,\n  -2.7227838039398193,\n  -2.039555072784424,\n  -2.0174853801727295,\n  -1.6151596307754517,\n  -1.438601016998291,\n  -1.3593250513076782,\n  -1.3225574493408203,\n  -0.47511163353919983,\n  -0.46689584851264954,\n  -0.07336807250976562,\n  -0.023420605808496475,\n  0.16628508269786835,\n  0.5770238637924194,\n  0.7388085722923279,\n  1.7237036228179932,\n  1.8312305212020874,\n  2.0931496620178223,\n  2.2784571647644043,\n  2.5303306579589844,\n  2.530586004257202,\n  2.573352098464966,\n  2.691553831100464,\n  2.9945571422576904,\n  3.059159278869629,\n  3.594330072402954,\n  3.854898452758789,\n  4.259452819824219,\n  4.748823642730713,\n  5.152063846588135,\n  5.190884590148926,\n  5.260278701782227,\n  5.601716041564941,\n  5.614979267120361,\n  5.854515075683594,\n  6.111264705657959,\n  6.191644668579102,\n  6.510514736175537,\n  7.1058759689331055,\n  7.98170280456543,\n  8.052763938903809,\n  8.670501708984375,\n  9.232467651367188,\n  9.261330604553223,\n  9.580409049987793,\n  10.643040657043457,\n  13.821883201599121,\n  15.088847160339355,\n  16.26095962524414,\n  17.9283447265625,\n  17.92876625061035,\n  18.381427764892578],\n [-19.276042938232422,\n  -18.424091339111328,\n  -15.833085060119629,\n  -13.181654930114746,\n  -12.153742790222168,\n  -12.04256820678711,\n  -11.953006744384766,\n  -11.900431632995605,\n  -11.39415168762207,\n  -10.937507629394531,\n  -10.102855682373047,\n  -9.526080131530762,\n  -9.49892807006836,\n  -9.371834754943848,\n  -8.373621940612793,\n  -8.267363548278809,\n  -7.786808967590332,\n  -7.22943115234375,\n  -7.009877681732178,\n  -6.919466018676758,\n  -6.583621025085449,\n  -5.983583450317383,\n  -5.7891011238098145,\n  -5.641002655029297,\n  -5.559606552124023,\n  -5.24099063873291,\n  -5.062380313873291,\n  -5.01386833190918,\n  -4.993772506713867,\n  -4.969567775726318,\n  -4.400035381317139,\n  -4.290590286254883,\n  -4.26821231842041,\n  -3.8927195072174072,\n  -3.619976043701172,\n  -3.617431640625,\n  -3.590660333633423,\n  -3.5813422203063965,\n  -3.543646812438965,\n  -3.179630756378174,\n  -3.069784641265869,\n  -2.9390463829040527,\n  -2.862231731414795,\n  -2.760904550552368,\n  -2.6774771213531494,\n  -2.615828514099121,\n  -2.399545431137085,\n  -2.077505588531494,\n  -2.046072244644165,\n  -1.8009270429611206,\n  -1.1837197542190552,\n  -1.1637827157974243,\n  -0.8003342151641846,\n  -0.640836775302887,\n  -0.5692213177680969,\n  -0.5360066294670105,\n  0.22954916954040527,\n  0.23697106540203094,\n  0.5924716591835022,\n  0.637592613697052,\n  0.8089667558670044,\n  1.1800153255462646,\n  1.3261665105819702,\n  2.2158896923065186,\n  2.313025951385498,\n  2.549635410308838,\n  2.717036485671997,\n  2.944571018218994,\n  2.9448018074035645,\n  2.9834353923797607,\n  3.0902152061462402,\n  3.363938570022583,\n  3.4222981929779053,\n  3.905754804611206,\n  4.141143798828125,\n  4.506605625152588,\n  4.94868803024292,\n  5.312962532043457,\n  5.348031520843506,\n  5.410720348358154,\n  5.71916389465332,\n  5.73114538192749,\n  5.947534561157227,\n  6.179473876953125,\n  6.252087116241455,\n  6.540143966674805,\n  7.077974796295166,\n  7.869168758392334,\n  7.933363437652588,\n  8.491408348083496,\n  8.999070167541504,\n  9.02514362335205,\n  9.313389778137207,\n  10.273337364196777,\n  13.145004272460938,\n  14.289539337158203,\n  15.348388671875,\n  16.854652404785156,\n  16.855031967163086,\n  17.263954162597656],\n [-17.02360725402832,\n  -16.244606018066406,\n  -13.875457763671875,\n  -11.451059341430664,\n  -10.511163711547852,\n  -10.409507751464844,\n  -10.327615737915039,\n  -10.279541969299316,\n  -9.81661319732666,\n  -9.399069786071777,\n  -8.635885238647461,\n  -8.10849666595459,\n  -8.083669662475586,\n  -7.967459201812744,\n  -7.054719924926758,\n  -6.957560062408447,\n  -6.518153190612793,\n  -6.0085015296936035,\n  -5.807747840881348,\n  -5.7250776290893555,\n  -5.417989253997803,\n  -4.869330883026123,\n  -4.691501617431641,\n  -4.556084156036377,\n  -4.4816575050354,\n  -4.190323829650879,\n  -4.02700662612915,\n  -3.9826488494873047,\n  -3.964273452758789,\n  -3.942141532897949,\n  -3.4213757514953613,\n  -3.3213019371032715,\n  -3.3008406162261963,\n  -2.9574995040893555,\n  -2.7081100940704346,\n  -2.7057836055755615,\n  -2.681304693222046,\n  -2.6727843284606934,\n  -2.6383166313171387,\n  -2.3054697513580322,\n  -2.205029249191284,\n  -2.0854856967926025,\n  -2.0152485370635986,\n  -1.9225974082946777,\n  -1.846313714981079,\n  -1.7899439334869385,\n  -1.5921801328659058,\n  -1.2977153062820435,\n  -1.268973469734192,\n  -1.0448191165924072,\n  -0.48046091198921204,\n  -0.4622310400009155,\n  -0.12990324199199677,\n  0.015937041491270065,\n  0.08142035454511642,\n  0.11179099977016449,\n  0.8117952346801758,\n  0.8185816407203674,\n  1.1436420679092407,\n  1.1848994493484497,\n  1.3415995836257935,\n  1.680876612663269,\n  1.8145134449005127,\n  2.6280529499053955,\n  2.716871976852417,\n  2.9332215785980225,\n  3.0862884521484375,\n  3.2943403720855713,\n  3.294551134109497,\n  3.3298768997192383,\n  3.427513360977173,\n  3.6777989864349365,\n  3.731161594390869,\n  4.173221588134766,\n  4.388454914093018,\n  4.722623825073242,\n  5.126852512359619,\n  5.459935665130615,\n  5.492002010345459,\n  5.549322605133057,\n  5.831355094909668,\n  5.842310905456543,\n  6.0401716232299805,\n  6.252251148223877,\n  6.318646430969238,\n  6.582037925720215,\n  7.073816776275635,\n  7.797264099121094,\n  7.855961799621582,\n  8.366223335266113,\n  8.830416679382324,\n  8.854257583618164,\n  9.11782169342041,\n  9.995573043823242,\n  12.621350288391113,\n  13.667882919311523,\n  14.636066436767578,\n  16.013355255126953,\n  16.013702392578125,\n  16.387609481811523],\n [-15.204924583435059,\n  -14.484371185302734,\n  -12.292978286743164,\n  -10.050481796264648,\n  -9.181105613708496,\n  -9.087077140808105,\n  -9.01132869720459,\n  -8.966862678527832,\n  -8.538666725158691,\n  -8.152451515197754,\n  -7.446528434753418,\n  -6.958709716796875,\n  -6.9357452392578125,\n  -6.828253746032715,\n  -5.983996868133545,\n  -5.894127368927002,\n  -5.487689018249512,\n  -5.0162763595581055,\n  -4.830584526062012,\n  -4.754117012023926,\n  -4.470069885253906,\n  -3.9625768661499023,\n  -3.7980897426605225,\n  -3.672832727432251,\n  -3.603990077972412,\n  -3.33451509475708,\n  -3.1834518909454346,\n  -3.1424221992492676,\n  -3.125425338745117,\n  -3.1049540042877197,\n  -2.623260974884033,\n  -2.530695676803589,\n  -2.5117695331573486,\n  -2.1941893100738525,\n  -1.963511347770691,\n  -1.9613593816757202,\n  -1.938717007637024,\n  -1.9308359622955322,\n  -1.8989545106887817,\n  -1.591080904006958,\n  -1.4981764554977417,\n  -1.3876020908355713,\n  -1.3226348161697388,\n  -1.2369352579116821,\n  -1.1663750410079956,\n  -1.1142346858978271,\n  -0.9313089847564697,\n  -0.6589377522468567,\n  -0.6323524117469788,\n  -0.42501628398895264,\n  0.09699846059083939,\n  0.11386056244373322,\n  0.4212539494037628,\n  0.5561519265174866,\n  0.616722047328949,\n  0.6448140144348145,\n  1.2922972440719604,\n  1.298574447631836,\n  1.5992457866668701,\n  1.637407660484314,\n  1.7823506593704224,\n  2.0961718559265137,\n  2.2197821140289307,\n  2.9722821712493896,\n  3.0544371604919434,\n  3.254554033279419,\n  3.396136522293091,\n  3.588578224182129,\n  3.588773250579834,\n  3.621448516845703,\n  3.711759328842163,\n  3.9432661533355713,\n  3.9926249980926514,\n  4.401517391204834,\n  4.600602149963379,\n  4.909698486328125,\n  5.283597946166992,\n  5.5916900634765625,\n  5.621350288391113,\n  5.674370288848877,\n  5.935242176055908,\n  5.945375919342041,\n  6.128391265869141,\n  6.324558258056641,\n  6.385972023010254,\n  6.62960147857666,\n  7.084482192993164,\n  7.753649711608887,\n  7.807943344116211,\n  8.27992057800293,\n  8.709284782409668,\n  8.731337547302246,\n  8.975126266479492,\n  9.787020683288574,\n  12.215786933898926,\n  13.183798789978027,\n  14.079340934753418,\n  15.353291511535645,\n  15.353612899780273,\n  15.69946575164795],\n [-13.7357177734375,\n  -13.06203556060791,\n  -11.013188362121582,\n  -8.916561126708984,\n  -8.103736877441406,\n  -8.015825271606445,\n  -7.945003986358643,\n  -7.903429985046387,\n  -7.503087520599365,\n  -7.141994953155518,\n  -6.481991291046143,\n  -6.025904178619385,\n  -6.0044331550598145,\n  -5.903934001922607,\n  -5.114594459533691,\n  -5.0305705070495605,\n  -4.650570392608643,\n  -4.209822177886963,\n  -4.036209583282471,\n  -3.9647161960601807,\n  -3.6991453170776367,\n  -3.2246639728546143,\n  -3.070876359939575,\n  -2.9537672996520996,\n  -2.8894026279449463,\n  -2.6374564170837402,\n  -2.4962196350097656,\n  -2.4578588008880615,\n  -2.441967725753784,\n  -2.422827959060669,\n  -1.9724682569503784,\n  -1.885924220085144,\n  -1.8682290315628052,\n  -1.5713067054748535,\n  -1.3556339740753174,\n  -1.3536220788955688,\n  -1.3324525356292725,\n  -1.3250840902328491,\n  -1.2952765226364136,\n  -1.007429599761963,\n  -0.9205683469772339,\n  -0.8171865940093994,\n  -0.7564453482627869,\n  -0.6763203740119934,\n  -0.6103500127792358,\n  -0.5616012215614319,\n  -0.39057457447052,\n  -0.13592055439949036,\n  -0.11106456071138382,\n  0.0827847421169281,\n  0.5708433985710144,\n  0.5866086483001709,\n  0.8740066289901733,\n  1.0001296997070312,\n  1.0567599534988403,\n  1.083024501800537,\n  1.6883901357650757,\n  1.6942590475082397,\n  1.975372314453125,\n  2.011051893234253,\n  2.146566390991211,\n  2.439974308013916,\n  2.5555436611175537,\n  3.2590951919555664,\n  3.3359060287475586,\n  3.523005723953247,\n  3.655378580093384,\n  3.8353021144866943,\n  3.835484743118286,\n  3.8660342693328857,\n  3.9504706859588623,\n  4.1669182777404785,\n  4.213066577911377,\n  4.595361232757568,\n  4.781496047973633,\n  5.070486068725586,\n  5.4200639724731445,\n  5.708115100860596,\n  5.735846042633057,\n  5.785417556762695,\n  6.029320240020752,\n  6.03879451751709,\n  6.20990514755249,\n  6.393311977386475,\n  6.450730800628662,\n  6.6785125732421875,\n  7.103804111480713,\n  7.729443550109863,\n  7.780205726623535,\n  8.221481323242188,\n  8.622916221618652,\n  8.643534660339355,\n  8.871465682983398,\n  9.630547523498535,\n  11.901327133178711,\n  12.806371688842773,\n  13.643659591674805,\n  14.834742546081543,\n  14.835042953491211,\n  15.158398628234863],\n [-12.548260688781738,\n  -11.912196159362793,\n  -9.97775650024414,\n  -7.998204708099365,\n  -7.230768203735352,\n  -7.147764682769775,\n  -7.080898761749268,\n  -7.0416460037231445,\n  -6.663658618927002,\n  -6.322729110717773,\n  -5.69957971572876,\n  -5.268960475921631,\n  -5.248688697814941,\n  -5.153800964355469,\n  -4.408538341522217,\n  -4.3292059898376465,\n  -3.9704248905181885,\n  -3.554287910461426,\n  -3.3903696537017822,\n  -3.322868585586548,\n  -3.072127103805542,\n  -2.624140739440918,\n  -2.478940725326538,\n  -2.368370771408081,\n  -2.307600259780884,\n  -2.0697226524353027,\n  -1.9363723993301392,\n  -1.900153636932373,\n  -1.8851499557495117,\n  -1.8670789003372192,\n  -1.4418671131134033,\n  -1.360155701637268,\n  -1.3434486389160156,\n  -1.0631064176559448,\n  -0.8594767451286316,\n  -0.8575771450996399,\n  -0.8375897407531738,\n  -0.830632746219635,\n  -0.8024895787239075,\n  -0.5307159423828125,\n  -0.4487050175666809,\n  -0.35109609365463257,\n  -0.29374656081199646,\n  -0.2180957943201065,\n  -0.1558091938495636,\n  -0.10978250950574875,\n  0.051694076508283615,\n  0.2921282947063446,\n  0.315596342086792,\n  0.4986211657524109,\n  0.959426760673523,\n  0.9743117094039917,\n  1.2456614971160889,\n  1.3647419214248657,\n  1.4182099103927612,\n  1.4430078268051147,\n  2.0145699977874756,\n  2.020111322402954,\n  2.285527229309082,\n  2.319214344024658,\n  2.447161912918091,\n  2.7241859436035156,\n  2.8333020210266113,\n  3.4975674152374268,\n  3.570089101791382,\n  3.74674129486084,\n  3.871722459793091,\n  4.041599273681641,\n  4.041771411895752,\n  4.070615291595459,\n  4.150336742401123,\n  4.354698181152344,\n  4.398269176483154,\n  4.759216785430908,\n  4.934957981109619,\n  5.207810878753662,\n  5.537868499755859,\n  5.809834957122803,\n  5.836017608642578,\n  5.8828206062316895,\n  6.113103866577148,\n  6.122049331665039,\n  6.283605098724365,\n  6.456770420074463,\n  6.510982990264893,\n  6.726045608520508,\n  7.127589225769043,\n  7.718293190002441,\n  7.766220569610596,\n  8.182855606079102,\n  8.561875343322754,\n  8.581341743469238,\n  8.796545028686523,\n  9.513239860534668,\n  11.657219886779785,\n  12.511727333068848,\n  13.302261352539062,\n  14.426834106445312,\n  14.427118301391602,\n  14.732418060302734],\n [-11.588088035583496,\n  -10.982240676879883,\n  -9.139697074890137,\n  -7.254184246063232,\n  -6.523205280303955,\n  -6.444145202636719,\n  -6.380455493927002,\n  -6.343067646026611,\n  -5.983036518096924,\n  -5.658303260803223,\n  -5.064756870269775,\n  -4.6545939445495605,\n  -4.635285377502441,\n  -4.544905662536621,\n  -3.8350467681884766,\n  -3.7594833374023438,\n  -3.417746067047119,\n  -3.0213780403137207,\n  -2.8652467727661133,\n  -2.800952196121216,\n  -2.5621225833892822,\n  -2.1354176998138428,\n  -1.9971154928207397,\n  -1.8917983770370483,\n  -1.8339147567749023,\n  -1.6073375940322876,\n  -1.480322241783142,\n  -1.445824146270752,\n  -1.4315330982208252,\n  -1.4143205881118774,\n  -1.0093086957931519,\n  -0.9314789175987244,\n  -0.9155654907226562,\n  -0.6485410928726196,\n  -0.4545849859714508,\n  -0.45277559757232666,\n  -0.43373769521713257,\n  -0.4271112382411957,\n  -0.40030497312545776,\n  -0.14144207537174225,\n  -0.0633271187543869,\n  0.02964484691619873,\n  0.0842699483036995,\n  0.15632690489292145,\n  0.21565455198287964,\n  0.25949472188949585,\n  0.4133002758026123,\n  0.6423125863075256,\n  0.6646657586097717,\n  0.8389959335327148,\n  1.2779107093811035,\n  1.292088508605957,\n  1.55054771900177,\n  1.663971185684204,\n  1.7148991823196411,\n  1.7385190725326538,\n  2.282928943634033,\n  2.2882070541381836,\n  2.5410141944885254,\n  2.573101043701172,\n  2.6949703693389893,\n  2.958834171295166,\n  3.0627667903900146,\n  3.6954758167266846,\n  3.764552593231201,\n  3.9328126907348633,\n  4.051856517791748,\n  4.213663101196289,\n  4.213827133178711,\n  4.2413010597229,\n  4.317235469818115,\n  4.51188850402832,\n  4.553389549255371,\n  4.897190093994141,\n  5.064582347869873,\n  5.3244733810424805,\n  5.638851642608643,\n  5.897898197174072,\n  5.922836780548096,\n  5.967416763305664,\n  6.186760425567627,\n  6.1952805519104,\n  6.349161624908447,\n  6.514101028442383,\n  6.565738201141357,\n  6.7705841064453125,\n  7.153051853179932,\n  7.715693950653076,\n  7.761344909667969,\n  8.158186912536621,\n  8.519201278686523,\n  8.537742614746094,\n  8.74272346496582,\n  9.425371170043945,\n  11.467500686645508,\n  12.281414031982422,\n  13.034393310546875,\n  14.10554313659668,\n  14.105813980102539,\n  14.396610260009766],\n [-10.811363220214844,\n  -10.229805946350098,\n  -8.46113395690918,\n  -6.651216983795166,\n  -5.949544429779053,\n  -5.873653888702393,\n  -5.8125176429748535,\n  -5.776628494262695,\n  -5.431032180786133,\n  -5.11931848526001,\n  -4.5495686531066895,\n  -4.155850410461426,\n  -4.13731575012207,\n  -4.0505595207214355,\n  -3.3691604137420654,\n  -3.296626567840576,\n  -2.968590497970581,\n  -2.58811354637146,\n  -2.438242197036743,\n  -2.376525402069092,\n  -2.147270917892456,\n  -1.7376737594604492,\n  -1.6049163341522217,\n  -1.5038214921951294,\n  -1.448258638381958,\n  -1.2307655811309814,\n  -1.1088424921035767,\n  -1.0757274627685547,\n  -1.0620094537734985,\n  -1.0454870462417603,\n  -0.6567130088806152,\n  -0.582003653049469,\n  -0.5667282342910767,\n  -0.31040942668914795,\n  -0.12422949820756912,\n  -0.12249265611171722,\n  -0.104218028485775,\n  -0.09785724431276321,\n  -0.07212571799755096,\n  0.17635875940322876,\n  0.25134190917015076,\n  0.340586394071579,\n  0.39302143454551697,\n  0.4621894657611847,\n  0.519138514995575,\n  0.5612210631370544,\n  0.7088601589202881,\n  0.9286907911300659,\n  0.950147807598114,\n  1.1174886226654053,\n  1.5388063192367554,\n  1.5524157285690308,\n  1.800512671470642,\n  1.909388780593872,\n  1.9582748413085938,\n  1.9809478521347046,\n  2.503530979156494,\n  2.5085973739624023,\n  2.7512691020965576,\n  2.782069444656372,\n  2.899052858352661,\n  3.1523375511169434,\n  3.252103328704834,\n  3.859445571899414,\n  3.925752639770508,\n  4.08726692199707,\n  4.2015380859375,\n  4.356857776641846,\n  4.357015132904053,\n  4.383387088775635,\n  4.456276893615723,\n  4.643126010894775,\n  4.6829633712768555,\n  5.012979984283447,\n  5.173661231994629,\n  5.423132419586182,\n  5.7249064445495605,\n  5.973567485809326,\n  5.997506141662598,\n  6.040298938751221,\n  6.250848293304443,\n  6.259027004241943,\n  6.406738758087158,\n  6.565064907073975,\n  6.6146321296691895,\n  6.811265468597412,\n  7.178399085998535,\n  7.7184834480285645,\n  7.762304306030273,\n  8.14323616027832,\n  8.489776611328125,\n  8.507574081420898,\n  8.704336166381836,\n  9.359615325927734,\n  11.319870948791504,\n  12.101153373718262,\n  12.823944091796875,\n  13.852148056030273,\n  13.852408409118652,\n  14.131546020507812],\n [-10.182785987854004,\n  -9.620768547058105,\n  -7.911523342132568,\n  -6.162417888641357,\n  -5.484321117401123,\n  -5.410980701446533,\n  -5.351898670196533,\n  -5.317215442657471,\n  -4.9832305908203125,\n  -4.681990146636963,\n  -4.131383895874023,\n  -3.750894069671631,\n  -3.7329823970794678,\n  -3.6491410732269287,\n  -2.9906365871429443,\n  -2.9205398559570312,\n  -2.6035256385803223,\n  -2.235832691192627,\n  -2.090996742248535,\n  -2.03135347366333,\n  -1.8098018169403076,\n  -1.4139670133590698,\n  -1.2856701612472534,\n  -1.187972068786621,\n  -1.1342761516571045,\n  -0.9240906238555908,\n  -0.8062641024589539,\n  -0.7742617130279541,\n  -0.761004626750946,\n  -0.745037317276001,\n  -0.3693259060382843,\n  -0.29712674021720886,\n  -0.2823645770549774,\n  -0.03465794026851654,\n  0.14526645839214325,\n  0.14694494009017944,\n  0.1646055430173874,\n  0.170752614736557,\n  0.19561956822872162,\n  0.4357551038265228,\n  0.5082188844680786,\n  0.5944647789001465,\n  0.6451380848884583,\n  0.7119820713996887,\n  0.767017662525177,\n  0.8076862692832947,\n  0.9503647685050964,\n  1.1628092527389526,\n  1.1835453510284424,\n  1.3452636003494263,\n  1.752425193786621,\n  1.7655773162841797,\n  2.005338430404663,\n  2.1105563640594482,\n  2.15779972076416,\n  2.179711103439331,\n  2.6847357749938965,\n  2.689631938934326,\n  2.924149751663208,\n  2.9539153575897217,\n  3.0669682025909424,\n  3.3117427825927734,\n  3.408156394958496,\n  3.9950923919677734,\n  4.059171676635742,\n  4.215259075164795,\n  4.325690746307373,\n  4.4757914543151855,\n  4.475943565368652,\n  4.501429557800293,\n  4.571870803833008,\n  4.75244140625,\n  4.790940284729004,\n  5.109869003295898,\n  5.265151023864746,\n  5.506240367889404,\n  5.797874927520752,\n  6.038180828094482,\n  6.061315536499023,\n  6.102670192718506,\n  6.306145191192627,\n  6.314049243927002,\n  6.456798076629639,\n  6.609804630279541,\n  6.657706260681152,\n  6.8477325439453125,\n  7.202530860900879,\n  7.72446870803833,\n  7.766817092895508,\n  8.134949684143066,\n  8.469846725463867,\n  8.48704719543457,\n  8.677197456359863,\n  9.310460090637207,\n  11.204852104187012,\n  11.959882736206055,\n  12.658388137817383,\n  13.652046203613281,\n  13.652297019958496,\n  13.9220552444458],\n [-9.673905372619629,\n  -9.127617835998535,\n  -7.466211318969727,\n  -5.766060829162598,\n  -5.106943130493164,\n  -5.0356550216674805,\n  -4.978226661682129,\n  -4.944514274597168,\n  -4.619877338409424,\n  -4.327067852020264,\n  -3.791872262954712,\n  -3.422031879425049,\n  -3.4046216011047363,\n  -3.323126792907715,\n  -2.6830527782440186,\n  -2.6149179935455322,\n  -2.306776523590088,\n  -1.9493745565414429,\n  -1.808592438697815,\n  -1.750618577003479,\n  -1.5352678298950195,\n  -1.1505117416381836,\n  -1.0258057117462158,\n  -0.9308421015739441,\n  -0.8786489963531494,\n  -0.6743462681770325,\n  -0.5598175525665283,\n  -0.5287108421325684,\n  -0.5158247947692871,\n  -0.5003044009208679,\n  -0.13510854542255402,\n  -0.06493011862039566,\n  -0.050581131130456924,\n  0.1901925802230835,\n  0.36508116126060486,\n  0.36671265959739685,\n  0.3838789761066437,\n  0.3898540139198303,\n  0.4140249788761139,\n  0.6474394798278809,\n  0.7178751230239868,\n  0.8017071485519409,\n  0.8509621620178223,\n  0.9159352779388428,\n  0.9694305658340454,\n  1.0089608430862427,\n  1.1476460695266724,\n  1.35414457321167,\n  1.374300241470337,\n  1.5314922332763672,\n  1.927258014678955,\n  1.9400420188903809,\n  2.1730926036834717,\n  2.2753655910491943,\n  2.321286916732788,\n  2.3425848484039307,\n  2.833474636077881,\n  2.838233709335327,\n  3.066187858581543,\n  3.095120429992676,\n  3.2050089836120605,\n  3.4429328441619873,\n  3.5366477966308594,\n  4.107156276702881,\n  4.169442176818848,\n  4.321160793304443,\n  4.428501605987549,\n  4.574401378631592,\n  4.574549674987793,\n  4.599322319030762,\n  4.667791366577148,\n  4.843308448791504,\n  4.880730152130127,\n  5.190732002258301,\n  5.341668128967285,\n  5.576009750366211,\n  5.8594818115234375,\n  6.093061923980713,\n  6.115549087524414,\n  6.1557464599609375,\n  6.353526592254639,\n  6.361209392547607,\n  6.49996280670166,\n  6.64868688583374,\n  6.695247650146484,\n  6.879955768585205,\n  7.224823474884033,\n  7.732153415679932,\n  7.773316383361816,\n  8.131145477294922,\n  8.456668853759766,\n  8.473387718200684,\n  8.65821647644043,\n  9.273755073547363,\n  11.11512565612793,\n  11.849024772644043,\n  12.527979850769043,\n  13.493826866149902,\n  13.494071006774902,\n  13.756278991699219],\n [-9.261781692504883,\n  -8.728165626525879,\n  -7.105295658111572,\n  -5.444580554962158,\n  -4.800751209259033,\n  -4.731117248535156,\n  -4.675020694732666,\n  -4.642090320587158,\n  -4.3249831199646,\n  -4.038965702056885,\n  -3.516183853149414,\n  -3.1549222469329834,\n  -3.13791561126709,\n  -3.0583112239837646,\n  -2.433084011077881,\n  -2.3665294647216797,\n  -2.065535306930542,\n  -1.716423511505127,\n  -1.578906774520874,\n  -1.5222777128219604,\n  -1.3119219541549683,\n  -0.9360904097557068,\n  -0.8142769932746887,\n  -0.7215160727500916,\n  -0.6705335974693298,\n  -0.4709697663784027,\n  -0.35909754037857056,\n  -0.3287123739719391,\n  -0.3161252439022064,\n  -0.3009648025035858,\n  0.0557602196931839,\n  0.12431085109710693,\n  0.1383270025253296,\n  0.37351590394973755,\n  0.5443479418754578,\n  0.5459415912628174,\n  0.5627096891403198,\n  0.5685461759567261,\n  0.5921564698219299,\n  0.8201568722724915,\n  0.8889586925506592,\n  0.9708462357521057,\n  1.0189588069915771,\n  1.0824248790740967,\n  1.1346791982650757,\n  1.173292636871338,\n  1.3087610006332397,\n  1.510469675064087,\n  1.5301578044891357,\n  1.6837037801742554,\n  2.0702898502349854,\n  2.082777261734009,\n  2.31042218208313,\n  2.410322904586792,\n  2.45517897605896,\n  2.475982904434204,\n  2.955486536026001,\n  2.960134983062744,\n  3.1828017234802246,\n  3.2110631465911865,\n  3.3184027671813965,\n  3.5508079528808594,\n  3.6423492431640625,\n  4.199624538421631,\n  4.260465621948242,\n  4.408665657043457,\n  4.513516426086426,\n  4.656032085418701,\n  4.656176567077637,\n  4.680374622344971,\n  4.747255802154541,\n  4.918701648712158,\n  4.955255031585693,\n  5.258066654205322,\n  5.405501842498779,\n  5.6344075202941895,\n  5.911304473876953,\n  6.139466762542725,\n  6.161432266235352,\n  6.200697422027588,\n  6.393889904022217,\n  6.401394367218018,\n  6.536929130554199,\n  6.682203769683838,\n  6.727684497833252,\n  6.908108234405518,\n  7.244976997375488,\n  7.740539073944092,\n  7.780747413635254,\n  8.130276679992676,\n  8.448249816894531,\n  8.464580535888672,\n  8.645122528076172,\n  9.246382713317871,\n  11.045042991638184,\n  11.761919021606445,\n  12.425125122070312,\n  13.368569374084473,\n  13.368807792663574,\n  13.624934196472168],\n [-8.927906036376953,\n  -8.404502868652344,\n  -6.81269645690918,\n  -5.1837687492370605,\n  -4.552262783050537,\n  -4.483961582183838,\n  -4.428938865661621,\n  -4.3966383934021,\n  -4.085601329803467,\n  -3.805058479309082,\n  -3.292283058166504,\n  -2.9379360675811768,\n  -2.921255111694336,\n  -2.8431742191314697,\n  -2.229914426803589,\n  -2.1646337509155273,\n  -1.869400978088379,\n  -1.5269713401794434,\n  -1.3920868635177612,\n  -1.3365416526794434,\n  -1.1302123069763184,\n  -0.7615744471549988,\n  -0.6420926451683044,\n  -0.5511072278022766,\n  -0.5011005997657776,\n  -0.30535656213760376,\n  -0.1956256479024887,\n  -0.1658220887184143,\n  -0.15347588062286377,\n  -0.13860562443733215,\n  0.21129140257835388,\n  0.27852991223335266,\n  0.2922777831554413,\n  0.5229650139808655,\n  0.6905271410942078,\n  0.6920903325080872,\n  0.7085375189781189,\n  0.7142622470855713,\n  0.7374206185340881,\n  0.9610569477081299,\n  1.0285418033599854,\n  1.108862042427063,\n  1.1560535430908203,\n  1.2183048725128174,\n  1.2695591449737549,\n  1.3074333667755127,\n  1.4403088092803955,\n  1.6381566524505615,\n  1.6574679613113403,\n  1.8080748319625854,\n  2.1872613430023193,\n  2.199509859085083,\n  2.422797203063965,\n  2.5207858085632324,\n  2.5647833347320557,\n  2.5851891040802,\n  3.0555145740509033,\n  3.0600743293762207,\n  3.2784790992736816,\n  3.306199550628662,\n  3.411484479904175,\n  3.6394412517547607,\n  3.7292304039001465,\n  4.275839328765869,\n  4.335515975952148,\n  4.480878829956055,\n  4.583723068237305,\n  4.7235107421875,\n  4.723652362823486,\n  4.747387409210205,\n  4.81298828125,\n  4.981152534484863,\n  5.0170063972473145,\n  5.314021587371826,\n  5.458634853363037,\n  5.683159351348877,\n  5.954756259918213,\n  6.178551197052002,\n  6.200096130371094,\n  6.238609790802002,\n  6.428104400634766,\n  6.435465335845947,\n  6.568406105041504,\n  6.710899829864502,\n  6.755510330200195,\n  6.932480335235596,\n  7.262901306152344,\n  7.7489776611328125,\n  7.788416385650635,\n  8.131255149841309,\n  8.44314193725586,\n  8.459160804748535,\n  8.636246681213379,\n  9.225998878479004,\n  10.990230560302734,\n  11.693385124206543,\n  12.343897819519043,\n  13.269283294677734,\n  13.269516944885254,\n  13.520740509033203],\n [-8.657336235046387,\n  -8.142171859741211,\n  -6.575418949127197,\n  -4.972128868103027,\n  -4.35056209564209,\n  -4.2833356857299805,\n  -4.2291789054870605,\n  -4.197387218475342,\n  -3.8912453651428223,\n  -3.6151180267333984,\n  -3.110413074493408,\n  -2.761643409729004,\n  -2.745224714279175,\n  -2.668372869491577,\n  -2.064765214920044,\n  -2.000511884689331,\n  -1.709925889968872,\n  -1.372885823249817,\n  -1.240124225616455,\n  -1.1854532957077026,\n  -0.9823713898658752,\n  -0.6195355653762817,\n  -0.5019342303276062,\n  -0.4123808741569519,\n  -0.3631612956523895,\n  -0.1704980731010437,\n  -0.06249423325061798,\n  -0.033159755170345306,\n  -0.021007858216762543,\n  -0.006371652241796255,\n  0.3380183279514313,\n  0.4041985869407654,\n  0.41773006319999695,\n  0.6447864770889282,\n  0.8097113966941833,\n  0.8112499117851257,\n  0.827438235282898,\n  0.83307284116745,\n  0.8558667898178101,\n  1.0759832859039307,\n  1.1424059867858887,\n  1.2214620113372803,\n  1.2679108381271362,\n  1.3291823863983154,\n  1.3796298503875732,\n  1.4169081449508667,\n  1.5476921796798706,\n  1.7424260377883911,\n  1.7614333629608154,\n  1.9096699953079224,\n  2.282888412475586,\n  2.2949440479278564,\n  2.5147171020507812,\n  2.61116361618042,\n  2.654468536376953,\n  2.674553155899048,\n  3.1374762058258057,\n  3.1419641971588135,\n  3.356931447982788,\n  3.3842155933380127,\n  3.4878435134887695,\n  3.712212324142456,\n  3.800588369369507,\n  4.33859395980835,\n  4.397331237792969,\n  4.540406227111816,\n  4.641631603240967,\n  4.779219627380371,\n  4.779358863830566,\n  4.802720546722412,\n  4.867288589477539,\n  5.032806396484375,\n  5.068095684051514,\n  5.36043643951416,\n  5.502773761749268,\n  5.723764419555664,\n  5.991086483001709,\n  6.211359024047852,\n  6.232564926147461,\n  6.270472049713135,\n  6.456984519958496,\n  6.464229583740234,\n  6.595077991485596,\n  6.7353291511535645,\n  6.779237270355225,\n  6.9534220695495605,\n  7.278642177581787,\n  7.757068634033203,\n  7.795886516571045,\n  8.133329391479492,\n  8.4403076171875,\n  8.456073760986328,\n  8.630373001098633,\n  9.21084213256836,\n  10.947306632995605,\n  11.639394760131836,\n  12.279668807983398,\n  13.190489768981934,\n  13.190719604492188,\n  13.437989234924316],\n [-8.438004493713379,\n  -7.929488182067871,\n  -6.38295316696167,\n  -4.800353050231934,\n  -4.186807155609131,\n  -4.120448589324951,\n  -4.066990852355957,\n  -4.035609245300293,\n  -3.7334179878234863,\n  -3.4608538150787354,\n  -2.9626619815826416,\n  -2.6183929443359375,\n  -2.602186441421509,\n  -2.5263261795043945,\n  -1.930507779121399,\n  -1.8670837879180908,\n  -1.5802475214004517,\n  -1.2475568056106567,\n  -1.1165084838867188,\n  -1.0625430345535278,\n  -0.8620818257331848,\n  -0.5039282441139221,\n  -0.3878445327281952,\n  -0.29944679141044617,\n  -0.25086236000061035,\n  -0.06068538501858711,\n  0.04592471569776535,\n  0.07488065212965012,\n  0.08687572926282883,\n  0.10132306069135666,\n  0.44126883149147034,\n  0.5065950751304626,\n  0.5199519395828247,\n  0.7440782785415649,\n  0.9068748950958252,\n  0.9083935618400574,\n  0.9243730306625366,\n  0.9299349188804626,\n  0.9524346590042114,\n  1.169710636138916,\n  1.235276222229004,\n  1.31331205368042,\n  1.3591614961624146,\n  1.4196423292160034,\n  1.469438910484314,\n  1.506235957145691,\n  1.6353323459625244,\n  1.8275532722473145,\n  1.8463153839111328,\n  1.9926389455795288,\n  2.3610410690307617,\n  2.372941255569458,\n  2.5898783206939697,\n  2.685080051422119,\n  2.7278263568878174,\n  2.7476518154144287,\n  3.2046008110046387,\n  3.209030866622925,\n  3.4212241172790527,\n  3.4481561183929443,\n  3.5504469871520996,\n  3.7719204425811768,\n  3.8591558933258057,\n  4.390218734741211,\n  4.448198318481445,\n  4.5894269943237305,\n  4.6893463134765625,\n  4.82515811920166,\n  4.825295925140381,\n  4.848355770111084,\n  4.912091255187988,\n  5.075472831726074,\n  5.110306739807129,\n  5.398874759674072,\n  5.539375305175781,\n  5.757513999938965,\n  6.021386623382568,\n  6.238816738128662,\n  6.259748935699463,\n  6.29716682434082,\n  6.4812726974487305,\n  6.488424301147461,\n  6.617583751678467,\n  6.756025314331055,\n  6.799366474151611,\n  6.971303462982178,\n  7.292326927185059,\n  7.764579772949219,\n  7.802896499633789,\n  8.135985374450684,\n  8.439001083374023,\n  8.454564094543457,\n  8.62661361694336,\n  9.199593544006348,\n  10.913649559020996,\n  11.596805572509766,\n  12.2288179397583,\n  13.127883911132812,\n  13.128111839294434,\n  13.372190475463867],\n [-8.260159492492676,\n  -7.757010459899902,\n  -6.226800441741943,\n  -4.660905838012695,\n  -4.053836822509766,\n  -3.988178253173828,\n  -3.9352846145629883,\n  -3.9042344093322754,\n  -3.6052331924438477,\n  -3.3355460166931152,\n  -2.8426129817962646,\n  -2.5019781589508057,\n  -2.4859423637390137,\n  -2.4108831882476807,\n  -1.8213540315628052,\n  -1.7585995197296143,\n  -1.4747910499572754,\n  -1.145612120628357,\n  -1.0159471035003662,\n  -0.9625513553619385,\n  -0.7642061114311218,\n  -0.4098331332206726,\n  -0.29497477412223816,\n  -0.20751014351844788,\n  -0.1594385802745819,\n  0.028730938211083412,\n  0.13421568274497986,\n  0.16286596655845642,\n  0.174734428524971,\n  0.189029261469841,\n  0.5253866314888,\n  0.5900232791900635,\n  0.6032391786575317,\n  0.8249996900558472,\n  0.9860778450965881,\n  0.9875805377960205,\n  1.0033912658691406,\n  1.008894443511963,\n  1.0311566591262817,\n  1.2461391687393188,\n  1.3110127449035645,\n  1.388224720954895,\n  1.4335901737213135,\n  1.493432641029358,\n  1.5427035093307495,\n  1.5791122913360596,\n  1.7068458795547485,\n  1.8970377445220947,\n  1.9156018495559692,\n  2.0603809356689453,\n  2.424894332885742,\n  2.436668634414673,\n  2.651315927505493,\n  2.7455127239227295,\n  2.7878077030181885,\n  2.8074238300323486,\n  3.259549617767334,\n  3.263932704925537,\n  3.473886013031006,\n  3.5005338191986084,\n  3.6017448902130127,\n  3.820880651473999,\n  3.9071953296661377,\n  4.432652473449707,\n  4.490019798278809,\n  4.629757404327393,\n  4.728621959686279,\n  4.863000392913818,\n  4.8631367683410645,\n  4.885953426361084,\n  4.9490156173706055,\n  5.110672950744629,\n  5.145139217376709,\n  5.430661201477051,\n  5.56967830657959,\n  5.785514831542969,\n  6.04660177230835,\n  6.261736869812012,\n  6.2824482917785645,\n  6.31947135925293,\n  6.501633167266846,\n  6.50870943069458,\n  6.636505603790283,\n  6.7734856605529785,\n  6.816370010375977,\n  6.986491680145264,\n  7.304126739501953,\n  7.7713942527771,\n  7.809306621551514,\n  8.13887882232666,\n  8.43869686126709,\n  8.454095840454102,\n  8.62432861328125,\n  9.19126033782959,\n  10.887223243713379,\n  11.5631685256958,\n  12.188508033752441,\n  13.078084945678711,\n  13.078310012817383,\n  13.319812774658203],\n [-8.115914344787598,\n  -7.617101669311523,\n  -6.1000800132751465,\n  -4.547680854797363,\n  -3.9458436965942383,\n  -3.880751132965088,\n  -3.8283135890960693,\n  -3.7975308895111084,\n  -3.5011065006256104,\n  -3.233743667602539,\n  -2.745059013366699,\n  -2.4073598384857178,\n  -2.3914623260498047,\n  -2.317049980163574,\n  -1.7326017618179321,\n  -1.670388102531433,\n  -1.3890256881713867,\n  -1.0626837015151978,\n  -0.9341362714767456,\n  -0.8812006711959839,\n  -0.6845648884773254,\n  -0.3332460820674896,\n  -0.21937762200832367,\n  -0.13266681134700775,\n  -0.08500954508781433,\n  0.10153822600841522,\n  0.20611386001110077,\n  0.23451721668243408,\n  0.2462833821773529,\n  0.26045501232147217,\n  0.5939134955406189,\n  0.6579930782318115,\n  0.671095073223114,\n  0.8909443616867065,\n  1.0506342649459839,\n  1.0521239042282104,\n  1.067798376083374,\n  1.0732542276382446,\n  1.0953246355056763,\n  1.3084542751312256,\n  1.3727686405181885,\n  1.4493151903152466,\n  1.494289755821228,\n  1.5536164045333862,\n  1.602462649345398,\n  1.6385575532913208,\n  1.7651903629302979,\n  1.9537429809570312,\n  1.9721471071243286,\n  2.115678310394287,\n  2.4770500659942627,\n  2.4887232780456543,\n  2.7015204429626465,\n  2.794905424118042,\n  2.8368358612060547,\n  2.856282949447632,\n  3.3045120239257812,\n  3.3088574409484863,\n  3.5170013904571533,\n  3.543419361114502,\n  3.6437580585479736,\n  3.8610050678253174,\n  3.946575880050659,\n  4.467504501342773,\n  4.524377346038818,\n  4.6629109382629395,\n  4.760923385620117,\n  4.894143581390381,\n  4.894278526306152,\n  4.916898727416992,\n  4.97941780090332,\n  5.139681339263916,\n  5.1738505363464355,\n  5.456912040710449,\n  5.594730854034424,\n  5.808707237243652,\n  6.067543983459473,\n  6.280825138092041,\n  6.301357746124268,\n  6.338061809539795,\n  6.518653869628906,\n  6.525669097900391,\n  6.6523637771606445,\n  6.788163185119629,\n  6.830677509307861,\n  6.999333381652832,\n  7.314230918884277,\n  7.77747106552124,\n  7.815056800842285,\n  8.141789436340332,\n  8.4390230178833,\n  8.454288482666016,\n  8.623055458068848,\n  9.185099601745605,\n  10.866446495056152,\n  11.536565780639648,\n  12.156517028808594,\n  13.038426399230957,\n  13.038649559020996,\n  13.278070449829102],\n [-7.998893737792969,\n  -7.5035858154296875,\n  -5.997223377227783,\n  -4.4557318687438965,\n  -3.858123540878296,\n  -3.7934882640838623,\n  -3.7414190769195557,\n  -3.71085262298584,\n  -3.416511058807373,\n  -3.151026964187622,\n  -2.665776014328003,\n  -2.3304495811462402,\n  -2.314663887023926,\n  -2.240774154663086,\n  -1.6604324579238892,\n  -1.5986559391021729,\n  -1.319270372390747,\n  -0.9952215552330017,\n  -0.8675772547721863,\n  -0.815013587474823,\n  -0.6197594404220581,\n  -0.2709091007709503,\n  -0.15784072875976562,\n  -0.07173916697502136,\n  -0.024416757747530937,\n  0.16082027554512024,\n  0.26466113328933716,\n  0.29286491870880127,\n  0.3045484125614166,\n  0.3186204731464386,\n  0.6497359871864319,\n  0.7133653163909912,\n  0.7263752222061157,\n  0.9446797966957092,\n  1.1032476425170898,\n  1.1047269105911255,\n  1.1202912330627441,\n  1.1257086992263794,\n  1.1476240158081055,\n  1.3592561483383179,\n  1.4231185913085938,\n  1.4991273880004883,\n  1.5437859296798706,\n  1.6026957035064697,\n  1.6511987447738647,\n  1.687040090560913,\n  1.8127830028533936,\n  2.0000109672546387,\n  2.0182857513427734,\n  2.1608083248138428,\n  2.519641160964966,\n  2.5312321186065674,\n  2.7425341606140137,\n  2.8352630138397217,\n  2.876898765563965,\n  2.896209239959717,\n  3.3412890434265137,\n  3.3456039428710938,\n  3.5522851943969727,\n  3.5785176753997803,\n  3.6781513690948486,\n  3.893872022628784,\n  3.978841543197632,\n  4.496109962463379,\n  4.55258321762085,\n  4.69014310836792,\n  4.787467002868652,\n  4.9197516441345215,\n  4.919885635375977,\n  4.942346572875977,\n  5.004426002502441,\n  5.1635637283325195,\n  5.197493076324463,\n  5.478565692901611,\n  5.615416049957275,\n  5.8278889656066895,\n  6.084907054901123,\n  6.296689510345459,\n  6.317078113555908,\n  6.353524208068848,\n  6.5328474044799805,\n  6.539813041687012,\n  6.665617942810059,\n  6.8004631996154785,\n  6.842678546905518,\n  7.0101494789123535,\n  7.322834491729736,\n  7.782819747924805,\n  7.820141315460205,\n  8.144577980041504,\n  8.439723014831543,\n  8.45488166809082,\n  8.622462272644043,\n  9.180558204650879,\n  10.850090980529785,\n  11.515501976013184,\n  12.131096839904785,\n  13.00680923461914,\n  13.007031440734863,\n  13.244770050048828],\n [-7.903938293457031,\n  -7.411464214324951,\n  -5.913720607757568,\n  -4.381049156188965,\n  -3.7868597507476807,\n  -3.7225944995880127,\n  -3.670823335647583,\n  -3.6404316425323486,\n  -3.3477742671966553,\n  -3.0838091373443604,\n  -2.601334571838379,\n  -2.2679266929626465,\n  -2.2522313594818115,\n  -2.178764581680298,\n  -1.601743221282959,\n  -1.5403201580047607,\n  -1.262533187866211,\n  -0.9403384327888489,\n  -0.8134244680404663,\n  -0.7611615657806396,\n  -0.5670245885848999,\n  -0.22017022967338562,\n  -0.10774879902601242,\n  -0.022139888256788254,\n  0.02491176314651966,\n  0.20908893644809723,\n  0.31233564019203186,\n  0.3403780460357666,\n  0.35199472308158875,\n  0.36598625779151917,\n  0.6952072381973267,\n  0.7584725022315979,\n  0.771407961845398,\n  0.9884634613990784,\n  1.1461241245269775,\n  1.1475948095321655,\n  1.1630702018737793,\n  1.1684565544128418,\n  1.1902464628219604,\n  1.4006677865982056,\n  1.4641648530960083,\n  1.5397387742996216,\n  1.584141731262207,\n  1.642714500427246,\n  1.690940022468567,\n  1.7265762090682983,\n  1.8515998125076294,\n  2.0377564430236816,\n  2.055926561355591,\n  2.197633981704712,\n  2.5544135570526123,\n  2.5659382343292236,\n  2.776031255722046,\n  2.868229389190674,\n  2.9096271991729736,\n  2.9288270473480225,\n  3.3713600635528564,\n  3.375650405883789,\n  3.581149101257324,\n  3.607231616973877,\n  3.7062952518463135,\n  3.9207816123962402,\n  4.005264759063721,\n  4.51957368850708,\n  4.575723648071289,\n  4.712496757507324,\n  4.809263706207275,\n  4.940791130065918,\n  4.940924644470215,\n  4.9632568359375,\n  5.024981498718262,\n  5.183208465576172,\n  5.216943740844727,\n  5.496407985687256,\n  5.632475852966309,\n  5.8437323570251465,\n  6.09928035736084,\n  6.309850692749023,\n  6.330122947692871,\n  6.366360187530518,\n  6.544657230377197,\n  6.551583290100098,\n  6.676668167114258,\n  6.810741901397705,\n  6.852716445922852,\n  7.019228935241699,\n  7.330124378204346,\n  7.787477970123291,\n  7.824585914611816,\n  8.14716625213623,\n  8.44062328338623,\n  8.455695152282715,\n  8.622316360473633,\n  9.17721939086914,\n  10.837199211120605,\n  11.49880313873291,\n  12.110876083374023,\n  12.98157787322998,\n  12.98179817199707,\n  13.21817684173584],\n [-7.826869964599609,\n  -7.336688995361328,\n  -5.845917224884033,\n  -4.320380687713623,\n  -3.728957414627075,\n  -3.6649913787841797,\n  -3.6134610176086426,\n  -3.5832109451293945,\n  -3.2919158935546875,\n  -3.029179573059082,\n  -2.5489509105682373,\n  -2.217095136642456,\n  -2.201472759246826,\n  -2.1283481121063232,\n  -1.5540128946304321,\n  -1.4928756952285767,\n  -1.2163819074630737,\n  -0.8956869840621948,\n  -0.7693638205528259,\n  -0.7173442244529724,\n  -0.5241109728813171,\n  -0.1788712739944458,\n  -0.06697317957878113,\n  0.01823720894753933,\n  0.06506982445716858,\n  0.24838963150978088,\n  0.35115569829940796,\n  0.3790675699710846,\n  0.39063015580177307,\n  0.4045565724372864,\n  0.7322449684143066,\n  0.7952157258987427,\n  0.8080909848213196,\n  1.0241360664367676,\n  1.1810626983642578,\n  1.182526707649231,\n  1.1979299783706665,\n  1.2032912969589233,\n  1.2249797582626343,\n  1.434421420097351,\n  1.4976229667663574,\n  1.5728451013565063,\n  1.6170413494110107,\n  1.6753414869308472,\n  1.7233424186706543,\n  1.7588127851486206,\n  1.8832542896270752,\n  2.068544387817383,\n  2.08663010597229,\n  2.227677583694458,\n  2.582796335220337,\n  2.5942673683166504,\n  2.803382396697998,\n  2.8951516151428223,\n  2.936356544494629,\n  2.9554669857025146,\n  3.395940065383911,\n  3.400210380554199,\n  3.604752540588379,\n  3.63071346282959,\n  3.729315996170044,\n  3.9428038597106934,\n  4.0268940925598145,\n  4.538808345794678,\n  4.594696998596191,\n  4.730833530426025,\n  4.827149868011475,\n  4.958065032958984,\n  4.958198070526123,\n  4.98042631149292,\n  5.041863441467285,\n  5.19935417175293,\n  5.232932090759277,\n  5.5110955238342285,\n  5.646529674530029,\n  5.8568034172058105,\n  6.111161231994629,\n  6.320751667022705,\n  6.34092903137207,\n  6.376997947692871,\n  6.554465293884277,\n  6.56135892868042,\n  6.685861587524414,\n  6.819311141967773,\n  6.861090183258057,\n  7.026827335357666,\n  7.336275577545166,\n  7.791500091552734,\n  7.82843542098999,\n  8.149514198303223,\n  8.441604614257812,\n  8.4566068649292,\n  8.622452735900879,\n  9.174772262573242,\n  10.827024459838867,\n  11.485548973083496,\n  12.094772338867188,\n  12.961421012878418,\n  12.961640357971191,\n  13.196918487548828],\n [-7.764307975769043,\n  -7.27598237991333,\n  -5.790853023529053,\n  -4.271090030670166,\n  -3.681905508041382,\n  -3.6181814670562744,\n  -3.5668461322784424,\n  -3.536710739135742,\n  -3.246518135070801,\n  -2.984776258468628,\n  -2.5063650608062744,\n  -2.1757652759552,\n  -2.1602022647857666,\n  -2.0873541831970215,\n  -1.5151927471160889,\n  -1.4542869329452515,\n  -1.1788396835327148,\n  -0.8593584895133972,\n  -0.7335134744644165,\n  -0.6816907525062561,\n  -0.4891888499259949,\n  -0.14525583386421204,\n  -0.033781249076128006,\n  0.051106635481119156,\n  0.09776199609041214,\n  0.2803879678249359,\n  0.3827650845050812,\n  0.41057130694389343,\n  0.4220901429653168,\n  0.43596383929252625,\n  0.7624120116233826,\n  0.8251444101333618,\n  0.8379709720611572,\n  1.0531983375549316,\n  1.2095310688018799,\n  1.2109894752502441,\n  1.2263344526290894,\n  1.2316755056381226,\n  1.253281831741333,\n  1.4619308710098267,\n  1.5248931646347046,\n  1.5998305082321167,\n  1.6438595056533813,\n  1.7019389867782593,\n  1.7497583627700806,\n  1.7850943803787231,\n  1.9090650081634521,\n  2.093653678894043,\n  2.111670970916748,\n  2.2521846294403076,\n  2.605959415435791,\n  2.617387056350708,\n  2.8257105350494385,\n  2.9171321392059326,\n  2.958181142807007,\n  2.977219343185425,\n  3.416025400161743,\n  3.4202795028686523,\n  3.6240475177764893,\n  3.6499102115631104,\n  3.7481393814086914,\n  3.9608192443847656,\n  4.044590950012207,\n  4.554568290710449,\n  4.610245227813721,\n  4.745866775512695,\n  4.841818332672119,\n  4.972238063812256,\n  4.972370147705078,\n  4.994514465332031,\n  5.055719375610352,\n  5.212613582611084,\n  5.24606466293335,\n  5.523175239562988,\n  5.658096790313721,\n  5.867574691772461,\n  6.120970249176025,\n  6.329767227172852,\n  6.349868297576904,\n  6.385800361633301,\n  6.562595844268799,\n  6.569463729858398,\n  6.693495273590088,\n  6.826439380645752,\n  6.868060111999512,\n  7.033170223236084,\n  7.341447353363037,\n  7.794949054718018,\n  7.83174467086792,\n  8.151607513427734,\n  8.44259262084961,\n  8.457537651062012,\n  8.622756004333496,\n  9.172985076904297,\n  10.818984031677246,\n  11.475016593933105,\n  12.081933975219727,\n  12.945302963256836,\n  12.945521354675293,\n  13.179908752441406],\n [-7.713510990142822,\n  -7.226686954498291,\n  -5.746126174926758,\n  -4.231037616729736,\n  -3.643665313720703,\n  -3.580137252807617,\n  -3.5289597511291504,\n  -3.4989171028137207,\n  -3.2096168994903564,\n  -2.9486801624298096,\n  -2.47174072265625,\n  -2.142157793045044,\n  -2.1266424655914307,\n  -2.054018497467041,\n  -1.4836169481277466,\n  -1.422898530960083,\n  -1.1482985019683838,\n  -0.829800009727478,\n  -0.7043420076370239,\n  -0.6526787281036377,\n  -0.4607689380645752,\n  -0.11789380013942719,\n  -0.006762102246284485,\n  0.07786467671394348,\n  0.12437653541564941,\n  0.3064407706260681,\n  0.408502995967865,\n  0.43622371554374695,\n  0.44770708680152893,\n  0.4615381062030792,\n  0.7869821786880493,\n  0.8495216369628906,\n  0.8623087406158447,\n  1.0768741369247437,\n  1.232725977897644,\n  1.2341798543930054,\n  1.2494776248931885,\n  1.2548022270202637,\n  1.2763421535491943,\n  1.4843493700027466,\n  1.547118067741394,\n  1.6218249797821045,\n  1.6657185554504395,\n  1.7236193418502808,\n  1.7712914943695068,\n  1.8065189123153687,\n  1.9301081895828247,\n  2.1141293048858643,\n  2.1320908069610596,\n  2.272172451019287,\n  2.624859094619751,\n  2.636251449584961,\n  2.8439342975616455,\n  2.935074806213379,\n  2.9759974479675293,\n  2.9949772357940674,\n  3.4324333667755127,\n  3.4366743564605713,\n  3.63981556892395,\n  3.6655988693237305,\n  3.76352596282959,\n  3.9755516052246094,\n  4.059065818786621,\n  4.567473888397217,\n  4.622980117797852,\n  4.75818395614624,\n  4.8538408279418945,\n  4.983859539031982,\n  4.9839911460876465,\n  5.006067276000977,\n  5.067083835601807,\n  5.223495960235596,\n  5.2568440437316895,\n  5.533102035522461,\n  5.667608737945557,\n  5.876441955566406,\n  6.129057884216309,\n  6.337213039398193,\n  6.35725212097168,\n  6.393074035644531,\n  6.5693254470825195,\n  6.576172351837158,\n  6.699821949005127,\n  6.832357406616211,\n  6.873850345611572,\n  7.038452625274658,\n  7.345781326293945,\n  7.797888278961182,\n  7.834570407867432,\n  8.153450012207031,\n  8.4435396194458,\n  8.458438873291016,\n  8.623148918151855,\n  9.171685218811035,\n  10.8126220703125,\n  11.466635704040527,\n  12.071686744689941,\n  12.93239974975586,\n  12.932618141174316,\n  13.166284561157227],\n [-7.672260761260986,\n  -7.186653137207031,\n  -5.709791660308838,\n  -4.198488712310791,\n  -3.612584114074707,\n  -3.5492148399353027,\n  -3.4981651306152344,\n  -3.4681975841522217,\n  -3.1796202659606934,\n  -2.91933536529541,\n  -2.4435875415802,\n  -2.11482834815979,\n  -2.099351644515991,\n  -2.026909112930298,\n  -1.457932949066162,\n  -1.3973662853240967,\n  -1.1234523057937622,\n  -0.8057495951652527,\n  -0.6806051135063171,\n  -0.6290708780288696,\n  -0.43764063715934753,\n  -0.0956222265958786,\n  0.015231793746352196,\n  0.09964711964130402,\n  0.14604276418685913,\n  0.32765209674835205,\n  0.4294593036174774,\n  0.457110732793808,\n  0.468565434217453,\n  0.48236188292503357,\n  0.806992769241333,\n  0.869376003742218,\n  0.8821310997009277,\n  1.0961604118347168,\n  1.2516227960586548,\n  1.2530730962753296,\n  1.268332600593567,\n  1.273643970489502,\n  1.2951301336288452,\n  1.502617597579956,\n  1.5652294158935547,\n  1.639749526977539,\n  1.6835334300994873,\n  1.7412896156311035,\n  1.7888426780700684,\n  1.8239821195602417,\n  1.9472625255584717,\n  2.130823850631714,\n  2.148740530014038,\n  2.2884721755981445,\n  2.64027738571167,\n  2.651641368865967,\n  2.8588054180145264,\n  2.9497179985046387,\n  2.9905385971069336,\n  3.0094707012176514,\n  3.445833921432495,\n  3.4500644207000732,\n  3.652698040008545,\n  3.6784167289733887,\n  3.77609920501709,\n  3.9875950813293457,\n  4.0709004402160645,\n  4.578038692474365,\n  4.633405685424805,\n  4.768272399902344,\n  4.86368989944458,\n  4.993383407592773,\n  4.9935150146484375,\n  5.015536308288574,\n  5.076399803161621,\n  5.232420921325684,\n  5.26568603515625,\n  5.541253566741943,\n  5.675424575805664,\n  5.883735656738281,\n  6.135720729827881,\n  6.343355655670166,\n  6.363344669342041,\n  6.39907693862915,\n  6.574888229370117,\n  6.581717491149902,\n  6.705058574676514,\n  6.837263107299805,\n  6.878652095794678,\n  7.042842864990234,\n  7.3494038581848145,\n  7.800381183624268,\n  7.836971759796143,\n  8.155054092407227,\n  8.444419860839844,\n  8.459280967712402,\n  8.623579978942871,\n  9.170745849609375,\n  10.807581901550293,\n  11.459961891174316,\n  12.06350040435791,\n  12.922063827514648,\n  12.922280311584473,\n  13.155364036560059],\n [-7.63875675201416,\n  -7.154134273529053,\n  -5.680269718170166,\n  -4.17203426361084,\n  -3.5873184204101562,\n  -3.5240776538848877,\n  -3.4731316566467285,\n  -3.4432246685028076,\n  -3.155233144760132,\n  -2.8954765796661377,\n  -2.420694351196289,\n  -2.092602014541626,\n  -2.0771567821502686,\n  -2.004861354827881,\n  -1.4370397329330444,\n  -1.3765959739685059,\n  -1.1032378673553467,\n  -0.7861799001693726,\n  -0.661289393901825,\n  -0.6098597645759583,\n  -0.41881799697875977,\n  -0.07749363034963608,\n  0.03313542529940605,\n  0.11737944930791855,\n  0.16368094086647034,\n  0.34492170810699463,\n  0.4465223252773285,\n  0.474117636680603,\n  0.48554909229278564,\n  0.49931755661964417,\n  0.8232896327972412,\n  0.8855462670326233,\n  0.8982754945755005,\n  1.1118704080581665,\n  1.2670173645019531,\n  1.2684646844863892,\n  1.2836933135986328,\n  1.2889938354492188,\n  1.3104363679885864,\n  1.517502784729004,\n  1.5799875259399414,\n  1.6543564796447754,\n  1.6980515718460083,\n  1.7556904554367065,\n  1.8031470775604248,\n  1.8382152318954468,\n  1.9612454175949097,\n  2.1444342136383057,\n  2.1623146533966064,\n  2.301762580871582,\n  2.6528539657592773,\n  2.6641948223114014,\n  2.870938301086426,\n  2.9616665840148926,\n  3.00240421295166,\n  3.0212981700897217,\n  3.456775665283203,\n  3.4609975814819336,\n  3.663220167160034,\n  3.6888866424560547,\n  3.7863707542419434,\n  3.9974374771118164,\n  4.080574035644531,\n  4.5866827964782715,\n  4.641937732696533,\n  4.7765302658081055,\n  4.871754169464111,\n  5.001184940338135,\n  5.001316070556641,\n  5.023292541503906,\n  5.084033012390137,\n  5.239737510681152,\n  5.272934436798096,\n  5.547943115234375,\n  5.6818413734436035,\n  5.889730453491211,\n  6.141203880310059,\n  6.348417282104492,\n  6.36836576461792,\n  6.404025554656982,\n  6.579480171203613,\n  6.5862956047058105,\n  6.709386348724365,\n  6.841322422027588,\n  6.882627487182617,\n  7.046485424041748,\n  7.352424144744873,\n  7.802485942840576,\n  7.83900260925293,\n  8.156439781188965,\n  8.44521713256836,\n  8.460049629211426,\n  8.624013900756836,\n  9.170069694519043,\n  10.803584098815918,\n  11.45464038848877,\n  12.056954383850098,\n  12.913774490356445,\n  12.913991928100586,\n  13.146601676940918],\n [-7.611539840698242,\n  -7.127716064453125,\n  -5.656280517578125,\n  -4.1505303382873535,\n  -3.5667781829833984,\n  -3.5036416053771973,\n  -3.452779769897461,\n  -3.422921895980835,\n  -3.1354050636291504,\n  -2.8760764598846436,\n  -2.402076482772827,\n  -2.0745251178741455,\n  -2.059105396270752,\n  -1.986928939819336,\n  -1.4200431108474731,\n  -1.3596988916397095,\n  -1.0867912769317627,\n  -0.7702558040618896,\n  -0.6455711126327515,\n  -0.5942262411117554,\n  -0.4034992754459381,\n  -0.06273742020130157,\n  0.047709330916404724,\n  0.13181452453136444,\n  0.17803971469402313,\n  0.35898181796073914,\n  0.46041497588157654,\n  0.48796483874320984,\n  0.49937742948532104,\n  0.5131232142448425,\n  0.8365614414215088,\n  0.8987154364585876,\n  0.9114237427711487,\n  1.1246665716171265,\n  1.2795579433441162,\n  1.2810028791427612,\n  1.2962063550949097,\n  1.3014981746673584,\n  1.3229053020477295,\n  1.5296305418014526,\n  1.5920122861862183,\n  1.666258692741394,\n  1.7098817825317383,\n  1.7674256563186646,\n  1.8148040771484375,\n  1.8498144149780273,\n  1.972641944885254,\n  2.1555287837982178,\n  2.17337965965271,\n  2.3125979900360107,\n  2.6631107330322266,\n  2.6744329929351807,\n  2.880835771560669,\n  2.971414566040039,\n  3.0120849609375,\n  3.030947685241699,\n  3.465707778930664,\n  3.4699225425720215,\n  3.671811819076538,\n  3.6974360942840576,\n  3.794759511947632,\n  4.005478382110596,\n  4.088478088378906,\n  4.593752861022949,\n  4.648916721343994,\n  4.783287048339844,\n  4.878354549407959,\n  5.007571697235107,\n  5.007702827453613,\n  5.029642581939697,\n  5.090282917022705,\n  5.245730876922607,\n  5.278873443603516,\n  5.553429126739502,\n  5.687106609344482,\n  5.894652843475342,\n  6.145711898803711,\n  6.352583885192871,\n  6.372499465942383,\n  6.408100605010986,\n  6.583265781402588,\n  6.5900702476501465,\n  6.712958335876465,\n  6.844676494598389,\n  6.885913848876953,\n  7.049501419067383,\n  7.354936122894287,\n  7.804256439208984,\n  7.840712547302246,\n  8.15762710571289,\n  8.445928573608398,\n  8.460736274719238,\n  8.624430656433105,\n  9.169586181640625,\n  10.800409317016602,\n  11.45039176940918,\n  12.051713943481445,\n  12.907122611999512,\n  12.90733814239502,\n  13.139565467834473],\n [-7.589427947998047,\n  -7.1062517166137695,\n  -5.63678503036499,\n  -4.133049488067627,\n  -3.5500783920288086,\n  -3.4870262145996094,\n  -3.436232328414917,\n  -3.406414747238159,\n  -3.1192824840545654,\n  -2.8603007793426514,\n  -2.386935234069824,\n  -2.059821844100952,\n  -2.0444228649139404,\n  -1.97234308719635,\n  -1.4062156677246094,\n  -1.3459522724151611,\n  -1.073409914970398,\n  -0.757297933101654,\n  -0.6327800750732422,\n  -0.5815038681030273,\n  -0.3910321295261383,\n  -0.050726234912872314,\n  0.0595727264881134,\n  0.14356538653373718,\n  0.1897287219762802,\n  0.3704287111759186,\n  0.4717261493206024,\n  0.49923914670944214,\n  0.5106364488601685,\n  0.5243638753890991,\n  0.8473693132400513,\n  0.9094401597976685,\n  0.9221314191818237,\n  1.1350890398025513,\n  1.2897729873657227,\n  1.2912160158157349,\n  1.3063991069793701,\n  1.3116838932037354,\n  1.3330624103546143,\n  1.53951096534729,\n  1.6018093824386597,\n  1.67595636844635,\n  1.7195210456848145,\n  1.7769880294799805,\n  1.8243030309677124,\n  1.8592665195465088,\n  1.9819296598434448,\n  2.164571762084961,\n  2.182398796081543,\n  2.3214306831359863,\n  2.6714744567871094,\n  2.68278169631958,\n  2.8889081478118896,\n  2.979365825653076,\n  3.019981861114502,\n  3.0388193130493164,\n  3.4729976654052734,\n  3.4772069454193115,\n  3.678825855255127,\n  3.704415798187256,\n  3.8016092777252197,\n  4.0120463371276855,\n  4.094934463500977,\n  4.5995330810546875,\n  4.654623031616211,\n  4.788814067840576,\n  4.883754253387451,\n  5.012798309326172,\n  5.012929439544678,\n  5.034840106964111,\n  5.095399379730225,\n  5.250638961791992,\n  5.2837371826171875,\n  5.557925224304199,\n  5.691424369812012,\n  5.898692607879639,\n  6.149415969848633,\n  6.356010913848877,\n  6.3759002685546875,\n  6.4114532470703125,\n  6.586384296417236,\n  6.593179702758789,\n  6.715902805328369,\n  6.847445487976074,\n  6.888627052307129,\n  7.051996231079102,\n  7.357022285461426,\n  7.805741310119629,\n  7.842148303985596,\n  8.158638954162598,\n  8.446555137634277,\n  8.461341857910156,\n  8.624817848205566,\n  9.169244766235352,\n  10.797884941101074,\n  11.44699764251709,\n  12.047514915466309,\n  12.901779174804688,\n  12.901994705200195,\n  13.1339111328125],\n [-7.571461200714111,\n  -7.088809967041016,\n  -5.620939254760742,\n  -4.118837833404541,\n  -3.5364997386932373,\n  -3.4735164642333984,\n  -3.4227776527404785,\n  -3.3929922580718994,\n  -3.1061720848083496,\n  -2.8474717140197754,\n  -2.3746204376220703,\n  -2.0478625297546387,\n  -2.032480239868164,\n  -1.960478663444519,\n  -1.3949663639068604,\n  -1.3347684144973755,\n  -1.062522053718567,\n  -0.7467535138130188,\n  -0.6223708987236023,\n  -0.5711504220962524,\n  -0.38088560104370117,\n  -0.040949393063783646,\n  0.06922974437475204,\n  0.1531311571598053,\n  0.19924433529376984,\n  0.37974801659584045,\n  0.4809354245662689,\n  0.5084185004234314,\n  0.5198034644126892,\n  0.5335159301757812,\n  0.8561704754829407,\n  0.9181739091873169,\n  0.930851399898529,\n  1.1435775756835938,\n  1.298093557357788,\n  1.2995350360870361,\n  1.3147016763687134,\n  1.3199806213378906,\n  1.3413360118865967,\n  1.547560214996338,\n  1.6097909212112427,\n  1.6838574409484863,\n  1.727374792098999,\n  1.7847793102264404,\n  1.832042932510376,\n  1.8669683933258057,\n  1.989498257637024,\n  2.1719419956207275,\n  2.1897497177124023,\n  2.3286306858062744,\n  2.6782939434051514,\n  2.689588785171509,\n  2.895491600036621,\n  2.9858508110046387,\n  3.0264227390289307,\n  3.0452396869659424,\n  3.4789464473724365,\n  3.4831509590148926,\n  3.6845510005950928,\n  3.710113286972046,\n  3.8072009086608887,\n  4.017409324645996,\n  4.100207805633545,\n  4.604258060455322,\n  4.65928840637207,\n  4.793333530426025,\n  4.88817024230957,\n  5.0170745849609375,\n  5.017205238342285,\n  5.039092063903809,\n  5.09958553314209,\n  5.254656791687012,\n  5.287718772888184,\n  5.561609268188477,\n  5.694962978363037,\n  5.902006149291992,\n  6.152457237243652,\n  6.358827590942383,\n  6.378695011138916,\n  6.414209842681885,\n  6.588951110839844,\n  6.595738887786865,\n  6.718328952789307,\n  6.849728107452393,\n  6.890865325927734,\n  7.054056644439697,\n  7.35875129699707,\n  7.80698299407959,\n  7.843350887298584,\n  8.159497261047363,\n  8.447100639343262,\n  8.461872100830078,\n  8.62516975402832,\n  9.169004440307617,\n  10.795876502990723,\n  11.444284439086914,\n  12.044148445129395,\n  12.89748477935791,\n  12.897700309753418,\n  13.129364013671875],\n [-7.556859493255615,\n  -7.074634075164795,\n  -5.608058452606201,\n  -4.107281684875488,\n  -3.5254576206207275,\n  -3.4625296592712402,\n  -3.4118356704711914,\n  -3.3820767402648926,\n  -3.0955095291137695,\n  -2.8370375633239746,\n  -2.364603042602539,\n  -2.038133382797241,\n  -2.0227646827697754,\n  -1.9508267641067505,\n  -1.3858133554458618,\n  -1.325668454170227,\n  -1.0536623001098633,\n  -0.7381722927093506,\n  -0.6138994693756104,\n  -0.5627241134643555,\n  -0.3726271688938141,\n  -0.03299083933234215,\n  0.07709110528230667,\n  0.1609184890985489,\n  0.20699100196361542,\n  0.3873354494571686,\n  0.4884335994720459,\n  0.5158924460411072,\n  0.527267336845398,\n  0.5409677028656006,\n  0.8633376359939575,\n  0.9252863526344299,\n  0.9379526376724243,\n  1.1504912376403809,\n  1.304870843887329,\n  1.306311011314392,\n  1.3214643001556396,\n  1.326738715171814,\n  1.3480751514434814,\n  1.5541175603866577,\n  1.61629319190979,\n  1.6902943849563599,\n  1.7337733507156372,\n  1.7911272048950195,\n  1.8383492231369019,\n  1.873243808746338,\n  1.9956656694412231,\n  2.177948236465454,\n  2.1957404613494873,\n  2.334498882293701,\n  2.6838538646698,\n  2.695138692855835,\n  2.9008595943450928,\n  2.9911391735076904,\n  3.031675338745117,\n  3.050475835800171,\n  3.483799695968628,\n  3.4880008697509766,\n  3.689223051071167,\n  3.7147626876831055,\n  3.81176495552063,\n  4.021787643432617,\n  4.104513168334961,\n  4.608119010925293,\n  4.663100719451904,\n  4.797027587890625,\n  4.891780853271484,\n  5.020571231842041,\n  5.0207014083862305,\n  5.042569160461426,\n  5.103009223937988,\n  5.257943630218506,\n  5.290976524353027,\n  5.564625263214111,\n  5.697861671447754,\n  5.904722213745117,\n  6.154952049255371,\n  6.361140727996826,\n  6.380990505218506,\n  6.416473865509033,\n  6.591060638427734,\n  6.597842693328857,\n  6.720324516296387,\n  6.8516082763671875,\n  6.892708778381348,\n  7.055756568908691,\n  7.360182285308838,\n  7.808018207550049,\n  7.844354152679443,\n  8.160221099853516,\n  8.44757080078125,\n  8.462329864501953,\n  8.625483512878418,\n  9.168838500976562,\n  10.794275283813477,\n  11.442111015319824,\n  12.0414457321167,\n  12.89402961730957,\n  12.894245147705078,\n  13.125704765319824],\n [-7.544992446899414,\n  -7.063112258911133,\n  -5.5975871086120605,\n  -4.0978851318359375,\n  -3.5164780616760254,\n  -3.4535951614379883,\n  -3.402937412261963,\n  -3.373199701309204,\n  -3.0868377685546875,\n  -2.8285508155822754,\n  -2.356454849243164,\n  -2.030219078063965,\n  -2.0148613452911377,\n  -1.9429749250411987,\n  -1.3783661127090454,\n  -1.318264365196228,\n  -1.0464529991149902,\n  -0.7311890125274658,\n  -0.6070051789283752,\n  -0.555866539478302,\n  -0.3659057021141052,\n  -0.026512641459703445,\n  0.08349045366048813,\n  0.16725780069828033,\n  0.2132973074913025,\n  0.3935125768184662,\n  0.4945383071899414,\n  0.5219774842262268,\n  0.5333442687988281,\n  0.5470348000526428,\n  0.8691738247871399,\n  0.9310781359672546,\n  0.9437353610992432,\n  1.1561217308044434,\n  1.310390830039978,\n  1.311829924583435,\n  1.3269723653793335,\n  1.3322429656982422,\n  1.3535641431808472,\n  1.5594589710235596,\n  1.6215901374816895,\n  1.6955382823944092,\n  1.7389861345291138,\n  1.796298861503601,\n  1.843487024307251,\n  1.878356695175171,\n  2.0006906986236572,\n  2.182842969894409,\n  2.200622320175171,\n  2.3392813205718994,\n  2.6883859634399414,\n  2.699662685394287,\n  2.9052364826202393,\n  2.9954514503479004,\n  3.0359585285186768,\n  3.0547454357147217,\n  3.4877591133117676,\n  3.491956949234009,\n  3.693035125732422,\n  3.7185566425323486,\n  3.8154892921447754,\n  4.02536153793335,\n  4.108027458190918,\n  4.611272811889648,\n  4.666214942932129,\n  4.800045967102051,\n  4.894731521606445,\n  5.0234293937683105,\n  5.023560047149658,\n  5.045412063598633,\n  5.105808734893799,\n  5.260632038116455,\n  5.293641567230225,\n  5.567094326019287,\n  5.700234889984131,\n  5.906947612762451,\n  6.156998157501221,\n  6.363039016723633,\n  6.382874488830566,\n  6.418332576751709,\n  6.592794418334961,\n  6.599571228027344,\n  6.721965789794922,\n  6.853155136108398,\n  6.894226551055908,\n  7.057157039642334,\n  7.361364841461182,\n  7.80888032913208,\n  7.845190048217773,\n  8.160831451416016,\n  8.447975158691406,\n  8.462722778320312,\n  8.625760078430176,\n  9.168725967407227,\n  10.792997360229492,\n  11.440369606018066,\n  12.039276123046875,\n  12.89124870300293,\n  12.891464233398438,\n  13.122757911682129]]\n\n\n\nlen(yhat_history)\n\n30\n\n\n\nlen(yhat_history[0]) #0에 100개... [1]에 100개.. \n\n100\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[2],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[9],'--')\n\n\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat_history[14],'--')\n\n\n\n\n- \\(\\hat{\\bf W}\\) 관찰\n\nWhat_history\n\n[[-3.657747745513916, 8.81106948852539],\n [-2.554811477661133, 7.861191749572754],\n [-1.649186134338379, 7.101552963256836],\n [-0.9060712456703186, 6.49347448348999],\n [-0.2966785430908203, 6.006272315979004],\n [0.20277434587478638, 5.615575313568115],\n [0.6119105815887451, 5.302003383636475],\n [0.9469034671783447, 5.050129413604736],\n [1.2210699319839478, 4.847657680511475],\n [1.4453645944595337, 4.684779167175293],\n [1.6287915706634521, 4.553659439086914],\n [1.778746247291565, 4.448036193847656],\n [1.90129816532135, 4.3628973960876465],\n [2.0014259815216064, 4.294229507446289],\n [2.0832109451293945, 4.238814353942871],\n [2.149996757507324, 4.194070339202881],\n [2.204521894454956, 4.157923698425293],\n [2.249027729034424, 4.128708839416504],\n [2.285348415374756, 4.105085849761963],\n [2.31498384475708, 4.0859761238098145],\n [2.339160442352295, 4.070511341094971],\n [2.3588807582855225, 4.057991027832031],\n [2.3749637603759766, 4.0478515625],\n [2.3880786895751953, 4.039637088775635],\n [2.3987717628479004, 4.032979965209961],\n [2.40748929977417, 4.027583599090576],\n [2.414595603942871, 4.023208141326904],\n [2.4203879833221436, 4.019659042358398],\n [2.4251089096069336, 4.016779899597168],\n [2.4289560317993164, 4.014443874359131]]\n\n\n- loss 관찰\n\nloss_history\n\n[8587.6875,\n 5675.2109375,\n 3755.637451171875,\n 2489.581787109375,\n 1654.0390625,\n 1102.3206787109375,\n 737.8441162109375,\n 496.96514892578125,\n 337.7142028808594,\n 232.39694213867188,\n 162.72906494140625,\n 116.63263702392578,\n 86.1263656616211,\n 65.93397521972656,\n 52.566444396972656,\n 43.71583557128906,\n 37.855220794677734,\n 33.974090576171875,\n 31.403636932373047,\n 29.701112747192383,\n 28.57339096069336,\n 27.826366424560547,\n 27.331483840942383,\n 27.003639221191406,\n 26.78643798828125,\n 26.642536163330078,\n 26.547197341918945,\n 26.48402976989746,\n 26.442174911499023,\n 26.414440155029297]\n\n\n\nplt.plot(loss_history)\n\n\n\n\n\n\n학습과정을 animation으로 시각화\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n- 왼쪽에는 \\((x_i,y_i)\\) and \\((x_i,\\hat{y}_i)\\) 을 그리고 오른쪽에는 \\(loss(w_0,w_1)\\) 을 그릴것임\n\nfig = plt.figure()\nax1 = fig.add_subplot(1, 2, 1)\nax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n\n\n\n\n# 왼쪽 2d 오른쪽 3d 축만 생긴다\n\n- 왼쪽그림!\n\nax1.plot(x,y,'o')\nline, = ax1.plot(x,yhat_history[0]) # 나중에 애니메이션 할때 필요해요..\n\n\nfig\n\n\n\n\n- 오른쪽 그림1: \\(loss(w_0,w_1)\\)\n\n_w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n_w1 = np.arange(-6, 11, 0.5)\nw1,w0 = np.meshgrid(_w1,_w0)\nlss=w0*0\nfor i in range(len(_w0)):\n    for j in range(len(_w1)):\n        lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\nax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \nax2.azim = 40  ## 3d plot의 view 조절 \nax2.dist = 8   ## 3d plot의 view 조절 \nax2.elev = 5   ## 3d plot의 view 조절 \n\n\nfig\n\n\n\n\n- 오른쪽 그림2: \\((w_0,w_1)=(2.5,4)\\) 와 \\(loss(2.5,4)\\) 값 &lt;- loss 함수가 최소가 되는 값 (이거 진짜야? ㅋㅋ)\n\nax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fac8c960610&gt;\n\n\n\nfig\n\n\n\n\n- 오른쪽 그림3: \\((w_0,w_1)=(-3.66, 8.81)\\) 와 \\(loss(-3.66,8.81)\\) 값\n\nWhat_history[0]\n\n[-3.657747745513916, 8.81106948852539]\n\n\n\nax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='grey') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n#처음 값!! 오른쪽 그림에서 저 동그라미 회색점이 별표로 가야해~~ 경사하강법생각하자!\n\n&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fac8c7e5710&gt;\n\n\n\nfig\n\n\n\n\n- 애니메이션\n\ndef animate(epoc):\n    line.set_ydata(yhat_history[epoc])\n    ax2.scatter(What_history[epoc][0],What_history[epoc][1],loss_history[epoc],color='grey')\n    return line\n\nani = animation.FuncAnimation(fig, animate, frames=30)\nplt.close()\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 함수로 만들자..\n\ndef show_lrpr(data,history):\n    x,y = data \n    loss_history,yhat_history,What_history = history \n    \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    ## ax1: 왼쪽그림 \n    ax1.plot(x,y,'o')\n    line, = ax1.plot(x,yhat_history[0]) \n    ## ax2: 오른쪽그림 \n    _w0 = np.arange(-6, 11, 0.5) ## 파란색곡면을 그리는 코드 (시작) \n    _w1 = np.arange(-6, 11, 0.5)\n    w1,w0 = np.meshgrid(_w1,_w0)\n    lss=w0*0\n    for i in range(len(_w0)):\n        for j in range(len(_w1)):\n            lss[i,j]=torch.sum((y-_w0[i]-_w1[j]*x)**2)\n    ax2.plot_surface(w0, w1, lss, rstride=1, cstride=1, color='b',alpha=0.35) ## 파란색곡면을 그리는 코드(끝) \n    ax2.scatter(2.5,4,torch.sum((y-2.5-4*x)**2),s=200,color='red',marker='*') ## 최소점을 표시하는 코드 (붉은색 별) \n    ax2.scatter(What_history[0][0],What_history[0][1],loss_history[0],color='b') ## 업데이트되는 What을 표시하는 점 (파란색 동그라미) \n    ax2.azim = 40  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#alpha에-대하여-alpha는-학습률",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#alpha에-대하여-alpha는-학습률",
    "title": "기계학습 (0921) 3주차",
    "section": "\\(\\alpha\\)에 대하여 (\\(\\alpha\\)는 학습률)",
    "text": "\\(\\alpha\\)에 대하여 (\\(\\alpha\\)는 학습률)\n\n#머신러닝에서 a는 학습률...\n\n\n(1) \\(\\alpha=0.0001\\): \\(\\alpha\\) 가 너무 작다면? \\(\\to\\) 비효율적이다.\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0001 \nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n(2) \\(\\alpha=0.0083\\): \\(\\alpha\\)가 너무 크다면? \\(\\to\\) 다른의미에서 비효율적이다 + 위험하다..\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0083\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n(3) \\(\\alpha=0.0085\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.0085\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad.data; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n\n\n(4) \\(\\alpha=0.01\\)\n\nloss_history = [] # 기록하고 싶은것 1  \nyhat_history = [] # 기록하고 싶은것 2 \nWhat_history = [] # 기록하고 싶은것 3 \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.01\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#숙제",
    "href": "posts/1. DNN/2022_09_21_(3주차)_9월21일_ipynb의_사본.html#숙제",
    "title": "기계학습 (0921) 3주차",
    "section": "숙제",
    "text": "숙제\n- 학습률(\\(\\alpha\\))를 조정하며 실습해보고 스크린샷 제출\n\n# α=0.00912\nloss_history = [] \nyhat_history = [] \nWhat_history = [] \n\n\nWhat= torch.tensor([-5.0,10.0],requires_grad=True)\nalpha=0.00912\nfor epoc in range(30): \n    yhat=X@What ; yhat_history.append(yhat.data.tolist())\n    loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n    loss.backward() \n    What.data = What.data-alpha * What.grad; What_history.append(What.data.tolist())\n    What.grad=None\n\n\nshow_lrpr([x,y],[loss_history,yhat_history,What_history])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Boram-coco",
    "section": "",
    "text": "Everyday with Coco"
  }
]